{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN(generative adversarial network)入門\n",
    "\n",
    "このテキストは画像生成手法であるGANについて述べます。GANは「機械学習分野において、この10年間でもっとも面白いアイデア」とまで言われています。\n",
    "\n",
    "このテキストを読み終える頃にはGANのエレガントさに驚いていると思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto encoderとはどう違うのか？\n",
    "\n",
    "画像生成手法といえば、教師なし学習によるオートエンコーダーがそれまでは主流でした。しかしオートエンコーダーは、教師なし学習なので、入力画像よりは高精度な画像を生成することができません。しかも、完全に内挿の範疇です。\n",
    "\n",
    "要するに入力された画像と違うニュアンスの画像を生成することはできません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANは教師なし学習なのか？\n",
    "\n",
    "ではGANは教師ありなのか？教師なしなのか？どちらでしょう。正解はどちらでもありません。\n",
    "\n",
    "GANは半教師あり学習と呼ばれるものになります。半教師ありというのは、名前の通り、半分は教師あり学習で半分は教師なし学習を使用したものです。\n",
    "\n",
    "半分は教師あり、半分は教師なしということはDNN的には\n",
    "\n",
    "NNの半分までは教師ありで、残り半分は教師なし\n",
    "教師ありで学習されたNNと教師なしで学習されたNNの両方を用いる\n",
    "みたいなことが考えられると思います。GANの場合は後者です。\n",
    "要するに教師あり学習で学習されたNNと教師なし学習で学習されたNNの二つを使用していることになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二つのNNの役割\n",
    "\n",
    "では2つのNNの役割について説明します。名前から入った方がわかりやすいと思います。\n",
    "\n",
    "教師あり学習の方のNNはdiscriminator(判別器)　、教師なし学習の方のNNはgenerator(生成器)　と呼ばれています。\n",
    "\n",
    "以下で、それぞれのNNについて説明しますが、説明後に図が示してありますので焦らず．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator\n",
    "\n",
    "日本語で言うと生成器になります。何を生成するのかというと主に画像です。最初は画素値として完全に乱数で生成されます。以下のような画像です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/image1_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dicriminator\n",
    "\n",
    "日本語でいうと「判別器」です。名前の通り、判別します。何を判別するかというと、generatorから生成された画像が我々が持っている画像と同じものかどうかを判定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### アルゴリズム\n",
    "\n",
    "上の二つのNNを使って、我々が知っているような画像を得るためのアルゴリズムを以下に示します。\n",
    "\n",
    "- generatorが乱数で適当に画像を生成\n",
    "- discriminatorにより、1で作成された画像が学習データと同じものかどうか判定する\n",
    "\n",
    "\n",
    "**違うものとdiscriminatorが判定した場合**\n",
    "- generatorはより高精度な（訓練画像に似ている）画像を生成できるように学習する\n",
    "- 学習したgeneratorが画像を生成する\n",
    "- discriminatorにより、4で作成された画像が学習データと同じものかどうか判定する\n",
    "- 違うと判断されれば、また3に戻る。以後これを繰り返す。\n",
    "\n",
    "**訓練データと同じものとdiscriminatorが判定した場合**\n",
    "- discriminatorが見破ることができるようにdicriminatorが学習する。\n",
    "- genertorが生成した画像を再度判定する。\n",
    "- discriminatorが訓練データと同じものと判定した場合、再度見破ることができるようにdiscriminatorが学習する。なお無事に見破ることができた場合はgeneratorがより高精度な画像を生成するように学習する。\n",
    "\n",
    "以上のアルゴリズムからわかるように、二つのNNが相互に影響を及ぼしあいながら学習が進んでいます。まるで二つのNNが敵対（adversarial）しているようです。これが名前の由来になります。\n",
    "\n",
    "discriminatorが偽造紙幣を見破る警察、generatorが偽造紙幣を作る業者という例で説明されている記事もあります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/image1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## どのように学習するか？\n",
    "\n",
    "二つのNNが相互的に学習をしていくのはイメージできたかと思います。ここからは二つのNNがどのように学習していくのかを見ていきます。\n",
    "\n",
    "GANの損失関数は以下のように定義されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\mathrm{min}_{G}\\mathrm{max}_{D}V(D,G) = E_{x{\\sim}p_\\mathrm{data}(x)}[\\mathrm{log}D(x)]+ E_{z{\\sim}p_\\mathrm{z}(z)}[\\mathrm{log}(1-D(G(z)))] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今はこういうものだと思った方が良いと思います（特に，なぜlogを使っているのか）。理論的になぜこの損失関数でうまくいくのか説明している論文がありましたが，初めてGANが生まれた時は少なからず「仮説だけど，損失をこれで置いたらうまくいった」という部分があったことは頭に入れておいてください。\n",
    "\n",
    "- Dがうまく分類できると右辺第1項は、大きくなる。Dはdiscriminatorが学習データだと判断する確率。generatorという観点で見れば、バレることになるのでD(G(z))は小さくなります、要するに、log(1-D(G(z)))は大きくなるということです。\n",
    "- Gが訓練データと似ている画像を生成できるようになると、Dは間違えるので、D(G(z))は大きくなる。すなわち、log(1-D(G(z)))は小さくなる\n",
    "\n",
    "以上の1、2を繰り返し、DとGが相互に影響を及ぼしながら学習していきます。discriminator、generatorどちらか片方のlossを最大化もしくは最小化するのではなく、両方同時にというのがきもだと思います。だからこそ、右辺が2項に別れているわけです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 論文のコード\n",
    "\n",
    "ここでは、GANの原著論文に書かれているアルゴリズムを詳細に追っていこうと思います。\n",
    "\n",
    "[https://arxiv.org/pdf/1406.2661.pdf](https://arxiv.org/pdf/1406.2661.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/image1_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator(判別器)の更新式\n",
    "\n",
    "- 事前確率分布$p_g(z)$ からミニバッチ分の $Z(z_1$~$z_m)$ を生成します  \n",
    "→実際には1枚の画像のピクセル数×バッチ枚数分のノイズ\n",
    "\n",
    "- 学習データXから$x_1$~$x_m$（1で取り出したバッチ枚数)だけ取り出します  \n",
    "→この時の事前分布は1と同じである必要があります。要するに1でノイズを生成する時に正規分布に基づいてノイズをサンプリングしているなら、学習データをサンプリングする際も、同じ確率分布（今は正規分布）でサンプリングする必要があります。\n",
    "\n",
    "- SGD（確率的勾配降下法）によりdiscriminatorを更新する  \n",
    "各画像（1バッチ）に対して毎回更新ではなく、バッチ枚数ごとのlossを足してそれをmで割っているので、更新には、平均が用いられていると考えて良いでしょう。GANのデメリットに「学習時における、収束の不安定さ」が取り上げられますが、それがこの式からイメージできると思います。バッチ枚数が多ければ多いほど、各画像におけるLossの偏差は小さくなるので、学習を速くしたい場合、バッチサイズを大きくすれば良さそうですが、そうすると、1エポックにかかる時間が多くなるので、ビミョーなところだと言えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/image1_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "式1〜mのばらつきはmが大きくなるにつれて、小さくなりますが、バッチ内で学習を安定化させるためにmを大きくするとバッチが変わる度にバッチの特徴を表現した平均値が更新されるので、サンプリングされた画像が全く異なれば、次に生成される画像はうまく更新を反映できない（学習が進んだ後でも変な画像が時々生成されるのはこのため）可能性あります。\n",
    "\n",
    "バッチを大きくすると、メモリの使用量が大きくなるデメリットがありますが、計算時間の効率化や比較的安定しやすいというメリットがあります。なのでGANにおける学習ではバッチサイズは大きめにしておくのがセオリーと言えます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generator(生成器)の更新式\n",
    "\n",
    "- 事前分布$p_g(z)$からバッチサイズ分のノイズ（画素数×バッチサイズ）をサンプリング\n",
    "- 以下の式によりgeneratorを更新する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/image1_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上式の$D(G(z^{(i)}))$はノイズzがGに入力されgeneratorが画像を生成し、その画像をdiscriminatorに入力として与えられ、そしてそれが本物（トレインの画像）かどうかを判断する部分です。\n",
    "\n",
    "generatorは最小化したいので（最初のLossの式参照）、$1-D(G(z^{(i)}))\\simeq 0$となるように最適化していきます。要するに，似ている画像をgeneratorが生成するようになると、$D(G(z^{(i)}))$は1に近づく。\n",
    "\n",
    "$1 - D(G(z^{(i)}))$を各画像に対して計算し、mごと（ミニバッチごと）の平均をそのバッチにおける更新量とします。\n",
    "\n",
    "以上で述べた片方を最小化、片方は最大化というフローに乗っ取り、両者（両DNN）の均衡点を探すのがGANのオリジナリティと言えます。\n",
    "\n",
    "次はフレームワークを使ってGANの実装を見ていきましょう。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
