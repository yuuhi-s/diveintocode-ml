{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQt679Z6Q7z3"
   },
   "source": [
    "# Sprint21課題 セグメンテーション2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsrziobuQ7z4"
   },
   "source": [
    "## この課題の目的\n",
    "\n",
    "- セグメンテーションの精度を改善する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uEGs4aadQ7z5"
   },
   "source": [
    "## セグメンテーションの精度向上\n",
    "\n",
    "前回に引き続きTGS Salt Identification Challengのデータセットの学習・推定を行います。\n",
    "\n",
    "[TGS Salt Identification Challenge | Kaggle](https://www.kaggle.com/c/tgs-salt-identification-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mm33bbCGQ7z5"
   },
   "source": [
    "## 【問題1】コードレビュー\n",
    "\n",
    "転移学習を使用してセグメンテーションの精度を改善したコードを提示するので、レビューを行ってください。\n",
    "\n",
    "視点例\n",
    "\n",
    "- Sprint20で使用した実装とはどのように違うのか\n",
    "- 転移学習をどのように行っているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "me0a3agWQ7z6"
   },
   "source": [
    "１つめのはDIVERの問題で使用\n",
    "\n",
    "2つめのはコードレビュー"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwYd3ksBQ7z6"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJkOOpfLQ7z7",
    "outputId": "5b5a6a93-fa36-4847-bb6f-9db822def89c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dy6BTvgLQ7z_"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSbrCWrZQ70B"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    #クラスを求める\n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    #塩分被覆率を追加\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    \n",
    "    #クラスを追加\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fu8ukkyNQ70D"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p__W60pDQ70D",
    "outputId": "4eccf152-dd99-493e-cd86-1a3786abef1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "#データのパス\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/sample_submission.csv')\n",
    "depth = pd.read_csv('../input/depths.csv')\n",
    "\n",
    "train_src = '../input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "#depthをマージ\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRPPrP0yQ70J"
   },
   "source": [
    "### Load images and masks, examine random sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FCzZaIHOQ70J",
    "outputId": "f6d55c6b-eefb-403f-ad2b-2b704267925a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "#画像の呼び出し、正規化\n",
    "X_train = np.asarray(\n",
    "    [cv2.imread('../input/train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('../input/train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "#shapeの出力\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVXqIWeDQ70M",
    "outputId": "e4c437ce-d800-4920-c938-92f47f0976ef",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6a59c4dd68>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#あるidの画像をランダムに出力\n",
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDVVzH_7Q70O"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1GP378wQ70P"
   },
   "outputs": [],
   "source": [
    "#塩分被覆率とクラスを追加\n",
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xWIGgRHgQ70Q"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI3JSi3fQ70R",
    "outputId": "9321cbea-37d4-4912-dff5-6e5240d61648"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "#チャンネル数を追加\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# ResNet50のデフォルトサイズにresize()\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "#一番後ろの軸に次元を増やす\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FefdmjYeQ70T"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79RQXL2cQ70U"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "#------------------------------------------Loss-------------------------------------------------------\n",
    "#BCEとDice係数を組み合わせたもの\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    #A : label\n",
    "    #B : pred\n",
    "    \n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "'''\n",
    "評価関数 : IoU\n",
    "ある物体Aが実際にAである、もしくはモデルがAであると予想した領域の内、\n",
    "モデルが正しくAであることを認識できた領域(TP)がどの程度かを表したもの。\n",
    "'''\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bMZ5vH8Q70V"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3YLcGiGowTu"
   },
   "outputs": [],
   "source": [
    "base_model = ResNet50(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NQfumaoQ70W"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTk7k9SLQ70X"
   },
   "outputs": [],
   "source": [
    "# 基本的なデコーダー : Conv, BN, PReLU\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "    \n",
    "    #畳み込み\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    \n",
    "    #BN : バッチごとに前の層の出力を正規化\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    \n",
    "    #活性化関数\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "  \n",
    "#真ん中の畳み込み層のフィルター数が最初と最後の半分\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "    \n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "    \n",
    "    #フィルターの数が半分\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIl_bbqfQ70Z"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hy-J0xtUQ70Z"
   },
   "outputs": [],
   "source": [
    "#U-Net, ResNetを組み合わせる\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    #Base_model エンコーダー\n",
    "    #include_top : 全結合層を含まない\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    #エンコーダー部分(ResNet50)\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    #中間部分(オリジナル)\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    #デコーダー部分(オリジナル)\n",
    "    #エンコーダー部分を結合\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    #出力\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "    \n",
    "    #モデル\n",
    "    model = Model(base_model.input, output)\n",
    "    #コンパイル\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ANllCbrQ70b"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjL3NpTIQ70c",
    "outputId": "1f8b0eb6-9090-4ebe-a1de-97ed400bc705",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/anaconda3/envs/idp3exp/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#imagenetで学習した重みを使用\n",
    "model = unet_resnet(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3E2iETPPQ70e"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ayB5_0CyQ70f"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "#モデル\n",
    "#dice and BCEのときはmy_iou_metric、lovash_lossの場合はmy_iou_metric2を使用\n",
    "#lovash_lossの場合は最後の層(sigmoid)を削除\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "#チェックポイント\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "\n",
    "#コールバック(評価値が改善されないときに学習率を下げる)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2 \n",
    "batch_size = 16\n",
    "\n",
    "#学習\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UuyS4n8lQ70i"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QdsUAqI3Q70j"
   },
   "outputs": [],
   "source": [
    "#推定\n",
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "#元のサイズ(101 * 101)にresize\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GzHM08JeQ70m"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kobnskq9Q70n"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    #ヒストグラムの作成\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    \n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SIrPdjeHQ70q",
    "outputId": "e4314ef1-513f-4599-8000-d3c57572bade"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:35<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "#しきい値の配列\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "#しきい値ごとにIoUを求める\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9_fV9pMQ70s",
    "outputId": "17854618-419e-4392-a785-946946b5487d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.2805 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.223362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.021597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.206841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.209080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.211940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.228545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.280473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.223362\n",
       "std     0.204939   0.021597\n",
       "min     0.200000   0.206841\n",
       "25%     0.370000   0.209080\n",
       "50%     0.540000   0.211940\n",
       "75%     0.710000   0.228545\n",
       "max     0.880000   0.280473"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# IoUが一番良い時のしきい値を出力\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# IoUのdescribe\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuVI3uaKQ70u",
    "outputId": "bc3825e4-930c-417a-db32-514e71b74c86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a593a98d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 縦軸にしきい値、横軸にIoU\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Gwg7chMQ70w"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XH1DJgDlQ70w"
   },
   "source": [
    "https://www.kaggle.com/c/tgs-salt-identification-challenge/discussion/66465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxFQr_EkQ70x"
   },
   "source": [
    "### Sprint20との違い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYs1RI_PQ70x"
   },
   "source": [
    "- モデルの構成\n",
    "    - sprint20  \n",
    "    U-Net  \n",
    "    入力部分(Conv + Conv + MaxPool)  \n",
    "    ↓  \n",
    "    ダウンサンプリング(Conv + Conv + (Drop) + MaxPool)$\\times$3  \n",
    "    ↓  \n",
    "    中間(Conv + Conv + Drop + UpConv)  \n",
    "    ↓  \n",
    "    アップサンプリング(Concat + Conv + Conv + UpConv)$\\times$3  \n",
    "    ↓  \n",
    "    出力(Concat + Conv + Conv + Conv + Conv)  \n",
    "    \n",
    "    - 今回  \n",
    "    U-Netの入力~ダウンサンプリング(input_1~activation49)がResNet50となっている。  \n",
    "    アップサンプリング~出力ではオリジナルのU-Netモデルを作成。  \n",
    "        - decoder_block_simple(Conv + BatchNormalization + PReLu)\n",
    "        - decoder_block_bottleneck((Conv + BatchNormalization + PReLu + DropOut)$\\times$3 + Add)(真ん中はフィルタサイズが半分)  \n",
    "        の2種類から選べるようになっている。(詳細は下記summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjL3NpTIQ70c",
    "outputId": "1f8b0eb6-9090-4ebe-a1de-97ed400bc705",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/w/anaconda3/envs/idp3exp/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           center_activation[0][0]          \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 42,912,065\n",
      "Trainable params: 42,856,833\n",
      "Non-trainable params: 55,232\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Activation\n",
    "    - sprint20 : ReLu(outputはsigmoid)\n",
    "    - 今回 : PReLu(outputはsigmoid)\n",
    "    \n",
    "    \n",
    "- Optimizer  \n",
    "    - sprint20 : Adam\n",
    "    - 今回 : Adam\n",
    "\n",
    "\n",
    "- 評価関数  \n",
    "    - sprint20 : accuracy\n",
    "    - 今回 : IoU\n",
    "\n",
    "\n",
    "- 損失関数\n",
    "    - sprint20 : binary_crossentropy\n",
    "    - 今回 :   \n",
    "        - デフォルト : binary_crossentropy  \n",
    "        - 学習時 : binary_crossentropyとDiceの類似度係数を組み合わせたもの\n",
    "\n",
    "\n",
    "- 重み\n",
    "    - sprint20 : ランダム初期値(重みがあればKerasのload_weightsでロード)\n",
    "    - 今回 : imagenetで学習した重み\n",
    "    \n",
    "    \n",
    " - 学習率の変動\n",
    "    - sprint20 : 一定\n",
    "    - 今回 : KerasのReduceLROnPlateau()により、学習が進むと変化する機能あり。  \n",
    "    IoUの上昇が5エポック止まれば、学習率に0.5をかけたものを新しい学習率とする。下限は0.0001\n",
    "    \n",
    "    \n",
    " - input size\n",
    "    - sprint20 : 256$\\times$256$\\times$チャンネル数(デフォルト1)\n",
    "    - 今回 : 224$\\times$224$\\times$チャンネル数(デフォルト3)\n",
    "    \n",
    "    \n",
    " - output size\n",
    "    - sprint20 : 256$\\times$256$\\times$1\n",
    "    - 今回 : 224$\\times$224$\\times$1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P3BDT4HlQ70y"
   },
   "source": [
    "### 転移学習をどのようにおこなっているか"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t70V0aUNQ705"
   },
   "source": [
    "- input ~ activation49までResNet50モデル、center以降はdecoder_block_simple or decoder_block_bottleneckを使用。\n",
    "\n",
    "- エンコーダーのactivation_1, activation_10, activation_22, activation_40, activation_49をデコーダーに結合している。これは画像のサイズが小さくなる前の部分を抜き出してあると思われる。\n",
    "\n",
    "- 学習時の重みはimagenetで学習した重みを使用している。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mMI0Ie-JQ706"
   },
   "source": [
    "## 【問題2】コードの書き換え\n",
    "\n",
    "エンコーダーにResNetが使用されていたコードをVGGに変更してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhawl139Q706"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    #Base_model エンコーダー\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    #エンコーダー部分(VGG16)\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output\n",
    "    encoder6 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    #中間部分(オリジナル)\n",
    "    center = decoder_block(\n",
    "        encoder6, 'center', num_filters=512)\n",
    "    concat6 = concatenate([center, encoder6], axis=-1)\n",
    "    \n",
    "\n",
    "    #デコーダー部分(オリジナル)\n",
    "    #エンコーダー部分を結合\n",
    "    decoder5 = decoder_block(\n",
    "        concat6, 'decoder5', num_filters=512)\n",
    "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
    "\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=512)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=256)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=128)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    #出力\n",
    "    #output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2040
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2228,
     "status": "ok",
     "timestamp": 1560931373754,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "mQHvLwuaQ708",
    "outputId": "a43083dd-970f-4a72-99bf-cbe1c2f04bb9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv (Conv2D)          (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn (BatchNormalization (None, 7, 7, 512)    2048        decoder5_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation (PReLU)     (None, 7, 7, 512)    25088       decoder5_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           decoder5_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 14, 14, 512)  2048        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 14, 14, 512)  100352      decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 28, 28, 256)  1024        decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 28, 28, 256)  200704      decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 56, 56, 128)  512         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 56, 56, 128)  401408      decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 112, 112, 64) 256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 112, 112, 64) 802816      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 36896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 32,815,809\n",
      "Trainable params: 32,811,777\n",
      "Non-trainable params: 4,032\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "#imagenetで学習した重みを使用\n",
    "model = unet_vgg(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NdPwFsjQ70-"
   },
   "source": [
    "## 【問題3】学習・推定\n",
    "\n",
    "ResNetとVGG双方のコードで学習・推定を行い、結果を比較してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2982,
     "status": "ok",
     "timestamp": 1560920073168,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "-tsciICHRPDi",
    "outputId": "69edd13e-7178-48d1-c7eb-6308f9771df8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12503,
     "status": "ok",
     "timestamp": 1560920082702,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "o2hn2hJDQ70-",
    "outputId": "905fe321-ab4c-4496-8dd0-92f633a43d56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7793b702-1979-4ecd-a6db-1f4520fa4f20\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-7793b702-1979-4ecd-a6db-1f4520fa4f20\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kaggle.json': b'{\"username\":\"yuhisoejima\",\"key\":\"2634857713af1415f450cf49bef0ce5f\"}'}"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ファイルをアップロード\n",
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gUwkMFEVQ71A"
   },
   "outputs": [],
   "source": [
    "#kaggleフォルダを作成し、そこにjsonをコピーする\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T6qY3cDoQ71D"
   },
   "outputs": [],
   "source": [
    "#アクセスパーミッション\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21322,
     "status": "ok",
     "timestamp": 1560920091545,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "WDqthnSNQ71F",
    "outputId": "b488d699-d4db-4ecc-fb3f-696913c3aaf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading depths.csv to /content\n",
      "\r",
      "  0% 0.00/322k [00:00<?, ?B/s]\n",
      "100% 322k/322k [00:00<00:00, 48.9MB/s]\n",
      "Downloading sample_submission.csv to /content\n",
      "  0% 0.00/264k [00:00<?, ?B/s]\n",
      "100% 264k/264k [00:00<00:00, 80.7MB/s]\n",
      "Downloading train.csv to /content\n",
      "  0% 0.00/922k [00:00<?, ?B/s]\n",
      "100% 922k/922k [00:00<00:00, 60.2MB/s]\n",
      "Downloading test.zip to /content\n",
      "100% 163M/163M [00:01<00:00, 138MB/s]\n",
      "100% 163M/163M [00:01<00:00, 125MB/s]\n",
      "Downloading train.zip to /content\n",
      " 66% 25.0M/37.9M [00:00<00:00, 50.9MB/s]\n",
      "100% 37.9M/37.9M [00:00<00:00, 85.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "#kaggleデータの読み込み\n",
    "!kaggle competitions download -c tgs-salt-identification-challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JcjerQl8Q71G"
   },
   "outputs": [],
   "source": [
    "#学習データの解凍\n",
    "!unzip train.zip -d train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J1CO9Lg4Q71I"
   },
   "outputs": [],
   "source": [
    "#テストデータの解凍\n",
    "!unzip test.zip -d test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nsh7KQnZQ71J"
   },
   "outputs": [],
   "source": [
    "#推定した画像を保存するディレクトリ\n",
    "!mkdir 'test/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pe7Fg2jOShGZ"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0tyIO6AQ71O"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    #クラスを求める\n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    #塩分被覆率を追加\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    \n",
    "    #クラスを追加\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35161,
     "status": "ok",
     "timestamp": 1560920105424,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "vGu9-vPWSlIo",
    "outputId": "bfba5226-b7cd-4f04-dcc1-589606c82998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('sample_submission.csv')\n",
    "depth = pd.read_csv('depths.csv')\n",
    "\n",
    "train_src = 'train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37099,
     "status": "ok",
     "timestamp": 1560920107368,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "taQlDLsgTLLI",
    "outputId": "516675c1-3a42-43b8-98ab-58c039305859"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 101, 101) (4000, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('train/images/{}.png'.format(x), 0) for x in train.id.tolist()], \n",
    "    dtype=np.uint8) / 255.\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('train/masks/{}.png'.format(x), 0) for x in train.id.tolist()],\n",
    "    dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 37804,
     "status": "ok",
     "timestamp": 1560920108078,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "kJ_HHGw9TJcp",
    "outputId": "7030d8e2-a52b-4103-f3b5-df95bd4fc1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f74e83de080>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfGkWEREREZnBl2YRERERkRn+f01ToVritxuKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kq1PGzSUVIFb"
   },
   "outputs": [],
   "source": [
    "#塩分被覆率とクラスを追加\n",
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56240,
     "status": "ok",
     "timestamp": 1560920126527,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "YY1XWVnUTWm8",
    "outputId": "865de44b-3587-4a74-b4c1-ad6ed7f2e438"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3196, 224, 224, 3) (3196, 224, 224, 1)\n",
      "(804, 224, 224, 3) (804, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQ46wJF-Q71R"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    #A : label\n",
    "    #B : pred\n",
    "    \n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "'''\n",
    "評価関数\n",
    "'''\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKZsDMCHQ71S"
   },
   "outputs": [],
   "source": [
    "# 基本的なデコーダー : Conv, BN, PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "    \n",
    "    #畳み込み\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    \n",
    "    #BN : バッチごとに前の層の出力を正規化\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    \n",
    "    #活性化関数\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "#真ん中の畳み込み層のフィルター数が最初と最後の半分\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "    \n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "    \n",
    "    #フィルターの数が半分\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13UuCUieQ71U"
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2pvv2gAQ71V"
   },
   "outputs": [],
   "source": [
    "#U-Net, ResNetを組み合わせる\n",
    "def unet_resnet(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    #Base_model エンコーダー\n",
    "    #include_top : 全結合層を含まない\n",
    "    base_model = ResNet50(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    #エンコーダー部分(ResNet50)\n",
    "    encoder1 = base_model.get_layer('activation_1').output\n",
    "    encoder2 = base_model.get_layer('activation_10').output\n",
    "    encoder3 = base_model.get_layer('activation_22').output\n",
    "    encoder4 = base_model.get_layer('activation_40').output\n",
    "    encoder5 = base_model.get_layer('activation_49').output\n",
    "\n",
    "    #中間部分(オリジナル)\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    #デコーダー部分(オリジナル)\n",
    "    #エンコーダー部分を結合(スキップ結合)\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    #出力\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "    \n",
    "    #モデル\n",
    "    model = Model(base_model.input, output)\n",
    "    #コンパイル\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10509
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 643877,
     "status": "ok",
     "timestamp": 1560920714191,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "ZlQ2sigVQ71X",
    "outputId": "86bb970c-1730-4100-f5f6-323b31392a8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0619 04:55:26.502578 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0619 04:55:26.504489 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0619 04:55:26.552702 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0619 04:55:26.555290 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0619 04:55:26.565037 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0619 04:55:29.516474 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0619 04:55:29.609007 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0619 04:55:39.977414 140141626345344 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0619 04:55:40.663323 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0619 04:55:42.504986 140141626345344 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0619 04:55:42.537237 140141626345344 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0619 04:55:42.575569 140141626345344 deprecation.py:323] From <ipython-input-16-81e81042f225>:159: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    9437696     activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 2560)   0           add_17[0][0]                     \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    5898496     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1280) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  1474688     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 128 0           up_sampling2d_4[0][0]            \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 128 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 48,978,353\n",
      "Trainable params: 48,919,953\n",
      "Non-trainable params: 58,400\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "3196/3196 [==============================] - 266s 83ms/step - loss: 0.7343 - my_iou_metric: 0.3348 - val_loss: 3.1331 - val_my_iou_metric: 0.1754\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.17537, saving model to unet_resnet.h5\n",
      "Epoch 2/2\n",
      "3196/3196 [==============================] - 234s 73ms/step - loss: 0.5629 - my_iou_metric: 0.5031 - val_loss: 0.6781 - val_my_iou_metric: 0.3776\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.17537 to 0.37761, saving model to unet_resnet.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "#モデル\n",
    "model_depth = unet_resnet(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "#チェックポイント\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_resnet.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  \n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "me3lDMtOQ71Z"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEH5IkTbQ71b"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708583,
     "status": "ok",
     "timestamp": 1560920778917,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "qUPEcKvcQ71c",
    "outputId": "1dbae985-9e82-4755-ffde-7a34a6618ad9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:47<00:00,  1.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708577,
     "status": "ok",
     "timestamp": 1560920778919,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "t6M9jcRAQ71d",
    "outputId": "8b433b7c-7475-427c-98bd-d683da2f7cbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.4963 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.399236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.048970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.313930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.362935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.394527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.430100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.496269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.399236\n",
       "std     0.204939   0.048970\n",
       "min     0.200000   0.313930\n",
       "25%     0.370000   0.362935\n",
       "50%     0.540000   0.394527\n",
       "75%     0.710000   0.430100\n",
       "max     0.880000   0.496269"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708899,
     "status": "ok",
     "timestamp": 1560920779246,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "Ml3siCAFQ71e",
    "outputId": "dd6b799a-2c44-4c1a-d8cd-2720e3c95021"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f74e5b68e80>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtMAAAIaCAYAAADiE8FNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8V9Xh//H3ySITQiAESAIJgbB3\nCLjAheKoe4A4cOGitbVV+62zalu11tU6igNQltYFbkVFRQUSNoQVAmQwk0BC9vic3x988JdShABJ\n7me8no9HHvC5n3tv3p+HSt4czz3HWGsFAAAA4OgFOB0AAAAA8FaUaQAAAOAYUaYBAACAY0SZBgAA\nAI4RZRoAAAA4RpRpAAAA4BhRpgEAAIBjRJkGAAAAjhFlGgAAADhGlGkAAADgGAU5HeBotG/f3iYl\nJTkdAwAAAD5syZIlhdba2Mac61VlOikpSZmZmU7HAAAAgA8zxmxt7LlM8wAAAACOEWUaAAAAOEaU\naQAAAOAYedWcaQAAADivtrZW+fn5qqqqcjrKcQkNDVVCQoKCg4OP+R6UaQAAAByV/Px8RUVFKSkp\nScYYp+McE2utioqKlJ+fr+Tk5GO+D9M8AAAAcFSqqqrUrl07ry3SkmSMUbt27Y57dJ0yDQAAgKPm\nzUX6gKb4DI0q08aYMcaY9caYbGPMHw/x/gRjzG5jzHL3100N3rvOGLPR/XVdg+NDjTGr3Pd83vjC\nPxEAAAC0iBNPPNHpCJIaUaaNMYGSXpB0jqQ+ksYZY/oc4tS3rLWD3F+vuq+NkfSQpOGS0iU9ZIxp\n6z7/JUk3S+rh/hpzvB8GAAAA/uHHH390OoKkxo1Mp0vKttbmWGtrJM2WdGEj73+2pC+ttcXW2j2S\nvpQ0xhjTSVJra+1Ca62V9Iaki44hPwAAAPxQZGSkpP0PEt59993q16+f+vfvr7feekuSNH/+fJ1/\n/vk/nz9p0iRNnTq1yXM0ZjWPeEl5DV7na/9I88EuNcaMlLRB0u+stXm/cG28+yv/EMcBAADgRf78\n4RplbStt0nv26dxaD/2qb6POfe+997R8+XKtWLFChYWFGjZsmEaOHNmkeQ6nqR5A/FBSkrV2gPaP\nPk9rovvKGDPRGJNpjMncvXt3U90WAAAAPmDBggUaN26cAgMDFRcXp1GjRikjI6PFvn9jRqYLJCU2\neJ3gPvYza21Rg5evSnqywbWnHnTtfPfxhMPds8G9J0uaLElpaWm2EXkBAADQQho7gtzSgoKC5HK5\nfn7dXBvMNGZkOkNSD2NMsjEmRNJYSXMbnuCeA33ABZLWun//uaSzjDFt3Q8eniXpc2vtdkmlxpgR\n7lU8rpU05zg/CwAAAPzMKaecorfeekv19fXavXu3vvvuO6Wnp6tr167KyspSdXW19u7dq6+++qpZ\nvv8RR6attXXGmEnaX4wDJb1urV1jjHlEUqa1dq6k3xhjLpBUJ6lY0gT3tcXGmEe1v5BL0iPW2mL3\n72+XNFVSmKRP3V8AAABAo1188cX66aefNHDgQBlj9OSTT6pjx46SpCuuuEL9+vVTcnKyBg8e3Czf\n3+xfTMM7pKWl2czMTKdjAAAA+LW1a9eqd+/eTsdoEof6LMaYJdbatMZczw6IAAAAwDGiTAMAAADH\niDINAAAAuB3tFGjKNAAAAI6aNz1390sO9RmmL9x6VPegTAMAAOCohIaGqqioyKsLtbVWRUVFCg0N\n/fnYmm0levTjtYe56n81ZtMWAAAA4GcJCQnKz8+Xt+9OHRoaqoSE/fsIllfX6dczlyk6LPio7kGZ\nBgAAwFEJDg5WcnKy0zGa1ANzVmtLUblm3DRCJ97f+OuY5gEAAAC/9u6SfL23tEC/Pr2HTkhpd1TX\nUqYBAADgtzbtLtMDc1YrPTlGvz69+1FfT5kGAACAX6qqrdekmcvUKihAz48drKDAo6/GzJkGAACA\nX/rrJ2u1dnupXp+Qpo5tQo98wSEwMg0AAAC/89nq7Xrjp6266eRknd4r7pjvQ5kGAACAX8krrtA9\n76zUwIQ2umdMr+O6F2UaAAAAfqO23qXfzF4ma6V/jhuikKDjq8PMmQYAAIDf+McXG7Qsd6/+OW6w\nurQLP+77MTINAAAAv/Ddht16+dtNGpeeqF8N7Nwk96RMAwAAwOft2lelu95ertS4SD14ft8muy/T\nPAAAAODT6l1Wv3trucqq6zTr5hEKCwlssntTpgEAAODTXpqfrR+yi/TEpf3VIy6qSe/NNA8AAAD4\nrIwtxXr6yw26YGBnXZGW2OT3p0wDAADAJ+0pr9FvZi1TYky4/nJxPxljmvx7MM0DAAAAPsdaq7vf\nWanCsmq9e9uJigoNbpbvw8g0AAAAfM7UH7do3tqd+uM5vTUgIbrZvg9lGgAAAD5ldUGJ/vbJOp3Z\nu4NuOCmpWb8XZRoAAAA+o6y6TpNmLlW7yBD9/bKBzTJPuiHmTAMAAMAnWGt13/urlFtcodkTT1Db\niJBm/56MTAMAAMAn/CczX3OWb9Nvz0xVenJMi3xPyjQAAAC8XvaufXpw7mqdmNJOd5zWvcW+L2Ua\nAAAAXq2qtl53zFimiJAgPXvlIAUGNO886YaYMw0AAACvZa3Vnz/M0vqd+zT1+mHq0Dq0Rb8/ZRoA\nAABep6q2XnOWF+jV7zdr464y3TKqm07t2aHFc1CmAQAA4DWKyqr15sKtevOnrSoqr1GfTq319BUD\nddGgeEfyUKYBAADg8bJ37dNrCzbr3aUFqqlz6fReHXTTKck6oVu7Zl9L+nAo0wAAAPBI1lr9uKlI\nr36fo2/W71aroABdNjRBN5yUrO4dIp2OJ4kyDQAAAA9TU+fShyu26dUFm7V2e6naR4bortGpGj+8\ni9pFtnI63n+hTAMAAMAj7K2o0YxFuZr24xbt2let1LhIPXnpAF0wqLNCgwOdjndIlGkAAAA4anNh\nuV5fsFnvLMlXZW29TunRXn+/fKBG9mjv6HzoxqBMAwAAoMVZa5WxZY9e+T5H89buVHBAgC4c1Fk3\nnpKsXh1bOx2v0SjTAAAAaFHfrN+lZ77coJX5JWobHqxJp3XXNSd0VYeolt1wpSlQpgEAANBivlm/\nSzdNy1Ri2zA9dlE/XTokQWEhnjkfujEo0wAAAGgRqwtKdMeMperVMUpv3XKCIlt5fxUNcDoAAAAA\nfF9ecYWun5qhtuEhmjJhmE8UaYmRaQAAADSzkopaXT81Q9W19Zp503B1aO19c6N/CWUaAAAAzaa6\nrl43v5mp3KIKvXFjunrERTkdqUlRpgEAANAsXC6rP/xnpRZvLtZzYwdpRLd2TkdqcsyZBgAAQLN4\n8vP1+nDFNt07ppcuHBTvdJxmQZkGAABAk3tz4Va9/O0mXT2ii24d1c3pOM2GMg0AAIAmNS9rpx6a\ns1pn9Oqgh3/V1+O3BD8elGkAAAA0mRV5e/XrWcvUL76N/nnVYAUF+nbd9O1PBwAAgBaTW1ShG6dl\nqH1UiF67bpjCQ3x/rQvKNAAAAI7bnvIaTZiyWHUuq6nXpys2qpXTkVqE7/91AQAAAM2qqrZeN7+R\nqfy9lZpx03ClxEY6HanFNGpk2hgzxhiz3hiTbYz542HOu9QYY40xae7X440xyxt8uYwxg9zvzXff\n88B7HZrmIwEAAKCluFxWd729XEty9+iZKwZpWFKM05Fa1BFHpo0xgZJekDRaUr6kDGPMXGtt1kHn\nRUm6U9KiA8estTMkzXC/31/SB9ba5Q0uG2+tzTzuTwEAAABH/PWTtfpk1Q7df15vnTegk9NxWlxj\nRqbTJWVba3OstTWSZku68BDnPSrpCUlVv3Cfce5rAQAA4AOm/LBZry7YrAknJunGk5OdjuOIxpTp\neEl5DV7nu4/9zBgzRFKitfbjw9znSkmzDjo2xT3F4wHjywsQAgAA+JjPVu/QIx9l6aw+cXrg/D4+\nvZb04Rz3ah7GmABJT0v6/WHOGS6pwlq7usHh8dba/pJOcX9d8wvXTjTGZBpjMnfv3n28cQEAAHCc\nlmzdoztnL9OgxGg9N3awAgP8s0hLjSvTBZISG7xOcB87IEpSP0nzjTFbJI2QNPfAQ4huY3XQqLS1\ntsD96z5JM7V/Osn/sNZOttamWWvTYmNjGxEXAAAAzWVzYblumpahTm1C9eq1aQoLCXQ6kqMaU6Yz\nJPUwxiQbY0K0vxjPPfCmtbbEWtveWptkrU2StFDSBQceLHSPXF+hBvOljTFBxpj27t8HSzpfUsNR\nawAAAHiYorJqTZiyWMYYTb0+Xe0i/WMt6cM54moe1to6Y8wkSZ9LCpT0urV2jTHmEUmZ1tq5h7+D\nRkrKs9bmNDjWStLn7iIdKGmepFeO6RMAAACg2VXW1OvGaZnaUVKlWRNHKKl9hNORPIKx1jqdodHS\n0tJsZiYr6QEAALSkepfVbdOX6Mu1O/XS+KEa06+j05GalTFmibU27chnsp04AAAADqOqtl53vb1c\nX2Tt1IPn9/H5In202E4cAAAAh7SjpEoT38zUyvwS3TOmp64/yT/Xkj4cyjQAAAD+x9LcPbrlzSWq\nqK7TK9emaXSfOKcjeSTKNAAAAP7LfzLzdN/7q9UpOlQzbhqu1LgopyN5LMo0AAAAJEl19S795ZO1\nmvLDFp3cvb3+ddVgRYeHOB3Lo1GmAQAAoL0VNZo0c5kWZBfq+pOSdN+5vRUUyFoVR0KZBgAA8HMb\ndu7TzW9kavveKj152QBdkZZ45IsgiTINAADg1+Zl7dSds5cpLCRIsyaO0NCubZ2O5FUo0wAAAH7I\nWqsX52/SU1+sV7/ObTT52qHq1CbM6VhehzINAADgZypr6nX3Oyv00crtunBQZz1x6QCFBgc6Hcsr\nUaYBAAD8SMHeSk18I1NZ20v1x3N66ZaR3WSMcTqW16JMAwAA+ImMLcW69c0lqqlz6fXrhum0Xh2c\njuT1KNMAAAB+YNbiXD04Z7US24Zr8rVp6t4h0ulIPoEyDQAA4MNq61169KMsvfHTVo1KjdXz4war\nTViw07F8BmUaAADARxWX1+iOGUv1U06RJo7spnvH9FJgAPOjmxJlGgAAwAet21Gqm6Zlate+aj19\nxUBdMiTB6Ug+iTINAADgY5bn7dVVryxUVGiQ3r7lBA1KjHY6ks+iTAMAAPiQXfuqdMubmYqJCNG7\nt52ouNahTkfyaZRpAAAAH1FT59Lt05eqpLJW7912EkW6BVCmAQAAfMQjH61R5tY9en7cYPXp3Nrp\nOH4hwOkAAAAAOH5vZeRq+sJc3TKymy4Y2NnpOH6DMg0AAODllubu0QMfrNEpPdrrnjG9nI7jVyjT\nAAAAXmxXaZVum75EHduE6p/jBrOOdAtjzjQAAICXqqlz6bYZS1VaWaf370hXdHiI05H8DmUaAADA\nSz384Rot2bpH/7pqsHp15IFDJzDNAwAAwAvNWpyrmYtydeuoFJ0/gAcOnUKZBgAA8DJLtu7Rg3NW\na2RqrO4+u6fTcfwaZRoAAMCL7HQ/cNipTZieHzuIBw4dRpkGAADwEtV19bpt+hKVVddp8rVDeeDQ\nA/AAIgAAgJd4eG6Wlubu1Yvjh/DAoYdgZBoAAMALzFi0VbMW5+r2U1N0bv9OTseBG2UaAADAw2Vu\nKdbDc9fo1J6x+v1ZPHDoSSjTAAAAHmxnaZVum7FUnaPD9NyV7HDoaZgzDQAA4KGq6+p16/QlKq+u\n0/Qbh6tNeLDTkXAQyjQAAIAHstbqoTlrtCx3r14aP0Q9O0Y5HQmHwDQPAAAADzRjUa5mZ+Rp0mnd\ndQ4PHHosyjQAAICHydhSrD9/uEan9YzV70anOh0Hh0GZBgAA8CDbSyp12/SlSmgbrmfH8sChp2PO\nNAAAgIeoqq3XrdOXqrKmTrNuHq42YTxw6Oko0wAAAB7AWqsH56zWiry9evnqoeoRxwOH3oBpHgAA\nAB5g+sKtejszX78+vbvG9OvodBw0EmUaAADAYd+s36WHP8zS6b066Hdn8sChN6FMAwAAOGhl/l7d\nPn2penWM0vPjBiuABw69CmUaAADAIVuLynXD1Ay1iwzRlOuHKbIVj7N5G8o0AACAA4rKqnXd64tV\n77KadkO6OkSFOh0Jx4C//gAAALSwipo63TAtU9tLqjTz5hFKiY10OhKOESPTAAAALaiu3qVfz1ym\nVfl79c9xgzW0a1unI+E4MDINAADQQqy1emDOan21bpceu6ifzurLEnjejpFpAACAFvL8V9matThP\nk07rrqtHdHU6DpoAZRoAAKAFvJ2Rp2fmbdClQxL0+7NYS9pXUKYBAACa2Tfrdun/3l+lkamxevzS\n/jKGtaR9BWUaAACgGa3I26vbZyxV705RenH8EAUHUr98SaP+aRpjxhhj1htjso0xfzzMeZcaY6wx\nJs39OskYU2mMWe7+ernBuUONMavc93ze8Fc0AADgYxpuyvL6BDZl8UVH/CdqjAmU9IKk0ZLyJWUY\nY+Zaa7MOOi9K0p2SFh10i03W2kGHuPVLkm52n/+JpDGSPj3qTwAAAOCBCsuqde3ri+WybMriyxoz\nMp0uKdtam2OtrZE0W9KFhzjvUUlPSKo60g2NMZ0ktbbWLrTWWklvSLqo8bEBAAA8V0VNnW6cmqGd\npVV6bcIwNmXxYY0p0/GS8hq8zncf+5kxZoikRGvtx4e4PtkYs8wY860x5pQG98w/3D0BAAC8UV29\nS5NmLtOqghL9c9wQDenCpiy+7Lgn7hhjAiQ9LWnCId7eLqmLtbbIGDNU0gfGmL5Hef+JkiZKUpcu\nXY4zLQAAQPOx1ur+D1br63W79JeL+2l0nzinI6GZNWZkukBSYoPXCe5jB0RJ6idpvjFmi6QRkuYa\nY9KstdXW2iJJstYukbRJUqr7+oTD3PNn1trJ1to0a21abGxs4z4VAACAA577aqNmZ+Tp16d31/jh\nbMriDxpTpjMk9TDGJBtjQiSNlTT3wJvW2hJrbXtrbZK1NknSQkkXWGszjTGx7gcYZYzpJqmHpBxr\n7XZJpcaYEe5VPK6VNKdpPxoAAEDLeSsjV8/O26jLhibortFsyuIvjjjNw1pbZ4yZJOlzSYGSXrfW\nrjHGPCIp01o79zCXj5T0iDGmVpJL0q3W2mL3e7dLmiopTPtX8WAlDwAA4JW+XrdTf3p/tUamxupv\nl7Apiz8x+xfT8A5paWk2MzPT6RgAAAA/W5G3V2MnL1T3DpGaPXGEIlhL2usZY5ZYa9Macy5b8AAA\nAByjLYX7N2VpH7V/UxaKtP+hTAMAAByDwrJqXTfFvSnL9emKjWrldCQ4gL8+AQAAHKWv1+3Ufe+v\n1p6KGs28eYS6sSmL36JMAwAANFJRWbUe+ShLc5ZvU2pcpF66eqgGJUY7HQsOokwDAAAcgbVWc1ds\n058/zNK+qlr99sweuv3U7goJYsasv6NMAwAAHMa2vZU/72o4KDFaT142QKlxUU7HgoegTAMAAByC\ny2U1Y3Gunvh0nepdVg+c30cTTkxSYABrSOP/o0wDAAAcJGd3mf747iot3lKsk7u3198u6a/EmHCn\nY8EDUaYBAADcautdeuX7HD07b6NCgwL05GUDdPnQBHY0xC+iTAMAAEhaXVCie99dqTXbSnVOv476\n84V91SEq1OlY8HCUaQAA4Neqauv13FcbNfm7HMVEhOjlq4doTL9OTseCl6BMAwAAv7V4c7H++O5K\n5RSW64q0BN13bh+1CQ92Oha8CGUaAAD4nX1VtXris3WavjBXiTFhmn7jcJ3co73TseCFKNMAAMCv\nHNgKfGdplW46OVl3nZWq8BAqEY4N/+YAAAC/sK+qVvd/sPrnrcBfHH+iBndp63QseDnKNAAA8Hnl\n1XWaMCVDK/L2shU4mhRlGgAA+LTKmnrdOC1Dy/P26p/jBuvc/qzUgabDX8kAAIDPqqqt18Q3M7Vo\nc7GevmIgRRpNjjINAAB8Uk2dS3fMWKrvNxbqiUsH6MJB8U5Hgg+iTAMAAJ9TV+/Sb2Yt01frdumx\ni/rpirREpyPBR1GmAQCAT6l3Wd319gp9tmaHHji/j64e0dXpSPBhlGkAAOAzXC6re99dqbkrtune\nMb1048nJTkeCj6NMAwAAn2Ct1f1zVuudJfn67Zk9dNupKU5Hgh+gTAMAAK9nrdUjH2Vp5qJc3XZq\niu48o4fTkeAnKNMAAMCrWWv1+GfrNOWHLbrhpGTdc3ZPGWOcjgU/QZkGAABe7dl5G/Xvb3N09Ygu\neuD83hRptCjKNAAA8FovfJOt577aqMuHJuiRC/pRpNHiKNMAAMArvfp9jv7++XpdOKizHr90gAIC\nKNJoeZRpAADgdd78aYse+3itzunXUf+4fKACKdJwCGUaAAB4lbcz8vTAnDU6s3cHPTd2sIICqTNw\nDv/2AQAAr/HBsgLd+95KjUyN1QvjhygkiCoDZ/FvIAAA8Aofr9yuu95erhHJ7fTvq4eqVVCg05EA\nyjQAAPB8X2bt1J2zl2lIl7Z69bo0hYVQpOEZKNMAAMCjzV+/S3fMWKq+8W005fphimgV5HQk4GeU\naQAA4LF+zC7ULW8uUY+4SL1xfbqiQoOdjgT8F8o0AADwSP/JzNP1UzOU1C5Cb944XG3CKdLwPPx/\nEgAA4FGqauv18Nw1mp2RpxNT2umf4wYrJiLE6VjAIVGmAQCAx8gtqtBtM5ZozbZSTTqtu343OpUN\nWeDRKNMAAMAjzMvaqbveXi5Jeu26NJ3RO87hRMCRUaYBAICj6updevrLDXpx/ib1i2+tl8YPVWJM\nuNOxgEahTAMAAMfs3let38xapp9yijQuvYse+lUfhQazhjS8B2UaAAA4ImNLse6YsVQllbV66vKB\numxogtORgKNGmQYAAC3KWqvXFmzW3z5dp8S2YZp2Q7p6d2rtdCzgmFCmAQBAi9lXVat73lmpT1fv\n0Nl94/T3yweqNRuxwItRpgEAQItYt6NUt01fqtziCt13bm/ddEqyjGHZO3g3yjQAAGh27y3N15/e\nX6Wo0GDNvGm4hndr53QkoElQpgEAQLOpqq3XIx9laeaiXA1PjtE/rxqsDlGhTscCmgxlGgAANIu8\n4grdPmOpVhWU6NZRKfrDWakKCgxwOhbQpCjTAACgyX2zbpd++9ZyuazV5GuG6qy+HZ2OBDQLyjQA\nAGgy9S6rZ77coH99k63enVrr5auHqGu7CKdjAc2GMg0AAI6by2U1b+1O/eubbK3ML9HlQxP06EX9\n2M0QPo8yDQAAjlldvUsfrdyuF+dna8POMnWJCdczVw7UxYPZzRD+oVFl2hgzRtJzkgIlvWqtffwX\nzrtU0juShllrM40xoyU9LilEUo2ku621X7vPnS+pk6RK9+VnWWt3HcdnAQAALaS6rl7vLinQy99u\nUm5xhVLjIvXslYN0/oBOPGQIv3LEMm2MCZT0gqTRkvIlZRhj5lprsw46L0rSnZIWNThcKOlX1tpt\nxph+kj6XFN/g/fHW2szj/AwAAKCFlFfXadbiXL3yfY52llZrYEIb3X/eUJ3ZO04BAWzAAv/TmJHp\ndEnZ1tocSTLGzJZ0oaSsg857VNITku4+cMBau6zB+2skhRljWllrq48rNQAAaFElFbWa9tMWTflh\ns/ZU1OqEbu30j8sH6aTu7djFEH6tMWU6XlJeg9f5koY3PMEYM0RSorX2Y2PM3Tq0SyUtPahITzHG\n1Et6V9Jj1lrb+OgAAKC57d5XrVcX5Gj6T1tVXlOvM3p10O2nddfQrm2djgZ4hON+ANEYEyDpaUkT\nDnNOX+0ftT6rweHx1toC9/SQdyVdI+mNQ1w7UdJESerSpcvxxgUAAI2Qv6dCk7/L0VsZeaqtd+m8\nAZ1126gU9enc2ulogEdpTJkukJTY4HWC+9gBUZL6SZrv/t88HSXNNcZc4H4IMUHS+5KutdZuOnCR\ntbbA/es+Y8xM7Z9O8j9l2lo7WdJkSUpLS2PkGgCAZpS9q0wvzd+kOcsLZIx0yeAE3XpqipLbs1Y0\ncCiNKdMZknoYY5K1v0SPlXTVgTettSWS2h947V6l4w/uIh0t6WNJf7TW/tDgnCBJ0dbaQmNMsKTz\nJc1rgs8DAACOweqCEr04P1ufrt6hVkEBuuaErrr5lG7qHB3mdDTAox2xTFtr64wxk7R/JY5ASa9b\na9cYYx6RlGmtnXuYyydJ6i7pQWPMg+5jZ0kql/S5u0gHan+RfuU4PgcAADgGS7bu0fNfbdS3G3Yr\nqlWQbj81RdeflKz2ka2cjgZ4BeNNz/ylpaXZzExW0gMA4HityNurZ+Zt0Pz1uxUTEaIbT07WNSd0\nVevQYKejAY4zxiyx1qY15lx2QAQAwI+sLijRs/M2aN7aXYoOD9a9Y3rp2hO6KqIVlQA4FvyXAwCA\nH1i3o1TPfLlBn6/ZqdahQfrDWam67sQkRTESDRwXyjQAAD5s4859evarjfp45XZFtQrSnWf00A0n\nJ6tNGCUaaAqUaQAAfNCm3WV6/quNmrtim8KDAzXptO666ZRkRYeHOB0N8CmUaQAAfMiWwnI9//VG\nfbCsQK2CAjVxZDfdMjJFMRGUaKA5UKYBAPABecUV+tfX2Xpnab6CAoxuOClZt4xKUWwUS9wBzYky\nDQCAF9u2t1L/+iZbb2fkKSDA6JoRXXX7qSnq0DrU6WiAX6BMAwDghXaUVOnF+dmavThPVlbj0rvo\n9tNS1KkNOxYCLYkyDQCAFykqq9YL32zS9EVb5XJZXZ6WqDtOS1FC23CnowF+iTINAIAXKK+u02sL\nNmvydzmqqKnTJUMS9JvTe6hLO0o04CTKNAAAHqy23qXZGXl6bt5GFZZV6+y+cbr77F7q3iHS6WgA\nRJkGAMAjWWv1yaodeuqL9dpcWK5hSW3172uGamjXtk5HA9AAZRoAAA/z46ZCPfHpOq3IL1FqXKRe\nuy5Np/fqIGOM09EAHIQyDQCAh8jaVqonPlunbzfsVqc2ofr7ZQN0yZAEBQZQogFPRZkGAMBhecUV\nevrLDfpgeYFahwbrT+f20rUnJCk0ONDpaACOgDINAIBDistr9MI32Xrzp60yRrplZIpuG5WiNuHB\nTkcD0EiUaQAAWlhFTZ2m/LBFL8/fpPKaOl0+NFG/Hd2DDVcAL0SZBgCghdTVu/R2Zr6enbdBu/ZV\na3SfON1zdk/1iItyOhqAY0Sxj0DzAAAgAElEQVSZBgCgmVlr9fmaHXry8/XK2V2uoV3b6sXxQ5SW\nFON0NADHiTINAEAzqa6r18crt+v1HzZrdUGpuneI1CvXpunM3ixzB/gKyjQAAE1sV2mVpi/K1cxF\nW1VYVqPuHSL15KUDdMmQeAUFBjgdD0ATokwDANBEVuTt1ZQfNuvjVdtV57I6vWcHTTgpSSd3b89I\nNOCjKNMAAByH2nqXPlm1XVN/3KJluXsV2SpIV4/oqutOSFJS+win4wFoZpRpAACOQVFZtWYuytX0\nRVu1s7Raye0j9PCv+uiytERFtuLHK+Av+K8dAICjsLqgRFN/3KK5K7apps6lkamxevySJI1KjVUA\n234DfocyDQDAEdTVu/RF1k5N/WGLFm8pVnhIoK5MS9R1J3ZV9w6sEQ34M8o0AAC/YG9FjWYtztOb\nP23RtpIqJcaE6f7zeuvytES1CWPLbwCUaQAA/se6HaWa9uMWvb+sQFW1Lp2Y0k4PX9BXZ/SOUyBT\nOQA0QJkGAEBSTZ1Ln63ZoTd/2qKMLXvUKihAlwyJ14QTk9WzI1M5ABwaZRoA4Ne27a3UzEW5mp2R\nq8KyGnVtF677z+uty4YmKDo8xOl4ADwcZRoA4Hestfohu0hv/LRF89bulJV0Rq8OuuaEJJ3SvT2r\ncgBoNMo0AMBvlFTW6t0l+Zq+cKtyCssVExGiW0al6Kr0LkqMCXc6HgAvRJkGAPi8NdtKNH3hVn2w\nbJsqa+s1pEu0nrlyoM7p10mhwYFOxwPgxSjTAACfVF1Xr09X7dCbC7dqydY9Cg0O0EWD4nX1iK7q\nF9/G6XgAfARlGgDgU/L3VGjmoly9lZGnovIaJbeP0APn99FlQxLUJpy1oQE0Lco0AMDrWWv1/cZC\nvfHTVn29bqck6Yzecbr2hK46KYUHCgE0H8o0AMBr1busPl29XS98s0lrt5eqXUSIbjs1RVcN76r4\n6DCn4wHwA5RpAIDXqalz6YPlBXp5/iblFJarW2yEnrxsgC4c1FmtgnigEEDLoUwDALxGVW29Zi/O\n1eTvcrStpEp9O7fWi+OH6Oy+HdnmG4AjKNMAAI9XWlWr6Qu36vUFm1VYVqO0rm31l0v669TUWBlD\niQbgHMo0AMBjFZVVa8oPWzTtpy3aV1WnkamxmnRad6UnxzgdDQAkUaYBAB5oe0mlXvlus2YtzlVV\nXb3G9O2o20/trv4JrA8NwLNQpgEAHmNLYble/naT3l2aL5eVLhzUWbefmqLuHaKcjgYAh0SZBgA4\nbt2OUr34zSZ9tHKbggIDNHZYF00c2U2JMeFORwOAw6JMAwAcszR3j178Jlvz1u5SREigbh7ZTTee\nnKwOUaFORwOARqFMAwBa3OqCEj3+6TotyC5UdHiwfndmqiacmMR23wC8DmUaANBitu2t1FNfrNf7\nywoUHRasP53bS+OHd1VEK34cAfBO/OkFAGh2+6pq9fK3m/Tq95tlJU0c2U23n9pdbcIYiQbg3SjT\nAIBmU1fv0qyMPD375QYVldfowkGd9YezevJgIQCfQZkGADQ5a62+WrtLf/t0rTbtLld6coxeP7e3\nBiZGOx0NAJoUZRoA0KRW5ZfoL59kaWFOsbq1j9Dka4ZqdJ84tv0G4JMo0wCAJlGwt1JPfb7/4cKY\niBA9cmFfjUvvouDAAKejAUCzadSfcMaYMcaY9caYbGPMHw9z3qXGGGuMSWtw7P/c1603xpx9tPcE\nAHi20qpaPfHZOp321Hx9vGq7bjs1RfPvPlXXnpBEkQbg8444Mm2MCZT0gqTRkvIlZRhj5lprsw46\nL0rSnZIWNTjWR9JYSX0ldZY0zxiT6n77iPcEAHiu2nqXZi3O1bPzNqq4vEYXD47XH87uqfjoMKej\nAUCLacw0j3RJ2dbaHEkyxsyWdKGkg4vvo5KekHR3g2MXSpptra2WtNkYk+2+nxp5TwCAh7HW6sus\nnXr803XKKSzXiG4xuu/cPuqf0MbpaADQ4hpTpuMl5TV4nS9peMMTjDFDJCVaaz82xtx90LULD7o2\n3v37w94TAOB5VuTt1V8+WavFm4vVLTZCr16bpjN6d+DhQgB+67gfQDTGBEh6WtKE405z6PtPlDRR\nkrp06dIc3wIAcARFZdX66yfr9O7SfLWLCNGjF/XT2GGJzIkG4PcaU6YLJCU2eJ3gPnZAlKR+kua7\nRyY6SpprjLngCNce7p4/s9ZOljRZktLS0mwj8gIAmojLZfV2Zp7+9uk6lVfX6dZRKbrjtBRFhbJz\nIQBIjSvTGZJ6GGOStb/wjpV01YE3rbUlktofeG2MmS/pD9baTGNMpaSZxpintf8BxB6SFksyh7sn\nAMB5a7eX6r73V2lp7l6lJ8fosYv6KTUuyulYAOBRjlimrbV1xphJkj6XFCjpdWvtGmPMI5IyrbVz\nD3PtGmPM29r/YGGdpDustfWSdKh7Hv/HAQAcr/LqOj331Ua9tmCz2oQF66nLB+rSIfHMiwaAQzDW\nes/MibS0NJuZmel0DADwWV+s2aGH567RtpIqjR2WqHvH9FLbiBCnYwFAizLGLLHWph35THZABABI\nyt9ToYfnrtG8tbvUq2OUnh83WGlJMU7HAgCPR5kGAD9WW+/Saws267l5GyVJfzq3l64/KZlVOgCg\nkSjTAOCnMrYU6773V2nDzjKd1SdOD13Ql90LAeAoUaYBwM8Ul9fo8U/X6u3MfMVHh+mVa9M0uk+c\n07EAwCtRpgHAT7hcVu8szdffPlmrfVX714z+zRndFR7CjwIAOFb8CQoAfmDDzn26//3VWrylWMOS\n2uqxi/qrZ0fWjAaA40WZBgAfVlFTp+e/ytar3+coMjRIT146QJcNTVBAAGtGA0BToEwDgI/ZU16j\nxVuKtSinWJ+t3q5tJVW6Ii1Bfzynt2JYMxoAmhRlGgC8XGFZtRZvLtainCIt2lysdTv2SZJCgwOU\n1jVGz44drPRk1owGgOZAmQYAL7OrtEoLG5Tn7F1lkqSw4EClJbXV+QM6aUS3dhqQEK2QINaLBoDm\nRJkGAA+3bW+lFm0u0qKcYi3aXKzNheWSpMhWQUpLaqtLhyRoeLcY9Y9vw2YrANDCKNMA4GHyiiu0\n0D3qvGhzkfKKKyVJUaFBGp4co6vSu2h4txj16dRaQZRnAHAUZRoAWlhlTb0K9lYob0+lCvZUKn9P\npQr2Vip/T4XyiitVWFYtSYoOD1Z6UowmnJis4ckx6t2ptQJZhQMAPAplGgCaWFl1nfL3VPxPUT7w\nuqi85r/ODw406hwdpvjoMJ3WM1b94ttoeLcYpXaIYgk7APBwlGkAOEbWWi3ILtQ363arYG+F8t1l\nuaSy9r/OCwkKUEJ0mOLbhumszq2V0DZc8dFhSmgbpoS24YqNasWIMwB4Kco0AByDlfl79fin6/Tj\npiKFBgcosW244tuGaXCXaMVHh7uL8v4C3T6iFSPMAOCjKNMAcBS2FJbr71+s18crtysmIkQP/6qP\nrhrelSXoAMBPUaYBoBF276vW819t1KzFuQoODNBvTu+um0d2U1RosNPRAAAOokwDwGGUVddp8nc5\nevX7HFXXuTQuPVG/OaOHOkSFOh0NAOABKNMAcAg1dS7NWpyr57/aqKLyGp3Xv5N+f1aqusVGOh0N\nAOBBKNMA0IDLZfXRqu166vP1yi2u0IhuMXrtnN4alBjtdDQAgAeiTAOA24KNhXr8s7VaXVCqXh2j\nNPX6YRqVGitjWIkDAHBolGkAfm91QYme+Gydvt9YqPjoMD1z5UBdODCe5ewAAEdEmQbgt3KLKvTU\nF+s1d8U2tQ0P1gPn99HVI7qoVVCg09EAAF6CMg3A7xSWVetfX2drxqKtCgwwmnRad00c1U2tWeYO\nAHCUKNMA/Mpnq7fr92+vUFWdS1cOS9SdZ/RQXGuWuQMAHBvKNAC/8c6SfN3zzgoNSIjWP64YqBSW\nuQMAHCfKNAC/MPWHzXr4wyyd3L29/n3NUEW04o8/AMDx46cJAJ9mrdW/vs7WP77coLP6xOn5cYMV\nGswDhgCApkGZBuCzrLX66ydr9cr3m3XJ4Hg9edkABQUGOB0LAOBDKNMAfFK9y+q+91dpdkaerjuh\nqx76VV/WjQYANDnKNACfU1Pn0l1vL9dHK7dr0mnd9fuzUtnFEADQLCjTAHxKZU29bp+xRN+s363/\nO6eXbhmV4nQkAIAPo0wD8Bn7qmp147RMZWwp1l8v7q+rhndxOhIAwMdRpgH4hOLyGk2YslhZ20r1\n7JWDdOGgeKcjAQD8AGUagNfbUVKla15bpK3FFfr3NUN1Ru84pyMBAPwEZRqAV8stqtD41xaquKxG\n065P1wkp7ZyOBADwI5RpAF5rw859uvrVRaqpd2nGzSM0KDHa6UgAAD9DmQbglVbk7dV1UxYrJDBA\nb008QT07RjkdCQDghyjTALzOwpwi3TQtU9HhwZpx03B1bRfhdCQAgJ+iTAPwKl+v26nbpi9VYky4\npt84XB3bhDodCQDgxyjTALzGhyu26XdvLVevTlGadn262kW2cjoSAMDPUaYBeIVZi3P1p/dXaVjX\nGL06IU2tQ4OdjgQAAGUagGez1urf3+Xo8U/XaVRqrF6+eqjCQgKdjgUAgCTKNAAPlltUoT+9v0oL\nsgt1Xv9OeubKQQoJCnA6FgAAP6NMA/A49S6rqT9u0VOfr1eAkR69qJ/Gp3dRQIBxOhoAAP+FMg3A\no2zYuU/3vLNSy/P26rSesfrLxf3VOTrM6VgAABwSZRqAR6ipc+nF+dl64ZtsRbYK0nNjB+mCgZ1l\nDKPRAADPRZkG4LhluXt077srtWFnmS4c1FkPnt+HZe8AAF6BMg3AMRU1dfrHFxv0+g+bFRcVqteu\nS9MZveOcjgUAQKNRpgE4YsHGQv3f+yuVV1ypq0d00b1jeimKtaMBAF6GMg2gRZVU1Oovn2Tp7cx8\nJbeP0FsTR2h4t3ZOxwIA4Jg0qkwbY8ZIek5SoKRXrbWPH/T+rZLukFQvqUzSRGttljFmvKS7G5w6\nQNIQa+1yY8x8SZ0kVbrfO8tau+t4PgwAz/bZ6u16YM4aFZfX6LZTU3TnGT0UGswGLAAA73XEMm2M\nCZT0gqTRkvIlZRhj5lprsxqcNtNa+7L7/AskPS1pjLV2hqQZ7uP9JX1grV3e4Lrx1trMpvkoADzV\nrtIqPThnjT5bs0N9OrXWlAnD1C++jdOxAAA4bo0ZmU6XlG2tzZEkY8xsSRdK+rlMW2tLG5wfIcke\n4j7jJM0+9qgAvI21Vv9Zkq/HPspSVZ1L94zpqZtP6abgQHYxBAD4hsaU6XhJeQ1e50safvBJxpg7\nJN0lKUTS6Ye4z5XaX8IbmmKMqZf0rqTHrLWHKuEAvFDDrcDTk2L0t0v7KyU20ulYAAA0qSZ7ANFa\n+4KkF4wxV0m6X9J1B94zxgyXVGGtXd3gkvHW2gJjTJT2l+lrJL1x8H2NMRMlTZSkLl26NFVcAE3I\nWqtd+6q1aVeZNhWWa+POffpPZr4CAwxbgQMAfFpjynSBpMQGrxPcx37JbEkvHXRsrKRZDQ9Yawvc\nv+4zxszU/ukk/1OmrbWTJU2WpLS0NEauAQdV1dZrc2G5cnaXa9PuMuXsLlOO+3VZdd3P54UFB2pk\nans99Ku+bAUOAPBpjSnTGZJ6GGOStb9Ej5V0VcMTjDE9rLUb3S/Pk7SxwXsBkq6QdEqDY0GSoq21\nhcaYYEnnS5p3PB8EQNP4eZR5d1mD0rz/14K9lWo4Gatzm1CldIjUpUPildIhUt3aR6pbbIQ6tg5l\nJBoA4BeOWKattXXGmEmSPtf+pfFet9auMcY8IinTWjtX0iRjzJmSaiXtUYMpHpJGSso78ACjWytJ\nn7uLdKD2F+lXmuQTAWi0XfuqtHb7Pq3dXqr1O/b9XJwPHmXuFhuhwV3a6rKhCeoWG6mU2Aglt49Q\neAhL1QMA/Jvxpmf+0tLSbGYmK+kBR6uu3qWcwnKt3V6qrG2lytpeqrXb96mwrPrnczq1CVWKuyjv\nL8yMMgMA/JMxZom1Nq0x5zKsBPiYkspardt+oDDvL83rd+5TTZ1LkhQSGKAecZE6tWesendqrd6d\notSnU2tFh4c4nBwAAO9DmQa8lMtllb+nUlkNinPWtlIV7K38+ZyYiBD16dRa153QVX06t1bvTq2V\nEhvJOs8AADQRyjTgZSpr6jXtpy2a/F2OistrJEkBRkpuH6HBXaI1fkQX9e7UWn06tVaHqFYyhika\nAAA0F8o04CVq6lx6KyNXz3+drd37qjUqNVZj+nVU706t1TMuSmEhgU5HBADA71CmAQ9X77L6YFmB\nnpm3Qfl7KjUsqa1euGqI0pNjnI4GAIDfo0wDHspaq8/X7NBTX2xQ9q4y9e3cWo9d1E+jUmOZugEA\ngIegTAMexlqr7zcW6qkv1mtlfolSYiP04vghGtO3I0vUAQDgYSjTgAdZsrVYT362Xos2Fys+Okx/\nv2yALh4cryBW3wAAwCNRpgEPsGZbif7xxQZ9vW6X2ke20p8v6Kux6YlqFcRDhQAAeDLKNOCgnN1l\nembeRn24YptahwbpnjE9NeHEJLbpBgDAS/ATG3DAtr2Vev6rjfrPknyFBAZo0mnddfPIbmoTFux0\nNAAAcBQo00ALKiyr1ovfbNL0hVslSdeM6Ko7Tuuu2KhWDicDAADHgjINtJBXv8/R019uUFVtvS4b\nmqDfnNFDCW3DnY4FAACOA2UaaAHTftyixz5eqzN6ddCfzuutlNhIpyMBAIAmQJkGmtnHK7fr4Q/X\naHSfOL00fgjL3AEA4EP4qQ40ox83Fep3by1XWte2+ue4wRRpAAB8DD/ZgWaSta1Ut7yxREntw/Xq\ntcMUGsya0QAA+BrKNNAM8oordN2UxYoMDdK0G9LVJpwl7wAA8EWUaaCJFZVV69rXF6umzqU3bkhX\npzZhTkcCAADNhDINNKHy6jrdMDVD2/ZW6vUJaeoRF+V0JAAA0Iwo00ATqa136fYZS7WqoET/umqI\nhnaNcToSAABoZiyNBzQBa63ufXelvt2wW49f0l+j+8Q5HQkAALQARqaBJvD4Z+v03tIC/X50qsam\nd3E6DgAAaCGUaeA4vbZgs/79bY6uGdFVk07v7nQcAADQgijTwHGYs7xAj36UpXP6ddTDF/SVMcbp\nSAAAoAVRpoFj9P3G3frDf1ZoeHKMnrlykAIDKNIAAPgbyjRwDFYXlOjWN5coJTZSk69NY3dDAAD8\nFGUaOEpbi8o1YcpiRYeH7N/dMIzdDQEA8FeUaeAo7N63f3fDepfVtBvSFdc61OlIAADAQawzDTRS\nWXWdrp+6WDtLqzTz5hHq3iHS6UgAAMBhlGmgEWrqXLr1zSVau32fXrl2qIZ0aet0JAAA4AGY5gEc\ngctl9Yf/rNCC7EI9fkl/nd6L3Q0BAMB+lGngMKy1+ssnazV3xTbdM6anLk9LdDoSAADwIJRp4DBe\n+T5Hry3YrAknJum2USlOxwEAAB6GOdPAIVhr9foPW/TXT9bpvAGd9OD5fdjdEAAA/A/KNHCQ0qpa\n3fvOSn26eodG94nT01cMVAC7GwIAgEOgTAMNrC4o0R0zlyp/T6X+dG4v3XxKN0akAQDAL6JMA9o/\nrWPGolw98mGWYiJC9NbEEUpLinE6FgAA8HCUafi9suo6/d97q/Thim0alRqrZ64cpJiIEKdjAQAA\nL0CZhl9bu71Ud8xYqi1F5br77J66bVQK86MBAECjUabhl6y1ejszTw/OWaM2YcGaefMIjejWzulY\nAADAy1Cm4Xcqaup0//ur9d6yAp3cvb2euXKQYqNaOR0LAAB4Ico0/MqGnft0+4yl2rS7TL87M1WT\nTu+uQKZ1AACAY0SZht94Z0m+HvhgtSJaBWr6jcN1Uvf2TkcCAABejjINn1dZU6+H5q7W25n5GtEt\nRs+PHawOrUOdjgUAAHwAZRo+bdPuMt0+fak27NqnX5/eXXee0UNBgQFOxwIAAD6CMg2fNWd5gf7v\nvVUKDQ7U1OvTNSo11ulIAADAx1Cm4XOqauv1yEdZmrkoV8OS2ur5cYPVqU2Y07EAAIAPokzDp2wp\nLNftM5Yqa3upbhnVTX84q6eCmdYBAACaCWUaXs/lslq4uUhzl2/Thyu2KSgwQK9dl6Yzesc5HQ0A\nAPg4yjS8krVWa7aVas7yAn24Yrt2lFYpIiRQZ/frqLtGpyqhbbjTEQEAgB+gTMOr5BZVaO6KAn2w\nfJuyd5UpKMDo1J6xuu+83jqzd5zCQgKdjggAAPxIo8q0MWaMpOckBUp61Vr7+EHv3yrpDkn1ksok\nTbTWZhljkiStlbTefepCa+2t7muGSpoqKUzSJ5LutNba4/w88EFFZdX6eNV2fbCsQEtz90qS0pNi\n9JeL++ncfp3UNiLE4YQAAMBfHbFMG2MCJb0gabSkfEkZxpi51tqsBqfNtNa+7D7/AklPSxrjfm+T\ntXbQIW79kqSbJS3S/jI9RtKnx/pB4FvKq+v0ZdZOfbC8QN9vLFS9y6pXxyjdO6aXfjWwE9M4AACA\nR2jMyHS6pGxrbY4kGWNmS7pQ0s9l2lpb2uD8CEmHHWE2xnSS1Npau9D9+g1JF4ky7ddq6136fuNu\nfbBsm77M2qnK2np1bhOqm0/pposGd1avjq2djggAAPBfGlOm4yXlNXidL2n4wScZY+6QdJekEEmn\nN3gr2RizTFKppPuttd+775l/0D3jjy46fIG1Vku27tEHywv08crt2lNRq+jwYF08JF4XDYpXWte2\nCggwTscEAAA4pCZ7ANFa+4KkF4wxV0m6X9J1krZL6mKtLXLPkf7AGNP3aO5rjJkoaaIkdenSpani\nwmFbi8r17tICvb8sX3nFlQoNDtCZveN00aB4jUyNVUgQa0MDAADP15gyXSApscHrBPexXzJb++dD\ny1pbLana/fslxphNklLd1yc05p7W2smSJktSWloaDyh6sdKqWn28crveXZKvzK17ZIx0cvf2+u0Z\nqTq7X0dFtmJxGQAA4F0a014yJPUwxiRrf+Ed+//au/Mwqeo73+PvL2tUEJRFERAiizsodFTGSVSS\nqOMWo9EouBCj0VGSZ2YSR58k1/ExN4/RZHLn3hmNBqNEIyHGLSaOl5ioE2UU6AbEgCyiLA2y71vT\ny+/+0eWdDqNSFN19qqver+fh6arT51R/qn9W1cfTv3MOMKbpChExJKW0KHf3fGBRbnkvYENKqT4i\njgKGAO+mlDZExJaIOI3GAxCvAf61WZ6RikpdfQOvvrOOp6qqeXHeamrqGhjU6yD+8dyj+eLJfb3M\ntyRJatP2WqZTSnURMR6YQuOp8R5OKc2NiLuAypTSc8D4iPgcUAtspHGKB8BngLsiohZoAG5KKW3I\nfe9m/uvUeC/gwYclZf6qLTxVVc2zs1eydmsN3Q/syJc/1Z9LR/RjWL9uRDgPWpIktX3Rlk7tXFFR\nkSorK7OOoY+wblsNv5m9kqeqqpn3/hY6tAtGH9ObS0b0Y/QxvZ0HLUmS2oSIqEopVeSzrpNUtV92\n1dbz0vw1PFVVzSsL11LfkBjWrxt3XngcF53Ul0O9oIokSSphlmnts5QSs5Zv4qmqan775kq27Krj\nsIM7c8Onj+KSEX0ZeljXrCNKkiS1Csu08lZb38Dk6ct4ZOoS3l23nU90bMe5xx/OJSP6cfrgnrT3\nfNCSJKnMWKa1Vykl/vD2Gu5+4W3eXbudEUd2595Lh/E3Jx5O1090zDqeJElSZizT+lhzqjfx/eff\nZtp7Gziq10E8dE0Fnz22t2fjkCRJwjKtj1C9cQc/mrKAZ2evpMdBnfjexSdwxaf607G9Z+SQJEn6\ngGVaf2HLrlruf3kxD099jwBuOWsQN50xyOkckiRJH8IyLaDx4MJJ05bxL39YyKadtXzx5L586+yj\nOaK7VyiUJEn6KJbpMpdS4vfzVvODF+bz3rrtjDqqB985/1hO6Nst62iSJElFzzJdxmYv38T3n5/H\njCUbGdy7Cw+Pq+Csoz24UJIkKV+W6TK0fMMO7p2ygN++uZKeXTrx/S+ewJcr+tPBgwslSZL2iWW6\njGzeUct9r7zDxKlLaNcOvj56MDeeMYgunf3PQJIkqRC2qDKwu66BX7yxlP/z0iI276zl0hH9+ObZ\nQ+nTzYMLJUmS9odluoRtq6njmZnVPPTaeyxdv4PTB/fg2+cdy/FHeHChJElSc7BMl6CFq7fy2OtL\neXpmNdt313Ni32488pVPcebQXh5cKEmS1Iws0yWitr6B389dzaOvL2Haexvo1KEdFwzrwzWjBjK8\nXzdLtCRJUguwTLdxqzbv4pfTl/HL6ctYs7WGfoccwO1/cwyXV/Tn0IM6ZR1PkiSppFmm26CUEq+/\nu55fvLGUKXNX05ASZw7txQ9GDeCMob1p38690JIkSa3BMt2GbN1Vy9MzV/DYG0t5Z802uh/Ykev/\n+pOMOfVIBvQ4KOt4kiRJZccy3QbMX7WFx15fyjOzVrBjdz3D+3XjR5cN54JhffhEx/ZZx5MkSSpb\nlukitbuugSlzV/HY60uZvmQDnTu046LhR3DVaQMY3r971vEkSZKEZbroNDQkHvjTYh6ZuoS1W2s4\n8tAD+fZ5x3DZyP4c4gGFkiRJRcUyXUTqGxLffvotflW5nDOG9mLclwZyxpBetPOAQkmSpKJkmS4S\ndfUN3PrkHJ6ZtYJvfHYIf/+5IZ4bWpIkqchZpotAbX0Dfzd5Ns+/9T63nnM0t5w1OOtIkiRJyoNl\nOmM1dfWMnzSLF+et5jvnHcsNnzkq60iSJEnKk2U6Q7tq67npF1W8smAtd33heK4ZNTDrSJIkSdoH\nlumM7Nhdx9cerWLq4nXcfcmJXHnKkVlHkiRJ0j6yTGdgW00d102cQeWSDfzoS8O5dGS/rCNJkiSp\nAJbpVrZ5Zy3jHpnOnOrN/O8rTubC4UdkHUmSJEkFsky3ok07dnP1z6Yzf9UW7hszgnNPODzrSJIk\nSdoPlulWsn5bDVf9bJuzhZMAAA7RSURBVDqL127jwatHMvqYw7KOJEmSpP1kmW4Fa7buYuyEaSzf\nuIOHrqngM0N7ZR1JkiRJzcAy3cLe37yTsROmsWrLLh4ZdwqjBvXIOpIkSZKaiWW6BS3fsIMxD73B\nxu21PHrdKVQMPDTrSJIkSWpGlukWsnT9dsZMmMbWXbX84vpTOal/96wjSZIkqZlZplvA4rXbGDPh\nDXbXNTDphtM4oW+3rCNJkiSpBVimm9mCVVsZ+9A0IDH5a6M4+vCuWUeSJElSC2mXdYBS8ucVm7ni\np6/TLrBIS5IklQHLdDN5c/kmxkx4gwM6tueJG0cxuHeXrCNJkiSphTnNoxlULtnAuEdmcMhBHZl0\n/Wn0P/TArCNJkiSpFbhnej+9NH81V/1sGr26duaJG0dZpCVJksqIZXo/PFVVzQ2PVjGkd1d+fdMo\n+nQ7IOtIkiRJakVO8yjQg/+xmLtfmM/pg3vw4NUVdOnsr1KSJKnc2AD3UUND4u4X3mbCq+9xwbA+\n/PPlw+ncoX3WsSRJkpQBy/Q+qK1v4LYn5/D0rBVcO2oA/3Th8bRrF1nHkiRJUkYs03nasbuOmx+f\nySsL1vKts4dyy1mDibBIS5IklTPLdB42bt/NVybOYE71Ju6+5ESuPOXIrCNJkiSpCFim92LFpp1c\n87NpLN+4k/vHjuTcEw7POpIkSZKKhGX6YyxcvZVrH57Otpo6HrvuFE49qkfWkSRJklRELNMfoWrp\nBq6bWEmnDu144sZRHNvn4KwjSZIkqchYpj/ES/NXc/PjM+nT7QAeve4Ur2ooSZKkD5XXFRAj4tyI\nWBAR70TE7R/y/Zsi4q2ImB0Rr0XEcbnln4+Iqtz3qiJidJNtXsk95uzcv97N97QK9+QeVzW0SEuS\nJOmj7HXPdES0B+4DPg9UAzMi4rmU0rwmq01KKT2QW/8i4MfAucA64MKU0sqIOAGYAvRtst3YlFJl\n8zyV/ffBVQ3/enBPHrh6pFc1lCRJ0sfKpy2eAryTUnoXICImA18A/n+ZTiltabL+QUDKLZ/VZPlc\n4ICI6JxSqtnf4M1pz6sa/vjyk+jUIa+d9pIkSSpj+ZTpvsDyJvergVP3XCkibgH+AegEjN7z+8Cl\nwMw9ivQjEVEPPAX8z5RSyjd4c6mtb+Afn5zDM7NWMO6vBnLHBcd5VUNJkiTlpdl2v6aU7kspDQJu\nA77b9HsRcTxwD3Bjk8VjU0onAp/O/bv6wx43Ir4WEZURUbl27drmigs0XtXw+p9X8sysFdx6ztH8\n04UWaUmSJOUvnzK9Aujf5H6/3LKPMhm4+IM7EdEPeAa4JqW0+IPlKaUVua9bgUk0Tif5b1JKP00p\nVaSUKnr16pVH3Pxs3L6bMROm8eqitfzgkhO9PLgkSZL2WT5legYwJCI+GRGdgCuA55quEBFDmtw9\nH1iUW94deB64PaU0tcn6HSKiZ+52R+AC4M/780T2xeotu/jSA//JvPe38JOrRnKFlweXJElSAfY6\nZzqlVBcR42k8E0d74OGU0tyIuAuoTCk9B4yPiM8BtcBG4Nrc5uOBwcAdEXFHbtnZwHZgSq5Itwf+\nAExoxuf1kXbsruOrP5/Bqs27vKqhJEmS9ktkcMxfwSoqKlJlZeFn0mtoSPzt41W8OG81D11bwehj\nDmvGdJIkSSoFEVGVUqrIZ92yOv/bD3+/gClzV/Pd84+zSEuSJGm/lU2Z/nXlcn7yymLGnnokXzl9\nYNZxJEmSVALKokxPf28D337mLU4f3IM7Lzres3ZIkiSpWZR8mV66fjs3PlZJ/0MP5P4xI+nYvuSf\nsiRJklpJSTfLzTtruW7iDBLw8LWfotuBHbOOJEmSpBJSsmW6tr6B8ZNmsmzDDh64aiQDex6UdSRJ\nkiSVmL2eZ7otSilx53NzeXXROu790jBO81zSkiRJagEluWd64n8u4fFpy7jxjKO4vKL/3jeQJEmS\nClByZfrlBWv43u/mcfZxh3HbOcdkHUeSJEklrKTK9IJVW/n6pFkc2+dg/uWKk2jXzlPgSZIkqeWU\nTJlet62G6ybO4MBO7Xno2goO7FSS08ElSZJUREqice6qredrj1ayfnsNT9w4ij7dDsg6kiRJkspA\nmy/TKSVue2oOM5dt4v6xIxjWr3vWkSRJklQm2vw0j3976R1+M3slt55zNOed2CfrOJIkSSojbbpM\n/27OSv75xYVccnJfbj5zUNZxJEmSVGbabJmevXwT33ziTSoGHMLdl55IhGfukCRJUutqk2V6xaad\nXP/zSnof3JkHrx5J5w7ts44kSZKkMtTmDkDcVlPHVyfOoKa2nkk3nEqPLp2zjiRJkqQy1ebK9N9N\nnsXC1Vt55CunMPSwrlnHkSRJUhlrU2X6/c27WPf2Gu76wvGcMbRX1nEkSZJU5trUnOl122q4dtQA\nrhk1MOsokiRJUtsq0106d+B/XHBc1jEkSZIkoI2V6SN7HEiH9m0qsiRJkkpYm2qm7T2XtCRJkopI\nmyrTkiRJUjGxTEuSJEkFskxLkiRJBbJMS5IkSQWyTEuSJEkFskxLkiRJBbJMS5IkSQWyTEuSJEkF\nskxLkiRJBbJMS5IkSQWyTEuSJEkFskxLkiRJBbJMS5IkSQWyTEuSJEkFskxLkiRJBbJMS5IkSQWy\nTEuSJEkFskxLkiRJBbJMS5IkSQWyTEuSJEkFipRS1hnyFhFbgQVZ5xA9gXVZhxDgWBQLx6F4OBbF\nwXEoHo5FYQaklHrls2KHlk7SzBaklCqyDlHuIqLScSgOjkVxcByKh2NRHByH4uFYtDyneUiSJEkF\nskxLkiRJBWprZfqnWQcQ4DgUE8eiODgOxcOxKA6OQ/FwLFpYmzoAUZIkSSombW3PtCRJklQ0iq5M\nR8S5EbEgIt6JiNs/5Pv/EBHzImJORPwxIgZkkbMc5DEWN0XEWxExOyJei4jjsshZ6vY2Dk3WuzQi\nUkR41HYLyeM1MS4i1uZeE7Mj4voscpa6fF4TEXF57rNibkRMau2M5SKP18T/avJ6WBgRm7LIWery\nGIcjI+LliJiV60/nZZGzVBXVNI+IaA8sBD4PVAMzgCtTSvOarHMWMC2ltCMi/hY4M6X05UwCl7A8\nx+LglNKW3O2LgJtTSudmkbdU5TMOufW6As8DnYDxKaXK1s5a6vJ8TYwDKlJK4zMJWQbyHIchwBPA\n6JTSxojonVJak0ngEpbv+1OT9b8OnJxSuq71Upa+PF8TPwVmpZR+ktvx9e8ppYFZ5C1FxbZn+hTg\nnZTSuyml3cBk4AtNV0gpvZxS2pG7+wbQr5Uzlot8xmJLk7sHAcXzf2alY6/jkPM94B5gV2uGKzP5\njoVaVj7jcANwX0ppI4BFusXs62viSuCXrZKsvOQzDgk4OHe7G7CyFfOVvGIr032B5U3uV+eWfZSv\nAi+0aKLylddYRMQtEbEYuBf4RitlKyd7HYeIGAH0Tyk935rBylC+70+X5v6M+mRE9G+daGUln3EY\nCgyNiKkR8UZE+BezlpH3Z3ZuSuYngZdaIVe5yWcc7gSuiohq4N+Br7dOtPJQbGU6bxFxFVAB/DDr\nLOUspXRfSmkQcBvw3azzlJuIaAf8GPhm1lkEwG+BgSmlYcCLwM8zzlOuOgBDgDNp3Bs6ISK6Z5pI\nVwBPppTqsw5Spq4EJqaU+gHnAY/lPj/UDIrtF7kCaLonp19u2V+IiM8B3wEuSinVtFK2cpPXWDQx\nGbi4RROVp72NQ1fgBOCViFgCnAY850GILWKvr4mU0vom70kPASNbKVs5yee9qRp4LqVUm1J6j8b5\npENaKV852ZfPiStwikdLyWccvkrjcQSklF4HPgH0bJV0ZaDYyvQMYEhEfDIiOtH44nuu6QoRcTLw\nII1F2nlwLSefsWj64XQ+sKgV85WLjx2HlNLmlFLPlNLA3MEkb9D42vAAxOaXz2uiT5O7FwFvt2K+\ncrHXcQCepXGvNBHRk8ZpH++2Zsgykc9YEBHHAIcAr7dyvnKRzzgsAz4LEBHH0lim17ZqyhLWIesA\nTaWU6iJiPDAFaA88nFKaGxF3AZUppedonNbRBfh1RAAsSyldlFnoEpXnWIzP/ZWgFtgIXJtd4tKU\n5zioFeQ5Ft/IndmmDtgAjMsscInKcxymAGdHxDygHrg1pbQ+u9SlaR/en64AJqdiOn1YCclzHL5J\n43Snv6fxYMRxjkfzKapT40mSJEltSbFN85AkSZLaDMu0JEmSVCDLtCRJklQgy7QkSZJUIMu0JEmS\nVCDLtCRlLCK6R8TNudtnRsTvWuBnjIuIf9vHbZbkztO85/I7I+JbzZdOktouy7QkZa87cPO+bBAR\n7VsoiyRpH1imJSl7PwAGRcRschemiognI2J+RDweuStU5fYU3xMRM4HLImJQRPzfiKiKiFdzV5oj\nIi6LiD9HxJsR8acmP+eI3PqLIuLeDxZGxJUR8VZum3s+LGBEfCciFkbEa8DRLfWLkKS2pqiugChJ\nZep24ISU0kkRcSbwG+B4YCUwFTgdeC237vqU0giAiPgjcFNKaVFEnArcD4wG7gDOSSmtiIjuTX7O\nScDJQA2wICL+lcYrBN4DjKTxSqa/j4iLU0rPfrBRRIyk8Sp2J9H4uTETqGr+X4MktT2WaUkqPtNT\nStUAub3VA/mvMv2r3PIuwF8Bv87tuAbonPs6FZgYEU8ATzd53D+mlDbntp8HDAB6AK+klNbmlj8O\nfAZ4tsl2nwaeSSntyK3jZewlKccyLUnFp6bJ7Xr+8r16e+5rO2BTSumkPTdOKd2U21N9PlCV27O8\nt8eVJBXAOdOSlL2tQNd92SCltAV4LyIuA4hGw3O3B6WUpqWU7gDWAv0/5qGmA2dERM/cQY1XAv+x\nxzp/Ai6OiAMioitw4b5klaRS5l4JScpYSml9REyNiD8DO4HVeW46FvhJRHwX6AhMBt4EfhgRQ4AA\n/phb9t/2YOd+9vsRcTvwcm7951NKv9ljnZkR8avc46wBZuzrc5SkUhUppawzSJIkSW2S0zwkSZKk\nAlmmJUmSpAJZpiVJkqQCWaYlSZKkAlmmJUmSpAJZpiVJkqQCWaYlSZKkAlmmJUmSpAL9P+p+S+d5\nx1/kAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jUELUe9nQ71h"
   },
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1XjgUsAQ71h"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "def unet_vgg(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    #Base_model エンコーダー\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    \n",
    "    #エンコーダー部分(VGG16)\n",
    "    encoder1 = base_model.get_layer('block1_conv2').output\n",
    "    encoder2 = base_model.get_layer('block2_conv2').output\n",
    "    encoder3 = base_model.get_layer('block3_conv3').output\n",
    "    encoder4 = base_model.get_layer('block4_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_conv3').output\n",
    "    encoder6 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    #中間部分(オリジナル)\n",
    "    center = decoder_block(\n",
    "        encoder6, 'center', num_filters=512)\n",
    "    concat6 = concatenate([center, encoder6], axis=-1)\n",
    "\n",
    "    #デコーダー部分(オリジナル)\n",
    "    #エンコーダー部分を結合\n",
    "    decoder5 = decoder_block(\n",
    "        concat6, 'decoder5', num_filters=512)\n",
    "    concat5 = concatenate([UpSampling2D()(decoder5), encoder5], axis=-1)\n",
    "\n",
    "    \n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=512)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=256)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=128)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    #出力\n",
    "    #output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        concat1, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4709
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 598021,
     "status": "ok",
     "timestamp": 1560931144923,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "6yh5Ss2bQ71k",
    "outputId": "4803dbdf-1204-4cbf-fd54-2db598073237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv1 (Conv2D)         (None, 7, 7, 512)    4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn1 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation1 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv2 (Conv2D)         (None, 7, 7, 256)    1179904     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn2 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder5_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation2 (PReLU)    (None, 7, 7, 256)    12544       decoder5_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 256)    0           decoder5_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_conv3 (Conv2D)         (None, 7, 7, 512)    1180160     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_bn3 (BatchNormalizatio (None, 7, 7, 512)    2048        decoder5_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder5_activation3 (PReLU)    (None, 7, 7, 512)    25088       decoder5_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 512)    0           decoder5_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 512)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 512)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 14, 14, 512)  4719104     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 14, 14, 256)  1179904     dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 14, 14, 256)  1024        decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 14, 14, 256)  50176       decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 256)  0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 14, 14, 512)  1180160     dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 14, 14, 512)  2048        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 14, 14, 512)  100352      decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 512)  0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 512)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 1024) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 28, 28, 256)  2359552     concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 28, 28, 128)  295040      dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 28, 28, 128)  512         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 28, 28, 128)  100352      decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 128)  0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 28, 28, 256)  295168      dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 28, 28, 256)  1024        decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 28, 28, 256)  200704      decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 256)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 256)  0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 512)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 56, 56, 128)  589952      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 56, 56, 64)   73792       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 56, 56, 64)   256         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 56, 56, 64)   200704      decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 64)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 56, 56, 128)  73856       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 56, 56, 128)  512         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 56, 56, 128)  401408      decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 128)  0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 128)  0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 128 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 256 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 112, 112, 64) 147520      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 112, 112, 32) 18464       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 112, 112, 32) 128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 112, 112, 32) 401408      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 112, 112, 32) 0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 112, 112, 64) 18496       dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 112, 112, 64) 256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 112, 112, 64) 802816      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 112, 112, 64) 0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 112, 112, 64) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 64) 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 224, 224, 128 0           up_sampling2d_5[0][0]            \n",
      "                                                                 block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 36896       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 224, 224, 32) 0           dropout_19[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 45,433,809\n",
      "Trainable params: 45,423,729\n",
      "Non-trainable params: 10,080\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 3196 samples, validate on 804 samples\n",
      "Epoch 1/2\n",
      "3196/3196 [==============================] - 291s 91ms/step - loss: 0.9770 - my_iou_metric: 0.1611 - val_loss: 1.9691 - val_my_iou_metric: 0.1674\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.16741, saving model to unet_vgg.h5\n",
      "Epoch 2/2\n",
      "3196/3196 [==============================] - 281s 88ms/step - loss: 0.7614 - my_iou_metric: 0.2932 - val_loss: 0.8150 - val_my_iou_metric: 0.2219\n",
      "\n",
      "Epoch 00002: val_my_iou_metric improved from 0.16741 to 0.22189, saving model to unet_vgg.h5\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_size = (224, 224, 3)\n",
    "\n",
    "#モデル\n",
    "model_depth = unet_vgg(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "#チェックポイント\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vgg.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  \n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vJYqouP5XqER"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 669411,
     "status": "ok",
     "timestamp": 1560931216556,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "UXWvw-3JXqCn",
    "outputId": "8d3c904f-3717-43e7-f898-f109be6c5c67"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:49<00:00,  1.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 669303,
     "status": "ok",
     "timestamp": 1560931216557,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "drIUTiLAXp_J",
    "outputId": "d7994394-220a-49c5-a1ae-43b3deec4f34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3012 at threshold: 0.880\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.231169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.022232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.211070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.220398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.225498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.227861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.301244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.231169\n",
       "std     0.204939   0.022232\n",
       "min     0.200000   0.211070\n",
       "25%     0.370000   0.220398\n",
       "50%     0.540000   0.225498\n",
       "75%     0.710000   0.227861\n",
       "max     0.880000   0.301244"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 669173,
     "status": "ok",
     "timestamp": 1560931216558,
     "user": {
      "displayName": "Yuhi Soejima",
      "photoUrl": "",
      "userId": "10660385064496019405"
     },
     "user_tz": -540
    },
    "id": "_f6H8Fg4X4Qn",
    "outputId": "8be19a8a-c540-446a-d33e-52b42ea20fa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7492528160>"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ioZAPocfz7OC"
   },
   "source": [
    "IoUを比較すると、U-Net + ResNetでのBest IoUは0.496、Unet + VGG16では0.301となり、U-Net + ResNetの組み合わせの方が良い結果となった。　また、その時のthresholdはどちらも0.880である。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "sprint21-segmentation2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
