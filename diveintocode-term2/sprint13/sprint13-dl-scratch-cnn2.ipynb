{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint13課題 深層学習スクラッチ畳み込みニューラルネットワーク2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## この課題の目的\n",
    "\n",
    "- スクラッチを通してCNNの基礎を理解する\n",
    "- 基本的なCNNのキーワードを学習する\n",
    "- 初期の有名なCNNモデルを知る"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スクラッチによる実装\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "Sprint12では1次元畳み込み層を実装しましたが、Sprint13では画像に対して一般的に使われる2次元畳み込み層を実装します。また、プーリング層なども作成することで、CNNの基本形を完成させます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの用意\n",
    "\n",
    "引き続きMNISTデータセットを使用します。2次元畳み込み層へは、28×28の状態で入力します。\n",
    "\n",
    "今回は白黒画像であるからチャンネルは1つしかありませんが、チャンネル方向の軸は用意しておく必要があります。\n",
    "\n",
    "(n_samples, n_channels, height, width)のNCHWまたは(n_samples, height, width, n_channels)のNHWCどちらかの形にしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "X_test = X_test[:, np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 28, 28)\n",
      "(12000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) \n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN分類器クラスの作成\n",
    "\n",
    "2次元畳み込みニューラルネットワークモデルのクラスScratch2dCNNClassifierを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】2次元畳み込み層の作成\n",
    "\n",
    "Sprint12で作成した1次元畳み込み層を発展させ、2次元畳み込み層のクラスConv2dを作成してください。\n",
    "\n",
    "$$\n",
    "a_{i,j,m} = \\sum_{k=0}^{K-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1}x_{(i+s),(j+t),k}w_{s,t,k,m}+b_{m}\n",
    "$$\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、mチャンネルの値\n",
    "\n",
    "$i$  : 配列の行方向のインデックス\n",
    "\n",
    "$j$ : 配列の列方向のインデックス\n",
    "\n",
    "$m$ : 出力チャンネルのインデックス\n",
    "\n",
    "$K$ : 入力チャンネル数\n",
    "\n",
    "$F_h,F_w$ : 高さ方向（h）と幅方向（w）のフィルタのサイズ\n",
    "\n",
    "$x_{(i+s),(j+t),k}$ : 入力の配列の(i+s)行(j+t)列、kチャンネルの値\n",
    "\n",
    "$w_{s,t,k,m}$ : 重みの配列のs行t列目。kチャンネルの入力に対して、mチャンネルへ出力する重み\n",
    "\n",
    "$b_m$ : mチャンネルへの出力のバイアス項\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "次に更新式です。1次元畳み込み層や全結合層と同じ形です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$w_{s,t,k,m}^{\\prime} = w_{s,t,k,m} - \\alpha \\frac{\\partial L}{\\partial w_{s,t,k,m}}\\\\\n",
    "b_{m}^{\\prime} = b_{m} - \\alpha \\frac{\\partial L}{\\partial b_{m}}\n",
    "$$\n",
    "\n",
    "$\\alpha$ : 学習率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$ : $w_{s,t,k,m}$ に関する損失 $L$ の勾配\n",
    "\n",
    "勾配$\\frac{\\partial L}{\\partial w_{s,t,k,m}}$や$\\frac{\\partial L}{\\partial b_{m}}$を求めるためのバックプロパゲーションの数式が以下である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{s,t,k,m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1} \\frac{\\partial L}{\\partial a_{i,j,m}}x_{(i+s)(j+t),k}\\\\\n",
    "\\frac{\\partial L}{\\partial b_{m}} = \\sum_{i=0}^{N_{out,h}-1}\\sum_{j=0}^{N_{out,w}-1}\\frac{\\partial L}{\\partial a_{i,j,m}}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi行j列、mチャンネルの値\n",
    "\n",
    "$N_{out,h},N_{out,w}$ : 高さ方向（h）と幅方向（w）の出力のサイズ\n",
    "\n",
    "前の層に流す誤差の数式は以下です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial x_{i,j,k}} = \\sum_{m=0}^{M-1}\\sum_{s=0}^{F_{h}-1}\\sum_{t=0}^{F_{w}-1} \\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}}w_{s,t,k,m}\n",
    "$$\n",
    "\n",
    "$\\frac{\\partial L}{\\partial x_{i,j,k}}$ : 前の層に流す誤差の配列のi列j行、kチャンネルの値\n",
    "\n",
    "$M$ : 出力チャンネル数\n",
    "\n",
    "ただし、$i-s<0$または$i-s>N_{out,h}-1$または$j-t<0$または$j-t>N_{out,w}-1$のとき$\\frac{\\partial L}{\\partial a_{(i-s),(j-t),m}} =0$です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    \"\"\"\n",
    "    2次元畳み込み層クラス\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "     initializer : インスタンス\n",
    "         重みの初期化方法\n",
    "     optimizer : インスタンス\n",
    "         最適化手法\n",
    "     filter_num : int\n",
    "         フィルタの数\n",
    "     C : int\n",
    "         チャンネル数\n",
    "     filter_size : int\n",
    "         フィルタの大きさ(縦横同じ)\n",
    "     stride : int\n",
    "         ストライド数\n",
    "     pad : int\n",
    "        パディング数    \n",
    "\n",
    "    Attributes\n",
    "    -------------\n",
    "    W : 次の形のndarray, shape (filter_num, C, filter_size)\n",
    "        フィルタ\n",
    "    B : 次の形のndarray, shape (filter_num)\n",
    "        バイアス\n",
    "    X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        入力データのコピー\n",
    "    col : im2colの結果\n",
    "    col_W : 展開したフィルタ\n",
    "\n",
    "    dW : 次の形のndarray, shape (batch_size, n_output)\n",
    "        Wに関する損失Lの勾配\n",
    "    dB : 次の形のndarray, shape (batch_size, n_output)\n",
    "        Bに関する損失Lの勾配\n",
    "    \"\"\"\n",
    "    def __init__(self, initializer, optimizer, filter_num, C, filter_size, stride=1, pad=0):\n",
    "        #ハイパーパラメータ\n",
    "        self.optimizer = optimizer\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_num=filter_num, C=C, filter_size=filter_size)\n",
    "        self.B = initializer.B(filter_num)\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.X = None #入力\n",
    "        self.col = None #im2col\n",
    "        self.col_W = None #展開したフィルタ\n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力データ\n",
    "            \n",
    "        Returns\n",
    "        ---------\n",
    "        A : 次の形のndarray, shape (N, C, out_h ,out_w)\n",
    "            畳み込みした結果\n",
    "        \"\"\"\n",
    "        #サイズを取得\n",
    "        FN, C, FH, FW = self.W.shape #フィルター\n",
    "        N, C, H, W = X.shape #サンプル\n",
    "        \n",
    "        #出力されるサイズ\n",
    "        out_h, out_w = self._out_shape(H, FH, W, FW)\n",
    "        \n",
    "        #im2col\n",
    "        self.col = self._im2col(X, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        #フィルタを展開\n",
    "        self.col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        #畳み込み演算\n",
    "        A = np.dot(self.col, self.col_W) + self.B\n",
    "        A = A.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2) \n",
    "        \n",
    "        #バックワードで使う\n",
    "        self.X = X\n",
    "        \n",
    "        return A\n",
    "\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        --------------\n",
    "        dA : 次の形のndarray, shape (N, C, out_h ,out_w)(プーリング後)\n",
    "            Aに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dX : 次の形のndarray, shape (N, C, H ,W)(プーリング後)\n",
    "            Xに関する損失Lの勾配\n",
    "        \"\"\"        \n",
    "        #フィルタサイズを取得\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        \n",
    "        #順番を入れ替え\n",
    "        dA = dA.transpose(0,2,3,1).reshape(-1, FN) \n",
    "        \n",
    "        #逆伝播\n",
    "        self.dB = np.sum(dA, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dA)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "        dcol = np.dot(dA, self.col_W.T)\n",
    "        \n",
    "        #col2im\n",
    "        dX = self._col2im(dcol, self.X.shape, FH, FW, self.stride, self.pad)\n",
    "        \n",
    "        # 重み、バイアスの更新\n",
    "        self = self.optimizer.update(self)        \n",
    "\n",
    "        return dX\n",
    "    \n",
    "    \n",
    "    def _im2col(self, X, FH, FW, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力データ\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "        stride : int\n",
    "            ストライド\n",
    "        pad : int\n",
    "            パディング\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        col : 2次元配列\n",
    "        \"\"\"\n",
    "        #サイズを取得\n",
    "        N, C, H, W = X.shape\n",
    "        \n",
    "        #出力されるサイズ\n",
    "        out_h, out_w = self._out_shape(H, FH, W, FW)\n",
    "\n",
    "        #パディング\n",
    "        img = np.pad(X, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "        \n",
    "        #ゼロ配列を用意し、結果を格納\n",
    "        col = np.zeros((N, C, FH, FW, out_h, out_w))\n",
    "        for y in range(FH):\n",
    "            y_max = y + stride * out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + stride * out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y: y_max: stride, x: x_max: stride]\n",
    "        \n",
    "        #位置変換、reshape\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1)\n",
    "\n",
    "        return col\n",
    "    \n",
    "    \n",
    "    def _col2im(self, dcol, X_shape, FH, FW, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dcol : Xに関する損失Lの勾配\n",
    "            \n",
    "        X_shape : shape\n",
    "            入力データの形状\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "        stride : int\n",
    "            ストライド\n",
    "        pad : int\n",
    "            パディング\n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        col2imの結果\n",
    "        \"\"\"\n",
    "        #入力データのサイズ\n",
    "        N, C, H, W = X_shape\n",
    "\n",
    "        #出力のサイズ\n",
    "        out_h, out_w = self._out_shape(H, FH, W, FW)\n",
    "        \n",
    "        #reshape、位置変換\n",
    "        dcol = dcol.reshape(N, out_h, out_w, C, FH, FW).transpose(0, 3, 4, 5, 1, 2)\n",
    "        \n",
    "        #ゼロ配列を用意し、結果を格納\n",
    "        img = np.zeros((N, C, H + 2 * pad + stride - 1, W + 2 * pad + stride - 1))\n",
    "        for y in range(FH):\n",
    "            y_max = y + stride * out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + stride * out_w\n",
    "                img[:, :, y: y_max: stride, x: x_max: stride] += dcol[:, :, y, x, :, :]\n",
    "\n",
    "        return img[:, :, pad: H + pad, pad: W + pad]\n",
    "    \n",
    "    \n",
    "    def _out_shape(self, H, FH, W, FW):\n",
    "        '''\n",
    "        出力サイズを計算する関数\n",
    "        \n",
    "        Parameters\n",
    "        --------------\n",
    "        H : int\n",
    "            高さ\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        W : int\n",
    "            幅\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        out_h : int\n",
    "            出力するときの高さ\n",
    "        out_w : int\n",
    "            出力するときの幅\n",
    "        '''\n",
    "        out_h = 1 + int((H + 2 * self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2 * self.pad - FW) / self.stride)\n",
    "        \n",
    "        return out_h, out_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】2次元畳み込み後の出力サイズ\n",
    "\n",
    "畳み込みを行うと特徴マップのサイズが変化します。どのように変化するかは以下の数式から求められます。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{h,out} =  \\frac{N_{h,in}+2P_{h}-F_{h}}{S_{h}} + 1\\\\\n",
    "N_{w,out} =  \\frac{N_{w,in}+2P_{w}-F_{w}}{S_{w}} + 1\n",
    "$$\n",
    "\n",
    "$N_out$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "$N_in$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$S$ : ストライドのサイズ\n",
    "\n",
    "$h$ が高さ方向、 $w$ が幅方向である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _out_shape(self, H, FH, W, FW):\n",
    "    '''\n",
    "    出力サイズを計算する関数\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    H : int\n",
    "        高さ\n",
    "    FH : int\n",
    "        フィルターの高さ\n",
    "    W : int\n",
    "        幅\n",
    "    FW : int\n",
    "        フィルターの幅\n",
    "            \n",
    "    Returns\n",
    "    ----------\n",
    "    out_h : int\n",
    "        出力するときの高さ\n",
    "    out_w : int\n",
    "        出力するときの幅\n",
    "    '''\n",
    "    out_h = 1 + int((H + 2 * self.pad - FH) / self.stride)\n",
    "    out_w = 1 + int((W + 2 * self.pad - FW) / self.stride)\n",
    "        \n",
    "    return out_h, out_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】最大プーリング層の作成\n",
    "\n",
    "最大プーリング層のクラスMaxPool2Dを作成してください。プーリング層は数式で表さない方が分かりやすい部分もありますが、フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_{i,j,k} = \\max_{(p,q)\\in P_{i,j}}x_{p,q,k}\n",
    "$$\n",
    "\n",
    "$P_{i,j}$ : i行j列への出力する場合の入力配列のインデックスの集合。 $S_h \\times S_w$ の範囲内の行（p）と列（q）\n",
    "\n",
    "$S_h,S_w$  : 高さ方向（h）と幅方向（w）のストライドのサイズ\n",
    "\n",
    "$(p,q)\\in P_{i,j}$ : $P_{i,j}$ に含まれる行（p）と列（q）のインデックス\n",
    "\n",
    "$a_{i,j,m}$ : 出力される配列のi行j列、kチャンネルの値\n",
    "\n",
    "$x_{p,q,k}$ : 入力の配列のp行q列、kチャンネルの値\n",
    "\n",
    "ある範囲の中でチャンネル方向の軸は残したまま最大値を計算することになります。\n",
    "\n",
    "バックプロパゲーションのためには、フォワードプロパゲーションのときの最大値のインデックス \n",
    "$(p,q)$ を保持しておく必要があります。フォワード時に最大値を持っていた箇所にそのままの誤差を流し、そこ以外には0を入れるためです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxPool2D:\n",
    "    '''\n",
    "    2次元畳み込み層クラス\n",
    "    Parameters\n",
    "    --------------\n",
    "     pool_h : int\n",
    "         対象領域の高さ\n",
    "     pool_w : int\n",
    "         対象領域の幅\n",
    "     filter_size : int\n",
    "         フィルタの大きさ(縦横同じ)\n",
    "     stride : int\n",
    "         ストライド数\n",
    "     pad : int\n",
    "        パディング数    \n",
    "\n",
    "    Attributes\n",
    "    -------------\n",
    "    X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        Xのコピー\n",
    "    arg_max : 次の形のndarray, shape (N * out_h * out_w,)\n",
    "        \n",
    "    '''\n",
    "    def __init__(self, pool_h=3, pool_w=3, stride=1, pad=0):\n",
    "        #ハイパーパラメータ\n",
    "        self.pool_h = pool_h #対象領域の高さ\n",
    "        self.pool_w = pool_w #対象領域の幅\n",
    "        self.stride = stride #ストライド数\n",
    "        self.pad = pad #パディング数\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.X = None #Xのコピー\n",
    "        self.arg_max = None #\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        out : \n",
    "            maxプーリングした結果\n",
    "\n",
    "        \"\"\"\n",
    "        #サイズを取得\n",
    "        N, C, H, W = X.shape\n",
    "        \n",
    "        #出力のサイズを取得\n",
    "        out_h, out_w = self._out_shape(H, self.pool_h, W, self.pool_w)\n",
    "        \n",
    "        #im2col\n",
    "        col = self._im2col(X, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        \n",
    "        #max_pooling\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        #配列を変換\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2) #(N, out_h, out_w, C)→(N, C, out_h, out_w)\n",
    "\n",
    "        #バックワードで使用\n",
    "        self.X = X\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        dout : \n",
    "            outに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dX : 2次元配列\n",
    "            Xに関する損失Lの勾配\n",
    "        \"\"\"        \n",
    "        #位置を変える\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        #col2im\n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dX = self._col2im(dcol, self.X.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    def _im2col(self, input_data, FH, FW, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_data : 次の形のndarray, shape (N, C, H ,W)\n",
    "            (データ数, チャンネル, 高さ, 幅)の4次元配列からなる入力データ\n",
    "        filter_h : int\n",
    "            フィルターの高さ\n",
    "        filter_w : int\n",
    "            フィルターの幅\n",
    "        stride : int\n",
    "            ストライド\n",
    "        pad : int\n",
    "            パディング\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        col : 2次元配列\n",
    "        \"\"\"\n",
    "        #サイズを取得\n",
    "        N, C, H, W = input_data.shape\n",
    "        \n",
    "        #出力されるサイズ\n",
    "        out_h, out_w = self._out_shape(H, FH, W, FW)\n",
    "\n",
    "        #パディング\n",
    "        img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "        \n",
    "        #ゼロ配列を用意し、結果を格納\n",
    "        col = np.zeros((N, C, FH, FW, out_h, out_w))\n",
    "        for y in range(FH):\n",
    "            y_max = y + stride * out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + stride * out_w\n",
    "                col[:, :, y, x, :, :] = img[:, :, y: y_max: stride, x: x_max: stride]\n",
    "\n",
    "        #位置変換、reshape\n",
    "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N * out_h * out_w, -1) \n",
    "\n",
    "        return col\n",
    "    \n",
    "    \n",
    "    def _col2im(self, col, input_shape, FH, FW, stride=1, pad=0):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        col : \n",
    "            \n",
    "        input_shape : \n",
    "            入力データの形状（例：(10, 1, 28, 28)）\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "        stride : int\n",
    "            ストライド\n",
    "        pad : int\n",
    "            パディング\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        col2imの結果\n",
    "        \"\"\"\n",
    "        #サイズ\n",
    "        N, C, H, W = input_shape\n",
    "\n",
    "        #出力のサイズ\n",
    "        out_h, out_w = self._out_shape(H, FH, W, FW)\n",
    "        \n",
    "        #reshape、位置変換\n",
    "        col = col.reshape(N, out_h, out_w, C, FH, FW).transpose(0, 3, 4, 5, 1, 2) \n",
    "\n",
    "        #ゼロ配列を用意し、結果を格納\n",
    "        img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "        for y in range(FH):\n",
    "            y_max = y + stride*out_h\n",
    "            for x in range(FW):\n",
    "                x_max = x + stride*out_w\n",
    "                img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "        return img[:, :, pad:H + pad, pad:W + pad]\n",
    "    \n",
    "    \n",
    "    def _out_shape(self, H, FH, W, FW):\n",
    "        '''\n",
    "        出力サイズを計算する関数\n",
    "\n",
    "        Parameters\n",
    "        --------------\n",
    "        H : int\n",
    "            高さ\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        W : int\n",
    "            幅\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        out_h : int\n",
    "            出力するときの高さ\n",
    "        out_w : int\n",
    "            出力するときの幅\n",
    "        '''\n",
    "        out_h = 1 + int((H - FH) / self.stride)\n",
    "        out_w = 1 + int((W- FW) / self.stride)\n",
    "        \n",
    "        return out_h, out_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】平滑化\n",
    "\n",
    "平滑化するためのクラスFlatten()を作成してください。\n",
    "\n",
    "フォワードのときはチャンネル、高さ、幅の3次元を1次元にreshapeします。その値は記録しておき、バックワードのときに再びreshapeによって形を戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    '''\n",
    "    平滑化を行うクラス\n",
    "    \n",
    "    Attribute\n",
    "    -----------\n",
    "    X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        入力\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.X_shape = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        フォワード\n",
    "\n",
    "        Parameters\n",
    "        -------------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        X_1d : 次の形のndarray, shape (N, C, H ,W)\n",
    "        '''\n",
    "        #1次元にする\n",
    "        X_1d = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        #shapeを記録\n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        return X_1d\n",
    "    \n",
    "\n",
    "    def backward(self, X):\n",
    "        '''\n",
    "        バックワード\n",
    "\n",
    "        Parameters\n",
    "        -------------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        '''\n",
    "        #shapeを戻す\n",
    "        X = X.reshape(self.X_shape)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】学習・推定\n",
    "\n",
    "作成したConv2dを使用してMNISTの分類を学習・推定してください。\n",
    "\n",
    "この段階では精度は気にせず、動くことを確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ScratchDeepNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    epoc : int\n",
    "        エポック数\n",
    "    activaiton : {'sigmoid', 'tanh', 'relu'} default 'relu'\n",
    "        活性化関数の種類\n",
    "    solver :  {'sgd', 'adagrad'}, default 'adam'\n",
    "        最適化手法の種類\n",
    "    alpha : float\n",
    "        学習率\n",
    "    batch_size : int\n",
    "        バッチサイズ\n",
    "    initial : {'simple', 'xavier', 'he'} default 'he'\n",
    "        重みの初期化方法\n",
    "    sigma : float\n",
    "        重みパラメータ(ガウス分布の標準偏差)\n",
    "    n_nodes1 : int\n",
    "        1層目の数\n",
    "    n_nodes2 : int\n",
    "        2層目の数\n",
    "    n_output : int\n",
    "        出力層の数\n",
    "    verbose : bool\n",
    "        学習過程の出力の有無\n",
    "        \n",
    "    Attributes\n",
    "    -------------\n",
    "    conv1, 2, 3 : インスタンス\n",
    "        畳み込み層のインスタンス\n",
    "    pool1, 2 : インスタンス\n",
    "        プーリング層のインスタンス\n",
    "    FC1, 2 : インスタンス\n",
    "        結合層のインスタンス\n",
    "    activation1, 2, 3 : インスタンス\n",
    "        活性化関数のインスタンス\n",
    "    flat : インスタンス\n",
    "        平滑化するインスタンス\n",
    "    loss_list : list\n",
    "        学習用データの損失を記録するリスト\n",
    "    mini_loss_list : list\n",
    "        バッチサイズごとの学習用データの損失を記録するリスト\n",
    "    val_loss_list : list\n",
    "        検証用データの損失を記録するリスト\n",
    "    mini_val_loss_list : list\n",
    "        バッチサイズごとの検証用データの損失を記録するリスト\n",
    "    \"\"\"\n",
    "    def __init__(self, epoc=10, activation='relu', solver='sgd', alpha=0.005,\n",
    "                             batch_size=20, initial='he', sigma=0.005, n_nodes1=200, \n",
    "                             n_nodes2=100, filter_num=3,  filter_size=3, verbose=True, \n",
    "                            stride=1, pad=0):\n",
    "        #ハイパーパラメータ \n",
    "        self.epoc            = epoc              #エポック数\n",
    "        self.activation   = activation     #活性化関数\n",
    "        self.solver          = solver            #最適化の手法\n",
    "        self.alpha           = alpha             #学習率\n",
    "        self.batch_size = batch_size   #バッチサイズ\n",
    "        self.initial           = initial             #重みの初期化方法\n",
    "        self.sigma          = sigma            #重みパラメータ\n",
    "        self.n_nodes1   = n_nodes1    #1層目のノード数\n",
    "        self.n_nodes2   = n_nodes2    #2層目のノード数\n",
    "        self.filter_num  = filter_num    #フィルタの数\n",
    "        self.filter_size   = filter_size    #フィルタのサイズ\n",
    "        self.verbose      = verbose        #学習過程の出力(True : 有, False : 無)\n",
    "        self.stride          = stride           #ストライド\n",
    "        self.pad             = pad               #パディング\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.conv1 = None #畳み込み層のインスタンス\n",
    "        self.conv2 = None #畳み込み層のインスタンス\n",
    "        self.conv3 = None #畳み込み層のインスタンス\n",
    "        self.pool1  = None #プーリング層のインスタンス\n",
    "        self.pool2  = None #プーリング層のインスタンス\n",
    "        self.FC1     = None #結合層のインスタンス\n",
    "        self.FC2     = None #結合層のインスタンス\n",
    "        self.activation1            = None #活性化関数のインスタンス\n",
    "        self.activation2             = None #活性化関数のインスタンス\n",
    "        self.activation3             = None #活性化関数のインスタンス\n",
    "        self.flat                           = None #平滑化するインスタンス\n",
    "        self.loss_list                  = None #学習用データの損失を記録する配列\n",
    "        self.mini_loss_list         = None #バッチサイズごとの学習用データの損失を記録する配列\n",
    "        self.val_loss_list           = None #検証用データの損失を記録する配列\n",
    "        self.mini_val_loss_list = None #バッチサイズごとの検証用データの損失を記録する配列\n",
    "\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        #1次元なら2次元にする\n",
    "        if X.ndim == 1:\n",
    "            X = X[:, np.newaxis]\n",
    "        if y.ndim == 1:\n",
    "            y = y[:, np.newaxis]\n",
    "            \n",
    "        #one_hotエンコーディング\n",
    "        n_output = np.unique(y).shape[0]\n",
    "        y_onehot = self._one_hot(y, n_output)\n",
    "        \n",
    "        #ミニバッチを取得するクラスをインスタンス化\n",
    "        train_mini_batch = GetMiniBatch(X, y_onehot, self.batch_size)\n",
    "        \n",
    "        #valがあるとき\n",
    "        if X_val is not None and y_val is not None:\n",
    "            \n",
    "            #1次元なら2次元にする\n",
    "            if X.ndim == 1:\n",
    "                X_val = X_val[:, np.newaxis]\n",
    "            if y_val.ndim == 1:\n",
    "                y_val = y_val[:, np.newaxis]\n",
    "            \n",
    "            #one-hotエンコーディング\n",
    "            y_val_onehot = self._one_hot(y_val, n_output) \n",
    "            \n",
    "            #インスタンス化\n",
    "            test_mini_batch = GetMiniBatch(X_val, y_val_onehot)\n",
    "        \n",
    "        #活性化関数の選択\n",
    "        if self.activation == 'sigmoid':\n",
    "            activate1 = Sigmoid()\n",
    "            activate2 = Sigmoid()\n",
    "            activate3 = Sigmoid()\n",
    "            activate4 = Sigmoid()\n",
    "        elif self.activation == 'tanh':\n",
    "            activate1 = Tanh()\n",
    "            activate2 = Tanh()\n",
    "            activate3 = Tanh()\n",
    "            activate4 = Tanh()\n",
    "        elif self.activation == 'relu':\n",
    "            activate1 = Relu()\n",
    "            activate2 = Relu()\n",
    "            activate3 = Relu()\n",
    "            activate4 = Relu()\n",
    "        \n",
    "        #最適化手法の選択\n",
    "        if self.solver == 'sgd':\n",
    "            optimizer1 = SGD(self.alpha)\n",
    "            optimizer2 = SGD(self.alpha)\n",
    "            optimizer3 = SGD(self.alpha) \n",
    "            optimizer4 = SGD(self.alpha)\n",
    "            optimizer5 = SGD(self.alpha) \n",
    "        elif self.solver == 'adagrad':\n",
    "            optimizer1 = AdaGrad(self.alpha)\n",
    "            optimizer2 = AdaGrad(self.alpha)\n",
    "            optimizer3 = AdaGrad(self.alpha)\n",
    "            optimizer4 = AdaGrad(self.alpha)\n",
    "            optimizer5 = AdaGrad(self.alpha)\n",
    "            \n",
    "        #重みの初期化方法の選択\n",
    "        if self.initial == 'simple':\n",
    "            initializer1 = SimpleInitializer(self.sigma)\n",
    "            initializer2 = SimpleInitializer(self.sigma)\n",
    "            initializer3 = SimpleInitializer(self.sigma)\n",
    "            initializer4 = SimpleInitializer(self.sigma)\n",
    "            initializer5 = SimpleInitializer(self.sigma)\n",
    "        elif self.initial == 'xavier':\n",
    "            initializer1 = XavierInitializer()\n",
    "            initializer2 = XavierInitializer()\n",
    "            initializer3 = XavierInitializer()\n",
    "            initializer4 = XavierInitializer()\n",
    "            initializer5 = XavierInitializer()\n",
    "        elif self.initial == 'he':\n",
    "            initializer1 = HeInitializer()\n",
    "            initializer2 = HeInitializer()\n",
    "            initializer3 = HeInitializer()\n",
    "            initializer4 = HeInitializer()\n",
    "            initializer5 = HeInitializer()        \n",
    "\n",
    "        #畳み込み層および活性化関数クラスのインスタンス化\n",
    "        self.conv1 = Conv2d(initializer1, optimizer1, self.filter_num, X.shape[1], self.filter_size)\n",
    "        self.activation1 = activate1\n",
    "        self.pool1 = MaxPool2D()\n",
    "        self.conv2 = Conv2d(initializer2, optimizer2, self.filter_num, self.filter_num, self.filter_size)\n",
    "        self.activation2 = activate2\n",
    "        self.pool2 = MaxPool2D()\n",
    "        self.conv3 = Conv2d(initializer3, optimizer3, self.filter_num, self.filter_num, self.filter_size)\n",
    "        self.activation3 = activate3\n",
    "        \n",
    "        #平滑化クラスのインスタンス化\n",
    "        self.flat = Flatten()\n",
    "        \n",
    "        #全結合前のサイズ\n",
    "        OH, OW = self._out_shape(X.shape[2], self.filter_size, X.shape[3], self.filter_size, 'conv')\n",
    "        OH, OW = self._out_shape(OH, self.filter_size, OW, self.filter_size, 'pool')\n",
    "        OH, OW = self._out_shape(OH, self.filter_size, OW, self.filter_size, 'conv')\n",
    "        OH, OW = self._out_shape(OH, self.filter_size, OW, self.filter_size, 'pool')\n",
    "        OH, OW = self._out_shape(OH, self.filter_size, OW, self.filter_size, 'conv')\n",
    "        size = OH * OW * self.filter_num\n",
    "        \n",
    "        #結合層および活性化関数クラスのインスタンス化\n",
    "        self.FC1 = FC(size, self.n_nodes1, initializer4, optimizer4) \n",
    "        self.activation4 = activate4\n",
    "        self.FC2 = FC(self.n_nodes1, y_onehot.shape[1], initializer5, optimizer5) \n",
    "        self.activation5 = Softmax()\n",
    "\n",
    "        #損失を記録するリスト(エポックごと)\n",
    "        self.loss_list = []\n",
    "        self.val_loss_list= []\n",
    "        \n",
    "        #エポック数だけ繰り返す\n",
    "        for i in range(self.epoc):\n",
    "            \n",
    "            #損失を記録するリスト(イテレーション)\n",
    "            self.mini_loss_list = []\n",
    "            \n",
    "            #イテレーション数実行\n",
    "            for mini_X_train, mini_y_train in train_mini_batch:\n",
    "                \n",
    "                #フォワード\n",
    "                self._forward(mini_X_train)\n",
    "                \n",
    "                #バックワード\n",
    "                #全結合層\n",
    "                dA5, mini_loss = self.activation5.backward(mini_y_train) \n",
    "                dZ4 = self.FC2.backward(dA5)          \n",
    "                dA4 = self.activation4.backward(dZ4) \n",
    "                dZ3 = self.FC1.backward(dA4)            \n",
    "                \n",
    "                #shapeを戻す\n",
    "                dZ3 = self.flat.backward(dZ3)\n",
    "                \n",
    "                #畳み込み層\n",
    "                dA3 = self.activation3.backward(dZ3)\n",
    "                dP2 = self.conv3.backward(dA3)\n",
    "                dZ2 = self.pool2.backward(dP2)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dP1 = self.conv2.backward(dA2)\n",
    "                dZ1 = self.pool1.backward(dP1)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dX = self.conv1.backward(dA1)   \n",
    "                \n",
    "                #イテレーションごとの損失をリストに格納\n",
    "                self.mini_loss_list.append(mini_loss)\n",
    "\n",
    "            #1エポックの損失をリストに格納\n",
    "            loss = np.mean(self.mini_loss_list)\n",
    "            self.loss_list.append(loss)\n",
    "\n",
    "            #valがあるときもイテレーション数実行\n",
    "            if X_val is not None and y_val is not None:\n",
    "                \n",
    "                self.mini_val_loss_list = []\n",
    "                for mini_X_val, mini_y_val in test_mini_batch:\n",
    "                    \n",
    "                    #確率を予測\n",
    "                    self._forward(mini_X_val)\n",
    "\n",
    "                    #損失を計算\n",
    "                    _, mini_val_loss = self.activation5.backward(mini_y_val) \n",
    "                    \n",
    "                    #イテレーションごとの損失をリストに格納\n",
    "                    self.mini_val_loss_list.append(mini_val_loss)\n",
    "\n",
    "                #1エポックの損失をリストに格納\n",
    "                val_loss = np.mean(self.mini_val_loss_list)\n",
    "                self.val_loss_list.append(val_loss)\n",
    "\n",
    "            #学習過程を出力する場合\n",
    "            if self.verbose == True:\n",
    "                print('学習用データの学習過程' + str(i + 1) + 'epoc目 : ' + str(self.loss_list[i]))\n",
    "\n",
    "                #検証用データあり\n",
    "                if X_val is not None or y_val is not None:\n",
    "                    print('検証用データの学習過程' + str(i + 1) + 'epoc目 : ' + str(self.val_loss_list[i]))\n",
    "                    \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        y_pred = self._forward(X)\n",
    "        \n",
    "        return np.argmax(y_pred, axis=1)\n",
    "            \n",
    "\n",
    "    def _one_hot(self, y, n_output):\n",
    "        '''\n",
    "        one-hotエンコーディングを行う関数\n",
    "       \n",
    "       Parameters\n",
    "        ---------------\n",
    "        y : 次の形のndarray, shape (n_features, 1)\n",
    "            正解ラベルのベクトル\n",
    "        n_output : int\n",
    "            正解ラベルのユニーク値\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        one_hot.T : 次の形のndarray, shape (n_features, n_output)\n",
    "        '''\n",
    "        #0配列を用意\n",
    "        one_hot = np.zeros((n_output, y.shape[0]))\n",
    "        \n",
    "        #0配列の該当する位置に1を挿入\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            one_hot[val, idx] = 1\n",
    "\n",
    "        return one_hot.T        \n",
    "    \n",
    "    \n",
    "    def _forward(self, X):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        \n",
    "        Parameters\n",
    "        --------------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データ\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z5 : 次の形のndarray, shape (n_samples, n_output)\n",
    "            フォワードの結果\n",
    "        '''\n",
    "        #畳み込み(1層目)\n",
    "        A1 = self.conv1.forward(X) \n",
    "        Z1 = self.activation1.forward(A1)    \n",
    "        P1 = self.pool1.forward(Z1)\n",
    "\n",
    "        #畳み込み(2層目)  \n",
    "        A2 = self.conv2.forward(P1) \n",
    "        Z2 = self.activation2.forward(A2)                \n",
    "        P2 = self.pool2.forward(Z2)           \n",
    "                \n",
    "        #畳み込み(3層目)  \n",
    "        A3 = self.conv3.forward(P2) \n",
    "        Z3 = self.activation3.forward(A3)  \n",
    "\n",
    "        #平滑化\n",
    "        Z3 = self.flat.forward(Z3)\n",
    "    \n",
    "        #全結合層\n",
    "        A4 = self.FC1.forward(Z3)                   \n",
    "        Z4 = self.activation4.forward(A4) \n",
    "        A5 = self.FC2.forward(Z4)             \n",
    "        Z5 = self.activation5.forward(A5)\n",
    "        \n",
    "        return Z5\n",
    "    \n",
    "    \n",
    "    def _out_shape(self, H, FH, W, FW, layer):\n",
    "        '''\n",
    "        出力サイズを計算する関数\n",
    "        \n",
    "        Parameters\n",
    "        --------------\n",
    "        H : int\n",
    "            高さ\n",
    "        FH : int\n",
    "            フィルターの高さ\n",
    "        W : int\n",
    "            幅\n",
    "        FW : int\n",
    "            フィルターの幅\n",
    "        layer : str\n",
    "            層の名前(conv or pool)\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        out_h : int\n",
    "            出力するときの高さ\n",
    "        out_w : int\n",
    "            出力するときの幅\n",
    "        '''\n",
    "        if layer == 'conv':\n",
    "            out_h = 1 + int((H + 2 * self.pad - FH) / self.stride)\n",
    "            out_w = 1 + int((W + 2 * self.pad - FW) / self.stride)\n",
    "        elif layer == 'pool':\n",
    "            out_h = 1 + int((H - FH) / self.stride)\n",
    "            out_w = 1 + int((W - FW) / self.stride)\n",
    "        \n",
    "        return out_h, out_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : インスタンス\n",
    "        初期化方法のインスタンス\n",
    "    optimizer : インスタンス\n",
    "        最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer #最適化手法\n",
    "        \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "\n",
    "    \n",
    "    def forward(self, Z1):\n",
    "        \"\"\"\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z1 : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        Z2 : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.Z = Z1.copy()\n",
    "        \n",
    "        #バイアスと重みを結合\n",
    "        Z2 = np.dot(Z1, self.W) + self.B\n",
    "        \n",
    "        return Z2\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape(batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        #Zに関する損失の勾配を計算\n",
    "        self.dB = dA \n",
    "        self.dW = np.dot(self.Z.T, dA) \n",
    "        dZ = np.dot(dA, self.W.T) \n",
    "        \n",
    "        # 重み、バイアスの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma #重みパラメータ\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "            前の層のノード数\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルターのサイズ(縦横同じ)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み\n",
    "        if filter_num is not None and C is not None and filter_size is not None:\n",
    "            W =  self.sigma * np.random.randn(filter_num, C, filter_size, filter_size) \n",
    "       \n",
    "        #全結合\n",
    "        if n_nodes1 is not None and n_nodes2 is not None:\n",
    "            W =  self.sigma * np.random.randn(n_nodes1, n_nodes2) \n",
    "\n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :次の形のndarray, shape (n_nodes2)\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierの初期値のクラス\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルタサイズ\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み層\n",
    "        if filter_num and C and filter_size is not None:\n",
    "            W =  np.random.randn(filter_num, C, filter_size, filter_size) / np.sqrt(filter/num) \n",
    "        \n",
    "        #全結合層\n",
    "        else:\n",
    "            W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1) \n",
    "    \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (n_nodes2, )\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heの初期値のクラス\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルタサイズ\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み層\n",
    "        if filter_num and C and filter_size is not None:\n",
    "            W = np.random.randn(filter_num, C, filter_size, filter_size) * np.sqrt(2 / filter_num)\n",
    "       \n",
    "        #全結合層\n",
    "        else:\n",
    "            W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
    "    \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (n_nodes2, )\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最適化手法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : float\n",
    "        学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha #学習率\n",
    "        \n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : インスタンス\n",
    "            更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : インスタンス\n",
    "            更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        #バッチサイズで割る\n",
    "        layer.W -= self.alpha* layer.dW / layer.dB.shape[0] #(n_nodes1, n_nodes2)\n",
    "        layer.B -= self.alpha* layer.dB.mean(axis=0) #(n_nodes2)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    AdaGradの最適化のクラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : 学習率\n",
    "    \n",
    "    Attributes\n",
    "    -------------\n",
    "    H_W : ndarray\n",
    "        前のイテレーションまでの重みの勾配の二乗和\n",
    "    H_B : ndarray\n",
    "        前のイテレーションまでのバイアスの勾配の二乗和\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        #ハイパーパラメータ\n",
    "        self.alpha = alpha #学習率\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.H_W= None #重みの勾配の二乗和の配列\n",
    "        self.H_B = None #バイアスの勾配の二乗和の配列\n",
    "        \n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : インスタンス\n",
    "            更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : インスタンス\n",
    "            更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        #self.Hの初期化\n",
    "        if self.H_W is None:\n",
    "            self.H_W = np.zeros(layer.W.shape)\n",
    "        if self.H_B is None:\n",
    "            self.H_B = np.zeros(layer.B.shape)\n",
    "        \n",
    "        #更新    \n",
    "        self.H_W += (layer.dW / layer.dB.shape[0]) ** 2 #重みの勾配の二乗和\n",
    "        self.H_B += (layer.dB.mean(axis=0)) ** 2 #バイアスの二乗和\n",
    "        layer.W -= self.alpha / np.sqrt(self.H_W + 1e-7) * layer.dW / layer.dB.shape[0] #重み\n",
    "        layer.B -= self.alpha / np.sqrt(self.H_B + 1e-7) * layer.dB.mean(axis=0) #バイアス \n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    シグモイド関数のクラス\n",
    "    Attributes\n",
    "    --------------\n",
    "    Z : ndarray\n",
    "        活性化関数を計算した配列\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None #活性化関数の配列\n",
    "    \n",
    "\n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.Z = 1 / (1 + np.exp(-A)) \n",
    "        \n",
    "        return self.Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        dA = dZ * (1 - self.Z) * self.Z\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    '''\n",
    "    ハイパポリックタンジェント関数のクラス\n",
    "    Attributes\n",
    "    --------------\n",
    "    Z : ndarray\n",
    "        活性化関数を計算した配列\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None #活性化関数の配列\n",
    "\n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.Z =  np.tanh(A)\n",
    "        \n",
    "        return  self.Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        dA = dZ * (1 - self.Z**2)\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    '''\n",
    "    ReLU関数のクラス\n",
    "    Attributes\n",
    "    --------------\n",
    "    X : ndarray\n",
    "        特徴量ベクトルと重みとバイアスを計算した配列\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.X = None #特徴量ベクトルと重みとバイアスを計算した配列\n",
    "\n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.X = A.copy()\n",
    "        \n",
    "        #Aが0以下なら0にする\n",
    "        Z = np.maximum(0, A)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        #forwardで0以下の部分を0にする\n",
    "        dA = np.where(self.X > 0, dZ, 0)\n",
    "\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    ソフトマックス関数のクラス\n",
    "    Attributes\n",
    "    --------------\n",
    "    Z : ndarray\n",
    "        活性化関数を計算した配列\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None #活性化関数の配列\n",
    "    \n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_output)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_output)\n",
    "            ソフトマックス関数の計算結果\n",
    "        '''\n",
    "        #オーバーフロー対策\n",
    "        c = np.max(A)\n",
    "        exp_A = np.exp(A - c)\n",
    "        \n",
    "        #分母\n",
    "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
    "\n",
    "        self.Z = exp_A / sum_exp_A\n",
    "        \n",
    "        return self.Z\n",
    "\n",
    "    \n",
    "    def backward(self, y):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        y : 次の形のndarray, shape (batch_size, n_output)\n",
    "            正解ラベルのベクトル\n",
    "        Z : 次の形のndarray, shape (batch_size, n_output)\n",
    "            フォワードプロバケーションの出力\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        #交差エントロピー誤差の計算\n",
    "        loss_sum = np.sum(y * np.log(self.Z), axis=1)\n",
    "        loss = -np.mean(loss_sum)\n",
    "        \n",
    "        #勾配の計算\n",
    "        dA = self.Z - y\n",
    "        \n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データの学習過程1epoc目 : 1.7358309898089987\n",
      "検証用データの学習過程1epoc目 : 0.4216033473197089\n",
      "学習用データの学習過程2epoc目 : 0.30544294004148564\n",
      "検証用データの学習過程2epoc目 : 0.21221516824381828\n",
      "学習用データの学習過程3epoc目 : 0.17856906483758142\n",
      "検証用データの学習過程3epoc目 : 0.1488838633302371\n",
      "学習用データの学習過程4epoc目 : 0.12848283797604457\n",
      "検証用データの学習過程4epoc目 : 0.12697778099371276\n",
      "学習用データの学習過程5epoc目 : 0.09998620047978056\n",
      "検証用データの学習過程5epoc目 : 0.11795979639624389\n",
      "学習用データの学習過程6epoc目 : 0.08266193714886177\n",
      "検証用データの学習過程6epoc目 : 0.11044843504788306\n",
      "学習用データの学習過程7epoc目 : 0.0700490404921777\n",
      "検証用データの学習過程7epoc目 : 0.1053454657820715\n",
      "学習用データの学習過程8epoc目 : 0.05961687827264721\n",
      "検証用データの学習過程8epoc目 : 0.10279017481073631\n",
      "学習用データの学習過程9epoc目 : 0.050709074743171725\n",
      "検証用データの学習過程9epoc目 : 0.09803442270086483\n",
      "学習用データの学習過程10epoc目 : 0.04324512701017189\n",
      "検証用データの学習過程10epoc目 : 0.09822929719511998\n"
     ]
    }
   ],
   "source": [
    "cls = ScratchDeepNeuralNetrowkClassifier()\n",
    "cls.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cls.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_curve(loss, val_loss):\n",
    "    '''\n",
    "    学習曲線を出力する関数\n",
    "    '''\n",
    "    plt.plot(loss)\n",
    "    plt.plot(val_loss)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('Cost curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_curve(cls.loss_list, cls.val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalution(y_test, y_pred):\n",
    "    '''\n",
    "     分類問題の指標値を出力する関数\n",
    " \n",
    "     Paraeters\n",
    "     -------------\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "        正解値\n",
    "    y_pred : 次の形のndarray, shape (n_samples, )\n",
    "        予測したラベル\n",
    "    '''\n",
    "    #accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('accuracy :', accuracy)\n",
    "\n",
    "    #precision\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    print('precision :', precision)\n",
    "\n",
    "    #recall\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    print('recall :', recall)\n",
    "\n",
    "    #f1\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print('f1 :', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.9731\n",
      "precision : 0.9729793416022826\n",
      "recall : 0.9730799709786432\n",
      "f1 : 0.9729535014460682\n"
     ]
    }
   ],
   "source": [
    "evalution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】（アドバンス課題）LeNet\n",
    "\n",
    "CNNで画像認識を行う際は、フィルタサイズや層の数などを１から考えるのではなく、有名な構造を利用することが一般的です。\n",
    "\n",
    "現在では実用的に使われることはありませんが、歴史的に重要なのは1998年のLeNetです。この構造を再現して動かしてみましょう。\n",
    "\n",
    "[Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※上記論文から引用\n",
    "\n",
    "サブサンプリングとは現在のプーリングに相当するものです。現代風に以下のように作ってみることにします。活性化関数も当時はシグモイド関数ですが、ReLUとします。\n",
    "\n",
    "- 畳み込み層　出力チャンネル数6、フィルタサイズ5$\\times$5、ストライド1\n",
    "- ReLU\n",
    "- 最大プーリング\n",
    "- 畳み込み層　出力チャンネル数16、フィルタサイズ5$\\times$5、ストライド1\n",
    "- ReLU\n",
    "- 最大プーリング\n",
    "- 平滑化\n",
    "- 全結合層　出力ノード数120\n",
    "- ReLU\n",
    "- 全結合層　出力ノード数84\n",
    "- ReLU\n",
    "- 全結合層　出力ノード数10\n",
    "- ソフトマックス関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題7】（アドバンス課題）有名な画像認識モデルの調査\n",
    "\n",
    "CNNの代表的な構造としてははAlexNet(2012)、VGG16(2014)などがあります。こういったものはフレームワークで既に用意されていることも多いです。\n",
    "\n",
    "どういったものがあるか簡単に調べてまとめてください。名前だけでも見ておくと良いでしょう。\n",
    "\n",
    "参考\n",
    "\n",
    "[Applications - Keras Documentation](https://keras.io/ja/applications/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Xception\n",
    "- VGG16\n",
    "- VGG19\n",
    "- ResNet50\n",
    "- InceptionV3\n",
    "- InceptionResNetV2\n",
    "- MobileNet\n",
    "- DenseNet\n",
    "- NASNet\n",
    "- MobileNetV2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題8】（アドバンス課題）平均プーリングの作成\n",
    "\n",
    "平均プーリング層のクラスAveragePool2Dを作成してください。\n",
    "\n",
    "範囲内の最大値ではなく、平均値を出力とするプーリング層です。\n",
    "\n",
    "画像認識関係では最大プーリング層が一般的で、平均プーリングはあまり使われません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題9】出力サイズとパラメータ数の計算\n",
    "\n",
    "CNNモデルを構築する際には、全結合層に入力する段階で特徴量がいくつになっているかを事前に計算する必要があります。\n",
    "\n",
    "また、巨大なモデルを扱うようになると、メモリや計算速度の関係でパラメータ数の計算は必須になってきます。フレームワークでは各層のパラメータ数を表示させることが可能ですが、意味を理解していなくては適切な調整が行えません。\n",
    "\n",
    "以下の3つの畳み込み層の出力サイズとパラメータ数を計算してください。パラメータ数についてはバイアス項も考えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_outshape_parameter(H, FH, W, FW, FN, P, S, IC):\n",
    "    '''\n",
    "    出力サイズとパラメータを計算する関数\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    H : int\n",
    "        高さ\n",
    "    FH : int\n",
    "        フィルターの高さ\n",
    "    W : int\n",
    "        幅\n",
    "    FW : int\n",
    "        フィルターの幅\n",
    "    FN : int\n",
    "        フィルタ数\n",
    "    P : int\n",
    "        パディング\n",
    "    S : int\n",
    "        ストライド\n",
    "    IC : int\n",
    "        入力のチャンネル数\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    out_h : int\n",
    "        出力の高さ\n",
    "    out_w : int\n",
    "        出力の幅\n",
    "    parameter : int \n",
    "        パラメータ\n",
    "    '''\n",
    "    out_h = int((H + 2 * P - FH) / S) + 1\n",
    "    out_w = int((W + 2 * P - FW) / S) + 1\n",
    "    parameter = FH * FW * IC * FN + FN\n",
    "        \n",
    "    return out_h, out_w, parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "- 入力サイズ : 144$\\times$144, 3チャンネル\n",
    "- フィルタサイズ : 3$\\times$3, 3チャンネル, 2フィルタ\n",
    "- ストライド : 1\n",
    "- パディング : なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ(OH × OW × FN) : 142 × 142 × 2\n",
      "パラメータ : 56\n"
     ]
    }
   ],
   "source": [
    "#入力サイズ\n",
    "H, W, IC = (144, 144, 3)\n",
    "\n",
    "#フィルタサイズ\n",
    "FH, FW, _ = (3, 3, 3)\n",
    "\n",
    "#フィルタ数\n",
    "FN = 2\n",
    "\n",
    "#ストライド\n",
    "S = 1\n",
    "\n",
    "#パディング\n",
    "P = 0\n",
    "\n",
    "#計算\n",
    "OH, OW, parameter = calc_outshape_parameter(H, FH, W, FW, FN, P, S, IC)\n",
    "\n",
    "print('出力サイズ(OH × OW × FN) : {} × {} × {}'.format(OH, OW, FN))\n",
    "print('パラメータ : {}'.format(parameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\n",
    "\n",
    "- 入力サイズ : 60$\\times$60, 24チャンネル\n",
    "- フィルタサイズ : 3$\\times$3, 24チャンネル, 2フィルタ\n",
    "- ストライド　: 1\n",
    "- パディング : なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ(OH × OW × FN) : 58 × 58 × 2\n",
      "パラメータ : 434\n"
     ]
    }
   ],
   "source": [
    "#入力サイズ\n",
    "H, W, IC = (60, 60, 24)\n",
    "\n",
    "#フィルタサイズ\n",
    "FH, FW, _ = (3, 3, 24)\n",
    "\n",
    "#フィルタ数\n",
    "FN = 2\n",
    "\n",
    "#ストライド\n",
    "S = 1\n",
    "\n",
    "#パディング\n",
    "P = 0\n",
    "\n",
    "#計算\n",
    "OH, OW, parameter = calc_outshape_parameter(H, FH, W, FW, FN, P, S, IC)\n",
    "\n",
    "print('出力サイズ(OH × OW × FN) : {} × {} × {}'.format(OH, OW, FN))\n",
    "print('パラメータ : {}'.format(parameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\n",
    "\n",
    "- 入力サイズ : 20$\\times$20, 10チャンネル\n",
    "- フィルタサイズ: 3$\\times$3, 10チャンネル, 2フィルタ\n",
    "- ストライド : 2\n",
    "- パディング : なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力サイズ(OH × OW × FN) : 9 × 9 × 2\n",
      "パラメータ : 182\n"
     ]
    }
   ],
   "source": [
    "#入力サイズ\n",
    "H, W, IC = (20, 20, 10)\n",
    "\n",
    "#フィルタサイズ\n",
    "FH, FW, _ = (3, 3, 10)\n",
    "\n",
    "#フィルタ数\n",
    "FN = 2\n",
    "\n",
    "#ストライド\n",
    "S = 2\n",
    "\n",
    "#パディング\n",
    "P = 0\n",
    "\n",
    "#計算\n",
    "OH, OW, parameter = calc_outshape_parameter(H, FH, W, FW, FN, P, S, IC)\n",
    "\n",
    "print('出力サイズ(OH × OW × FN) : {} × {} × {}'.format(OH, OW, FN))\n",
    "print('パラメータ : {}'.format(parameter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "＊最後の例は丁度良く畳み込みをすることができない場合です。フレームワークでは余ったピクセルを見ないという処理が行われることがあるので、その場合を考えて計算してください。端が欠けてしまうので、こういった設定は好ましくないという例です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題10】（アドバンス課題）フィルタサイズに関する調査\n",
    "\n",
    "畳み込み層にはフィルタサイズというハイパーパラメータがありますが、2次元畳み込み層において現在では3$\\times$3と1$\\times$1の使用が大半です。以下のそれぞれを調べたり、自分なりに考えて説明してください。\n",
    "\n",
    "7$\\times$7などの大きめのものではなく、3$\\times$3のフィルタが一般的に使われる理由\n",
    "高さや幅方向を持たない1$\\times$1のフィルタの効果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
