{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clc5C3jAv8Ll"
   },
   "source": [
    "# Sprint12課題 深層学習スクラッチ畳み込みニューラルネットワーク1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRSFk8uZv8Lm"
   },
   "source": [
    "## この課題の目的\n",
    "\n",
    "- スクラッチを通してCNNの基礎を理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boEwwqt9v8Ln"
   },
   "source": [
    "## スクラッチによる実装\n",
    "\n",
    "NumPyなど最低限のライブラリのみを使いアルゴリズムを実装していきます。\n",
    "\n",
    "Sprint11で作成したディープニューラルネットワークのクラスを拡張する形でCNNを作成します。まず、Sprint12で1次元畳み込み層を作成し、畳み込みの基礎を理解することを目指します。そして、Sprint13で一般的に画像に対して使われる2次元畳み込み層とプーリング層を作成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wimNXp8Uv8Ln"
   },
   "source": [
    "### 1次元畳み込み層\n",
    "\n",
    "畳み込みニューラルネットワークは画像に対して使われる2次元畳み込みが代表的ですが、理解を容易にするためにまずは1次元畳み込みを実装します。1次元畳み込みは系列データで使われることが多いです。畳み込みは任意の次元に対して考えることができ、立体データに対しての3次元畳み込みまでがフレームワークで一般的に用意されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O3O7GA-zv8Lo"
   },
   "source": [
    "### データセットの用意\n",
    "\n",
    "引き続きMNISTデータセットを使用します。1次元畳み込みでは全結合のニューラルネットワークと同様に平滑化されたものを入力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "04SFWTmev8Lo",
    "outputId": "9d1f62a7-94f9-444a-f81d-a3d330437c81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyJCFWVWv8Lt"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qEVdYEOv8Lx"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1, 784)\n",
    "X_test = X_test.reshape(-1, 1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqdK9KBpwjUF"
   },
   "outputs": [],
   "source": [
    "X_train = X_train[:480]\n",
    "y_train = y_train[:480]\n",
    "X_test = X_test[:120]\n",
    "y_test = y_test[:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vnRh8Eb1v8Ly",
    "outputId": "df08c83d-55be-4b79-8a8c-c323607a40b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "IwAqgf3Ev8L1",
    "outputId": "560259b4-52c2-4b0b-f136-fdc00e3c8f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 1, 784)\n",
      "(96, 1, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) \n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kzGd7E2sv8L3"
   },
   "source": [
    "### CNN分類器クラスの作成\n",
    "\n",
    "1次元畳み込みニューラルネットワークモデルのクラスScratch1dCNNClassifierを作成してください。Sprint11で作成したScratchDeepNeuralNetrowkClassifierを元にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZEMqpyRv8L4"
   },
   "source": [
    "## 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成\n",
    "\n",
    "チャンネル数を1に限定した1次元畳み込み層のクラスSimpleConv1dを作成してください。基本構造はsprint11で作成したFCクラスと同じになります。なお、重みの初期化に関するクラスは必要に応じて作り変えてください。Xavierの初期値などを使う点は全結合層と同様です。\n",
    "\n",
    "ここではパディングは考えず、ストライドも1に固定します。また、複数のデータを同時に処理することも考えなくて良く、バッチサイズは1のみに対応してください。この部分の拡張はアドバンス課題とします。\n",
    "\n",
    "フォワードプロパゲーションの数式は以下のようになります。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RCHDNxaiv8L4"
   },
   "source": [
    "$a_i$  : 出力される配列のi番目の値\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$x_{(i+s)}$ : 入力の配列の(i+s)番目の値\n",
    "\n",
    "$w_s$ : 重みの配列のs番目の値\n",
    "\n",
    "$b$ : バイアス項\n",
    "\n",
    "全てスカラーです。\n",
    "\n",
    "次に更新式です。ここがAdaGradなどに置き換えられる点は全結合層と同様です。\n",
    "\n",
    "$$\n",
    "w_s^{\\prime} = w_s - \\alpha \\frac{\\partial L}{\\partial w_s}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "La9Nh4Krv8L5"
   },
   "source": [
    "$$\n",
    "b^{\\prime} = b - \\alpha \\frac{\\partial L}{\\partial b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AmhtI_Bpv8L5"
   },
   "source": [
    "$\\alpha$  : 学習率\n",
    "\n",
    "$\\frac{\\partial L}{\\partial w_s}$ : $w_s$ に関する損失 $L$ の勾配\n",
    "\n",
    "$\\frac{\\partial L}{\\partial b}$ : $b$ に関する損失 $L$ の勾配\n",
    "\n",
    "勾配$\\frac{\\partial L}{\\partial w_s}$ や $\\frac{\\partial L}{\\partial b}$ を求めるためのバックプロパゲーションの数式が以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_s} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}x_{(i+s)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0uGBzX9v8L7"
   },
   "source": [
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \\sum_{i=0}^{N_{out}-1} \\frac{\\partial L}{\\partial a_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SoLVRQsRv8L7"
   },
   "source": [
    "$\\frac{\\partial L}{\\partial a_i}$ : 勾配の配列のi番目の値\n",
    "\n",
    "$N_{out}$ : 出力のサイズ\n",
    "\n",
    "前の層に流す誤差の数式は以下です。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial x_j} = \\sum_{s=0}^{F-1} \\frac{\\partial L}{\\partial a_{(j-s)}}w_s\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkktraHtv8L8"
   },
   "source": [
    "$\\frac{\\partial L}{\\partial x_j}$ : 前の層に流す誤差の配列のj番目の値\n",
    "\n",
    "ただし、$j-s<0$または$j-s>N_{out}-1$のとき$\\frac{\\partial L}{\\partial a_{(j-s)}} =0$です。\n",
    "\n",
    "全結合層との大きな違いは、重みが複数の特徴量に対して共有されていることです。この場合は共有されている分の誤差を全て足すことで勾配を求めます。計算グラフ上での分岐はバックプロパゲーションの際に誤差の足し算をすれば良いことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9f9N_8GJv8L9"
   },
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を1に限定した1次元畳み込み層クラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, filter_size, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes2, n_nodes1, filter_size)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "        #\n",
    "        self.X = None\n",
    "        self.index = None\n",
    "        self.n_out = None\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        a : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        #Xをコピー\n",
    "        self.X = X.copy()\n",
    "        \n",
    "        #配列作成\n",
    "        idx1 = np.arange(self.W.shape[0])\n",
    "        idx2 = np.arange(self.W.shape[0] - 1).reshape(-1, 1)\n",
    "        self.index = idx1 + idx2\n",
    "\n",
    "        #出力の計算\n",
    "        a = np.dot(X[idx1 + idx2], self.W.T) + self.B\n",
    "\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape(batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dX : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        #バイアス\n",
    "        dB = np.sum(dA)\n",
    "        \n",
    "        #重み\n",
    "        dW = np.dot(da, self.X[self.index])\n",
    "        \n",
    "        #0配列を用意\n",
    "        dX = np.zeros(self.X.shape[0])\n",
    "        \n",
    "        #n_out\n",
    "        self.n_out = self._n_out(self.X.shape[0], 0, self.W.shape[0], 1)\n",
    "                \n",
    "        #計算\n",
    "        for j in range(self.X.shape[0]):\n",
    "            for s in range(self.W.shape[0]):\n",
    "\n",
    "                #場合分け\n",
    "                if j - s < 0 or j - s > self.n_out - 1:\n",
    "                     dX[j] += 0 * self.W[s]\n",
    "                else:\n",
    "                    dX[j] += dA[j - s] * self.W[s]\n",
    "\n",
    "        \n",
    "        # 重み、バイアスの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dX\n",
    "    \n",
    "    \n",
    "    def _n_out(self, n_in, P, F, S):\n",
    "        '''\n",
    "        出力サイズの計算\n",
    "        \n",
    "        Parameters\n",
    "        --------------\n",
    "        n_in : int\n",
    "            入力のサイズ\n",
    "        P : int\n",
    "            パディング数\n",
    "        F : \n",
    "            フィルター(重み)のサイズ\n",
    "        S : \n",
    "            ストライドのサイズ\n",
    "            \n",
    "        returns\n",
    "        ---------\n",
    "        n_out : int\n",
    "            出力のサイズ\n",
    "        '''\n",
    "        n_out = int(((n_in + 2 * P - F) / S ) + 1)\n",
    "        \n",
    "        return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPX2kJIJv8L_"
   },
   "source": [
    "## 【問題2】1次元畳み込み後の出力サイズの計算\n",
    "\n",
    "畳み込みを行うと特徴量の数が変化します。どのように変化するかは以下の数式から求められます。パディングやストライドも含めています。この計算を行う関数を作成してください。\n",
    "\n",
    "$$\n",
    "N_{out} =  \\frac{N_{in}+2P-F}{S} + 1\n",
    "$$\n",
    "\n",
    "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
    "\n",
    "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
    "\n",
    "$P$ : ある方向へのパディングの数\n",
    "\n",
    "$F$ : フィルタのサイズ\n",
    "\n",
    "$S$ : ストライドのサイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gw2Xvpaqv8L_"
   },
   "outputs": [],
   "source": [
    "def n_out(n_in, P, F, S):\n",
    "    n_out = int(((n_in + 2 * P - F) / S ) + 1)\n",
    "    return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_xwHeA1pv8MD"
   },
   "source": [
    "## 【問題3】小さな配列での1次元畳み込み層の実験\n",
    "\n",
    "次に示す小さな配列でフォワードプロパゲーションとバックプロパゲーションが正しく行えているか確認してください。\n",
    "\n",
    "入力x、重みw、バイアスbを次のようにします。\n",
    "\n",
    "```python\n",
    "x = np.array([1,2,3,4])  \n",
    "w = np.array([3, 5, 7])  \n",
    "b = np.array([1]) \n",
    "```\n",
    "\n",
    "\n",
    "フォワードプロパゲーションをすると出力は次のようになります。\n",
    "\n",
    "```python\n",
    "a = np.array([35, 50])\n",
    "```\n",
    "\n",
    "次にバックプロパゲーションを考えます。誤差は次のようであったとします。\n",
    "\n",
    "```python\n",
    "delta_a = np.array([10, 20])\n",
    "```\n",
    "\n",
    "バックプロパゲーションをすると次のような値になります。\n",
    "\n",
    "```python\n",
    "delta_b = np.array([30])  \n",
    "delta_w = np.array([50, 80, 110])  \n",
    "delta_x = np.array([30, 110, 170, 140])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_k_HvPoSv8MD"
   },
   "source": [
    "### 実装上の工夫\n",
    "\n",
    "畳み込みを実装する場合は、まずはfor文を重ねていく形で構いません。しかし、できるだけ計算は効率化させたいため、以下の式を一度に計算する方法を考えることにします。\n",
    "\n",
    "$$\n",
    "a_i = \\sum_{s=0}^{F-1}x_{(i+s)}w_s+b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jt8bDO8fv8ME"
   },
   "source": [
    "バイアス項は単純な足し算のため、重みの部分を見ます。\n",
    "\n",
    "$$\n",
    "\\sum_{s=0}^{F-1}x_{(i+s)}w_s\n",
    "$$\n",
    "\n",
    "これは、xの一部を取り出した配列とwの配列の内積です。具体的な状況を考えると、以下のようなコードで計算できます。この例では流れを分かりやすくするために、各要素同士でアダマール積を計算してから合計を計算しています。これは結果的に内積と同様です。\n",
    "\n",
    "```python\n",
    "x = np.array([1, 2, 3, 4])\n",
    "w = np.array([3, 5, 7])\n",
    "\n",
    "a = np.empty((2, 3))\n",
    "\n",
    "indexes0 = np.array([0, 1, 2]).astype(np.int)\n",
    "indexes1 = np.array([1, 2, 3]).astype(np.int)\n",
    "\n",
    "a[0] = x[indexes0]*w # x[indexes0]は([1, 2, 3])である\n",
    "a[1] = x[indexes1]*w # x[indexes1]は([2, 3, 4])である\n",
    "\n",
    "a = a.sum(axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_SMA5msv8MF"
   },
   "source": [
    "ndarrayは配列を使ったインデックス指定ができることを利用した方法です。\n",
    "\n",
    "また、二次元配列を使えば一次元配列から二次元配列が取り出せます。\n",
    "\n",
    "```python\n",
    "x = np.array([1, 2, 3, 4])\n",
    "indexes = np.array([[0, 1, 2], [1, 2, 3]]).astype(np.int)\n",
    "\n",
    "print(x[indexes]) # ([[1, 2, 3], [2, 3, 4]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BXamV4iLv8MF"
   },
   "source": [
    "このこととブロードキャストなどをうまく組み合わせることで、一度にまとめて計算することも可能です。\n",
    "\n",
    "畳み込みの計算方法に正解はないので、自分なりに効率化していってください。\n",
    "\n",
    "<u>参考</u>\n",
    "\n",
    "以下のページのInteger array indexingの部分がこの方法についての記述です。\n",
    "\n",
    "[Indexing — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4XAioqvv8MG"
   },
   "source": [
    "#### ・フォワードプロバケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AdVo4O_v8MG"
   },
   "outputs": [],
   "source": [
    "#フォワードプロバケーションの初期値\n",
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "4-M-ipI2v8MI",
    "outputId": "5da18ba5-bf51-410d-f9e3-93f5daa12316"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 50])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#配列作成\n",
    "idx1 = np.arange(w.shape[0])\n",
    "idx2 = np.arange(w.shape[0] - 1).reshape(-1, 1)\n",
    "index = idx1 + idx2\n",
    "\n",
    "#出力の計算\n",
    "a = np.dot(x[index], w.T) + b\n",
    "        \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BX_k97tv8MO"
   },
   "outputs": [],
   "source": [
    "#バックプロバケーションの初期値\n",
    "da = np.array([10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "Su2DsME8v8MR",
    "outputId": "1ab91f4e-f826-4d84-af93-ee9a998d7ac0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = np.sum(da)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "6OxJSEIjv8MU",
    "outputId": "fd22c46b-a8e3-43c7-a49d-f09765791b19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 50,  80, 110])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw = np.dot(da, x[index])\n",
    "dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "id": "5q5tHz0cv8MX",
    "outputId": "0883fddd-0367-416c-d285-d3ec4b8a8323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30., 110., 170., 140.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0配列を用意\n",
    "dx = np.zeros(x.shape[0])\n",
    "\n",
    "#計算\n",
    "for j in range(x.shape[0]):\n",
    "    for s in range(w.shape[0]):\n",
    "        \n",
    "        #場合分け\n",
    "        if j - s < 0 or j - s > 1:\n",
    "             dx[j] += 0 * w[s]\n",
    "        else:\n",
    "            dx[j] += da[j - s] * w[s]\n",
    "\n",
    "dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXTxnFAvv8Ma"
   },
   "source": [
    "## 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成\n",
    "\n",
    "チャンネル数を1に限定しない1次元畳み込み層のクラスConv1dを作成してください。\n",
    "\n",
    "紙やホワイトボードを使い計算グラフを書きながら考えてください。\n",
    "\n",
    "例えば以下のようなx, w, bがあった場合は、\n",
    "\n",
    "```python\n",
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。  \n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。  \n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "```\n",
    "\n",
    "出力は次のようになります。\n",
    "\n",
    "```python\n",
    "a = np.array([[16, 22], [17, 23], [18, 24]]) # shape(3, 2)で、（出力チャンネル数、特徴量数）である。\n",
    "```\n",
    "\n",
    "入力が2チャンネル、出力が3チャンネルの例です。計算グラフを書いた上で、バックプロパゲーションも手計算で考えてみましょう。計算グラフの中には和と積しか登場しないので、微分を新たに考える必要はありません。\n",
    "\n",
    "補足\n",
    "\n",
    "チャンネル数を加える場合、配列をどういう順番にするかという問題があります。(バッチサイズ、チャンネル数、特徴量数)または(バッチサイズ、特徴量数、チャンネル数)が一般的で、ライブラリによって順番は異なっています。（切り替えて使用できるものもあります）\n",
    "\n",
    "今回のスクラッチでは自身の実装上どちらが効率的かを考えて選んでください。上記の例ではバッチサイズは考えておらず、(チャンネル数、特徴量数)です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "Pk6rtmHxv8Mb",
    "outputId": "75268a6d-1bd5-4e4d-ab43-3c4924813100"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[16. 22.]\n",
      "  [17. 23.]\n",
      "  [18. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]])  # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
    "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
    "b = np.array([1, 2, 3]) # （出力チャンネル数）\n",
    "\n",
    "#バッチ数を追加\n",
    "x = x[np.newaxis, :]\n",
    "\n",
    "#shapeの取得\n",
    "batch, C, W = x.shape #(バッチサイズ, 入力チャンネル, 特徴量)\n",
    "FN, C, FS = w.shape #(出力チャンネル,  入力チャンネル, フィルタサイズ)\n",
    "\n",
    "#出力のサイズ(特徴量方向)\n",
    "out_w = n_out(W, 0, FS, 1)\n",
    "\n",
    "#出力の形\n",
    "a = np.zeros((batch, FN, out_w)) #(バッチサイズ, 出力チャンネル数, 特徴量数)\n",
    "\n",
    "#バッチ数\n",
    "for i in range(batch):\n",
    "    #出力チャンネル数\n",
    "    for j in range(FN):\n",
    "        #入力チャンネル数\n",
    "        for k in range(C):\n",
    "            #特徴量数\n",
    "            for l in range(out_w):\n",
    "                #足しあげる\n",
    "                a[i, j, l] += np.sum(x[i, k, l: l+FS] * w[j, k, :] ) \n",
    "\n",
    "#バイアスを足す\n",
    "a += b.reshape(1, -1, 1)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "AQ7ZHkBUv8Md",
    "outputId": "e8152896-8895-4f65-9e9d-9ffaf30123cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw :\n",
      " [[[ 50.  80. 110.]\n",
      "  [ 80. 110. 140.]]\n",
      "\n",
      " [[ 50.  80. 110.]\n",
      "  [ 80. 110. 140.]]\n",
      "\n",
      " [[ 50.  80. 110.]\n",
      "  [ 80. 110. 140.]]]\n",
      "dx :\n",
      " [[[30. 90. 90. 60.]\n",
      "  [30. 90. 90. 60.]]]\n",
      "db :\n",
      " [[30 30 30]]\n"
     ]
    }
   ],
   "source": [
    "#バックプロバケーションの初期値\n",
    "da = np.array([[10, 20], [10, 20], [10, 20]])\n",
    "\n",
    "FN, C, FS = w.shape # (出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
    "batch, C, W = x.shape # (バッチサイズ、入力チャンネル数、特徴量数)\n",
    "\n",
    "#da(バッチサイズ, 出力チャンネル数, 特徴量数)\n",
    "da = da[np.newaxis, :]\n",
    "\n",
    "#ｗの勾配\n",
    "dw = np.zeros(w.shape)\n",
    "\n",
    "#xの勾配\n",
    "dx = np.zeros(x.shape)\n",
    "\n",
    "#バッチサイズ\n",
    "for i in range(batch):\n",
    "    #出力チャンネル\n",
    "    for j in range(FN):\n",
    "        #入力チャンネル\n",
    "        for k in range(C):\n",
    "            #フィルタサイズ\n",
    "            for l in range(FS):\n",
    "                #出力特徴量\n",
    "                for m in range(out_w):\n",
    "                    #足しあげる\n",
    "                    dw[j, k, l] += da[i, j, m] * x[i, k, l + m]\n",
    "                    dx[i, k, l + m] += da[i, j, m] * w[j, k, l]\n",
    "\n",
    "#bの勾配\n",
    "db = da.sum(axis=2)\n",
    "        \n",
    "print('dw :\\n', dw)\n",
    "print('dx :\\n', dx)\n",
    "print('db :\\n', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qtdck_WAv8Mg"
   },
   "outputs": [],
   "source": [
    "class Conv1d:\n",
    "    \"\"\"\n",
    "    チャンネル数を指定しない1次元畳み込み層クラス\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    W : 重み\n",
    "    B : バイアス\n",
    "    X : 入力\n",
    "    out_w : 出力のサイズ\n",
    "    \"\"\"\n",
    "    def __init__(self, initializer, optimizer, filter_num, C, filter_size):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(filter_num=filter_num, C=C, filter_size=filter_size)\n",
    "        self.B = initializer.B(filter_num)\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.X = None\n",
    "        self.out_w = None\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        A : 出力\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        \n",
    "        #shapeの取得\n",
    "        batch, C, W = self.X.shape #(バッチサイズ, 入力チャンネル, 特徴量)\n",
    "        FN, C, FS = self.W.shape #(出力チャンネル,  入力チャンネル, フィルタサイズ)\n",
    "\n",
    "        #出力のサイズ(特徴量方向)\n",
    "        self.out_w = self._n_out(W, 0, FS, 1)\n",
    "\n",
    "        #出力の形\n",
    "        A = np.zeros((batch, FN, self.out_w)) #(バッチサイズ, 出力チャンネル数, 特徴量数)\n",
    "\n",
    "        #バッチ数\n",
    "        for i in range(batch):\n",
    "            #出力チャンネル数\n",
    "            for j in range(FN):\n",
    "                #入力チャンネル数\n",
    "                for k in range(C):\n",
    "                    #特徴量数\n",
    "                    for l in range(self.out_w):\n",
    "                        #足しあげる\n",
    "                        A[i, j, l] += np.sum(self.X[i, k, l: l + FS] * self.W[j, k, :] ) \n",
    "\n",
    "        #バイアスを足す\n",
    "        A += self.B.reshape(1, -1, 1)\n",
    "        \n",
    "        return A\n",
    "\n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dX : 前に流す勾配\n",
    "        \"\"\"\n",
    "        FN, C, FS = self.W.shape # (出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
    "        batch, C, W = self.X.shape # (バッチサイズ、入力チャンネル数、特徴量数)\n",
    "\n",
    "        #空の配列\n",
    "        self.dW = np.zeros(self.W.shape) #Wの勾配\n",
    "        dX = np.zeros(self.X.shape) #Xの勾配\n",
    "\n",
    "        #バッチサイズ\n",
    "        for i in range(batch):\n",
    "            #出力チャンネル\n",
    "            for j in range(FN):\n",
    "                #入力チャンネル\n",
    "                for k in range(C):\n",
    "                    #フィルタサイズ\n",
    "                    for l in range(FS):\n",
    "                        #出力特徴量\n",
    "                        for m in range(self.out_w):\n",
    "                            #足しあげる\n",
    "                            self.dW[j, k, l] += dA[i, j, m] * self.X[i, k, l + m]\n",
    "                            dX[i, k, l + m] += dA[i, j, m] * self.W[j, k, l]\n",
    "\n",
    "        #bの勾配\n",
    "        self.dB = dA.sum(axis=2)\n",
    "        \n",
    "        # 重み、バイアスの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        \n",
    "        return dX\n",
    "\n",
    "    \n",
    "    def _n_out(self, n_in, P, F, S):\n",
    "        '''\n",
    "        出力サイズの計算\n",
    "        \n",
    "        Parameters\n",
    "        --------------\n",
    "        n_in : int\n",
    "            入力のサイズ\n",
    "        P : int\n",
    "            パディング数\n",
    "        F : \n",
    "            フィルター(重み)のサイズ\n",
    "        S : \n",
    "            ストライドのサイズ\n",
    "            \n",
    "        returns\n",
    "        ---------\n",
    "        n_out : int\n",
    "            出力のサイズ\n",
    "        '''\n",
    "        n_out = int(((n_in + 2 * P - F) / S ) + 1)\n",
    "        \n",
    "        return n_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wgweK2C8v8Mh"
   },
   "source": [
    "## 【問題5】学習・推定\n",
    "\n",
    "これまで使ってきたニューラルネットワークの全結合層の一部をConv1dに置き換えて学習と推定を行ってください。出力層だけは全結合層をそのまま使ってください。\n",
    "\n",
    "チャンネルが複数ある状態では全結合層への入力は行えません。その段階でのチャンネルは1になるようにするか、平滑化を行います。平滑化はNumPyのreshapeが使用できます。\n",
    "\n",
    "[numpy.reshape — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html)\n",
    "\n",
    "画像に対しての1次元畳み込みは実用上は行わないことのため、精度は問いません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBvtVtHqv8Mh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Scratch1dCNNClassifier():\n",
    "    \"\"\"\n",
    "    ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    --------------\n",
    "    epoc : int\n",
    "        エポック数\n",
    "    activaiton : {'sigmoid', 'tanh', 'relu'} default 'relu'\n",
    "        活性化関数の種類\n",
    "    solver :  {'sgd', 'adagrad'}, default 'adam'\n",
    "        最適化手法の種類\n",
    "    alpha : float\n",
    "        学習率\n",
    "    batch_size : int\n",
    "        バッチサイズ\n",
    "    initial : {'simple', 'xavier', 'he'} default 'he'\n",
    "        重みの初期化方法\n",
    "    sigma : float\n",
    "        重みパラメータ(ガウス分布の標準偏差)\n",
    "    n_nodes1 : int\n",
    "        1層目の数\n",
    "    n_nodes2 : int\n",
    "        2層目の数\n",
    "    n_output : int\n",
    "        出力層の数\n",
    "    verbose : bool\n",
    "        学習過程の出力の有無\n",
    "        \n",
    "    Attributes\n",
    "    -------------\n",
    "    conv1 : インスタンス\n",
    "        畳み込み層のインスタンス\n",
    "    FC1 :  インスタンス\n",
    "        結合層のインスタンス\n",
    "    FC2 :   インスタンス\n",
    "        結合層のインスタンス\n",
    "    FC3 :   インスタンス\n",
    "        結合層のインスタンス\n",
    "    activation1 : インスタンス\n",
    "        活性化関数のインスタンス\n",
    "    activation2 : インスタンス\n",
    "        活性化関数のインスタンス\n",
    "    activation3 : インスタンス\n",
    "        活性化関数のインスタンス\n",
    "    loss_list : list\n",
    "        学習用データの損失を記録するリスト\n",
    "    mini_loss_list : list\n",
    "        学習用データの損失を記録するリスト(ミニバッチごと)\n",
    "    val_loss_list : list\n",
    "        検証用データの損失を記録するリスト\n",
    "    mini_val_loss_list : list\n",
    "        検証用データの損失を記録するリスト(ミニバッチごと)\n",
    "    flat : インスタンス\n",
    "        平滑化のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, epoc=10, activation='relu', solver='adagrad', alpha=0.005,\n",
    "                             batch_size=10, initial='he', sigma=0.01, n_nodes1=50, \n",
    "                             n_nodes2=25, filter_num=3,  filter_size=7, verbose=True):\n",
    "        #ハイパーパラメータ \n",
    "        self.epoc            = epoc              #エポック数\n",
    "        self.activation   = activation     #活性化関数\n",
    "        self.solver          = solver            #最適化の手法\n",
    "        self.alpha           = alpha             #学習率\n",
    "        self.batch_size = batch_size   #バッチサイズ\n",
    "        self.initial           = initial             #重みの初期化方法\n",
    "        self.sigma          = sigma            #重みパラメータ\n",
    "        self.n_nodes1   = n_nodes1    #1層目のノード数\n",
    "        self.n_nodes2   = n_nodes2    #2層目のノード数\n",
    "        self.filter_num  = filter_num    #フィルタの数\n",
    "        self.filter_size   = filter_size    #フィルタのサイズ\n",
    "        self.verbose      = verbose        #学習過程の出力(True : 有, False : 無)\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.conv1              =None #畳み込み層のインスタンス\n",
    "        self.FC1                  = None #結合層のインスタンス\n",
    "        self.FC2                  = None #結合層のインスタンス\n",
    "        self.activation1     = None #活性化関数のインスタンス\n",
    "        self.activation2     = None #活性化関数のインスタンス\n",
    "        self.activation3     = None #活性化関数のインスタンス\n",
    "        self.loss_list           = None #学習用データの損失を記録する配列\n",
    "        self.mini_loss_list  = None #学習用データの損失を記録する配列(ミニバッチごと)\n",
    "        self.val_loss_list    = None #検証用データの損失を記録する配列\n",
    "        self.mini_loss_list  = None #検証用データの損失を記録する配列(ミニバッチごと)\n",
    "        self.flat                   = None #平滑化インスタンス\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            学習用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            学習用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"            \n",
    "        #one_hotエンコーディング\n",
    "        n_output = np.unique(y).shape[0]\n",
    "        y_onehot = self._one_hot(y, n_output)\n",
    "        \n",
    "        #ミニバッチを取得するクラスをインスタンス化\n",
    "        train_mini_batch = GetMiniBatch(X, y_onehot, self.batch_size)\n",
    "        \n",
    "        #valがあるとき\n",
    "        if X_val is not None and y_val is not None:       \n",
    "            y_val_onehot = self._one_hot(y_val, n_output) #one-hotエンコーディング\n",
    "            test_mini_batch = GetMiniBatch(X_val, y_val_onehot) #インスタンス化\n",
    "        \n",
    "        \n",
    "        #活性化関数の選択\n",
    "        if self.activation == 'sigmoid':\n",
    "            activate1 = Sigmoid()\n",
    "            activate2 = Sigmoid()\n",
    "            activate3 = Sigmoid()\n",
    "        elif self.activation == 'tanh':\n",
    "            activate1 = Tanh()\n",
    "            activate2 = Tanh()\n",
    "            activate3 = Tanh()\n",
    "        elif self.activation == 'relu':\n",
    "            activate1 = Relu()\n",
    "            activate2 = Relu()\n",
    "            activate3 = Relu()\n",
    "\n",
    "        \n",
    "        #最適化手法の選択\n",
    "        if self.solver == 'sgd':\n",
    "            optimizer1 = SGD(self.alpha)\n",
    "            optimizer2 = SGD(self.alpha)\n",
    "            optimizer3 = SGD(self.alpha) \n",
    "            optimizer4 = SGD(self.alpha)\n",
    "            optimizer5 = SGD(self.alpha) \n",
    "        elif self.solver == 'adagrad':\n",
    "            optimizer1 = AdaGrad(self.alpha)\n",
    "            optimizer2 = AdaGrad(self.alpha)\n",
    "            optimizer3 = AdaGrad(self.alpha)\n",
    "            optimizer4 = AdaGrad(self.alpha)\n",
    "            optimizer5 = AdaGrad(self.alpha)\n",
    "            \n",
    "        #重みの初期化方法の選択\n",
    "        if self.initial == 'simple':\n",
    "            initializer1 = SimpleInitializer(self.sigma)\n",
    "            initializer2 = SimpleInitializer(self.sigma)\n",
    "            initializer3 = SimpleInitializer(self.sigma)\n",
    "            initializer4 = SimpleInitializer(self.sigma)\n",
    "            initializer5 = SimpleInitializer(self.sigma)\n",
    "        elif self.initial == 'xavier':\n",
    "            initializer1 = XavierInitializer()\n",
    "            initializer2 = XavierInitializer()\n",
    "            initializer3 = XavierInitializer()\n",
    "            initializer4 = XavierInitializer()\n",
    "            initializer5 = XavierInitializer()\n",
    "        elif self.initial == 'he':\n",
    "            initializer1 = HeInitializer()\n",
    "            initializer2 = HeInitializer()\n",
    "            initializer3 = HeInitializer()\n",
    "            initializer4 = HeInitializer()\n",
    "            initializer5 = HeInitializer()\n",
    "\n",
    "        #畳み込み層\n",
    "        self.conv1 = Conv1d(initializer1, optimizer1, self.filter_num, X.shape[1], self.filter_size)\n",
    "        self.activation1 = activate1\n",
    "        \n",
    "        #平滑化クラスのインスタンス化\n",
    "        self.flat = Flatten()\n",
    "        out = self.filter_num * (X.shape[2] - (self.filter_size - 1))\n",
    "\n",
    "        #結合層および活性化関数クラスのインスタンス化\n",
    "        self.FC1 = FC(out, self.n_nodes1, initializer2, optimizer2) #第1層\n",
    "        self.activation2 = activate2\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, initializer3, optimizer3) #第2層\n",
    "        self.activation3 = activate3\n",
    "        self.FC3 = FC(self.n_nodes2, y_onehot.shape[1], initializer4, optimizer4) #第3層\n",
    "        self.activation4 = Softmax()\n",
    "        \n",
    "        #損失を記録するリスト(エポックごと)\n",
    "        self.loss_list = []\n",
    "        self.val_loss_list= []\n",
    "        \n",
    "        #エポック数だけ繰り返す\n",
    "        for i in range(self.epoc):\n",
    "            \n",
    "            #損失を記録するリスト(イテレーション)\n",
    "            self.mini_loss_list = []\n",
    "            \n",
    "            #イテレーション数実行\n",
    "            for mini_X_train, mini_y_train in train_mini_batch:\n",
    "                \n",
    "                #フォワード\n",
    "                #畳み込み(1層目)\n",
    "                A1 = self.conv1.forward(mini_X_train) \n",
    "                Z1 = self.activation1.forward(A1)    \n",
    "                \n",
    "                #平滑化\n",
    "                F1 = self.flat.forward(Z1)\n",
    "                \n",
    "                #全結合層\n",
    "                A2 = self.FC1.forward(F1)                   \n",
    "                Z2 = self.activation2.forward(A2) \n",
    "                A3 = self.FC2.forward(Z2)             \n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                A4 = self.FC3.forward(Z3)             \n",
    "                Z4 = self.activation4.forward(A4)   \n",
    "                \n",
    "                #バックワード\n",
    "                #全結合層\n",
    "                dA4, mini_loss = self.activation4.backward(mini_y_train) \n",
    "                dZ4 = self.FC3.backward(dA4)          \n",
    "                dA3 = self.activation3.backward(dZ4) \n",
    "                dZ3 = self.FC2.backward(dA3)            \n",
    "                dA2 = self.activation2.backward(dZ3) \n",
    "                dZ2 = self.FC1.backward(dA2)    \n",
    "                \n",
    "                #shapeを戻す\n",
    "                dF1 = self.flat.backward(dZ2)\n",
    "                \n",
    "                #畳み込み層\n",
    "                dA2 = self.activation1.backward(dF1)\n",
    "                dZ1 = self.conv1.backward(dA2)\n",
    "\n",
    "                #イテレーションごとの損失をリストに格納\n",
    "                self.mini_loss_list.append(mini_loss)\n",
    "\n",
    "            #1エポックの損失をリストに格納\n",
    "            loss = np.mean(self.mini_loss_list)\n",
    "            self.loss_list.append(loss)\n",
    "\n",
    "            \n",
    "            #valがあるときもイテレーション数実行\n",
    "            if X_val is not None and y_val is not None:\n",
    "                \n",
    "                self.mini_val_loss_list = []\n",
    "                for mini_X_val, mini_y_val in test_mini_batch:\n",
    "              \n",
    "                    #確率を予測\n",
    "                    A1 = self.conv1.forward(mini_X_val)\n",
    "                    Z1 = self.activation1.forward(A1)\n",
    "                    F1 = self.flat.forward(Z1)\n",
    "                    A2 = self.FC1.forward(F1)\n",
    "                    Z2 = self.activation2.forward(A2)\n",
    "                    A3 = self.FC2.forward(Z2)\n",
    "                    Z3 = self.activation3.forward(A3)\n",
    "                    A4 = self.FC3.forward(Z3) \n",
    "                    Z4 = self.activation4.forward(A4)\n",
    "\n",
    "                    #損失を計算\n",
    "                    _, mini_val_loss = self.activation4.backward(mini_y_val)\n",
    "\n",
    "                    #イテレーションごとの損失をリストに格納\n",
    "                    self.mini_val_loss_list.append(mini_val_loss)\n",
    "\n",
    "                #1エポックの損失をリストに格納\n",
    "                val_loss = np.mean(self.mini_val_loss_list)\n",
    "                self.val_loss_list.append(val_loss)\n",
    "\n",
    "                \n",
    "            #学習過程を出力する場合\n",
    "            if self.verbose == True:\n",
    "                print('学習用データの学習過程' + str(i + 1) + 'epoc目 : ' + str(self.loss_list[i]))\n",
    "\n",
    "                #検証用データあり\n",
    "                if X_val is not None or y_val is not None:\n",
    "                    print('検証用データの学習過程' + str(i + 1) + 'epoc目 : ' + str(self.val_loss_list[i]))\n",
    "                    \n",
    "                \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        #フォワード\n",
    "        #畳み込み(1層目)\n",
    "        A1 = self.conv1.forward(X) \n",
    "        Z1 = self.activation1.forward(A1) \n",
    "        \n",
    "        #平滑化\n",
    "        F1 = self.flat.forward(Z1)\n",
    "        \n",
    "        #全結合層\n",
    "        A2 = self.FC1.forward(F1)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "        A3 = self.FC2.forward(Z2)\n",
    "        Z3 = self.activation3.forward(A3)\n",
    "        A4 = self.FC3.forward(Z3)\n",
    "        y_pred = self.activation4.forward(A4)  \n",
    "                       \n",
    "        return np.argmax(y_pred, axis=1)\n",
    "            \n",
    "\n",
    "    def _one_hot(self, y, n_output):\n",
    "        '''\n",
    "        one-hotエンコーディングを行う関数\n",
    "       \n",
    "       Parameters\n",
    "        ---------------\n",
    "        y : 次の形のndarray, shape (n_features, 1)\n",
    "            正解ラベルのベクトル\n",
    "        n_output : int\n",
    "            正解ラベルのユニーク値\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        one_hot.T : 次の形のndarray, shape (n_features, n_output)\n",
    "        '''\n",
    "        #0配列を用意\n",
    "        one_hot = np.zeros((n_output, y.shape[0]))\n",
    "        \n",
    "        #0配列の該当する位置に1を挿入\n",
    "        for idx, val in enumerate(y.astype(int)):\n",
    "            one_hot[val, idx] = 1\n",
    "\n",
    "        return one_hot.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1QQ2pqQv8Mj"
   },
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 10, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self.X = X[shuffle_index]\n",
    "        self.y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self.X[p0:p1], self.y[p0:p1]        \n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self.X[p0:p1], self.y[p0:p1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3akqCGRv8Mk"
   },
   "source": [
    "**layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iu9tO2bbv8Ml"
   },
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "        \n",
    "        #インスタンス変数\n",
    "        self.X = None\n",
    "\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        Z2 : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        self.X = X.copy()\n",
    "        Z2 = np.dot(X, self.W) + self.B\n",
    "        \n",
    "        return Z2\n",
    "    \n",
    "    \n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape(batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.dB = dA \n",
    "        self.dW = np.dot(self.X.T, dA) \n",
    "        dZ = np.dot(dA, self.W.T) \n",
    "        \n",
    "        # 重み、バイアスの更新\n",
    "        self = self.optimizer.update(self)\n",
    "        return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7EF8izMv8Mn"
   },
   "source": [
    "**初期化クラス**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUdKwGu9v8Mo"
   },
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    \"\"\"\n",
    "    ガウス分布によるシンプルな初期化\n",
    "    Parameters\n",
    "    ----------\n",
    "    sigma : float\n",
    "      ガウス分布の標準偏差\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma #重みパラメータ\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "            前の層のノード数\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルターのサイズ(縦横同じ)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み\n",
    "        if filter_num is not None and C is not None and filter_size is not None:\n",
    "            W =  self.sigma * np.random.randn(filter_num, C, filter_size) \n",
    "       \n",
    "        #全結合\n",
    "        if n_nodes1 is not None and n_nodes2 is not None:\n",
    "            W =  self.sigma * np.random.randn(n_nodes1, n_nodes2) \n",
    "\n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :次の形のndarray, shape (n_nodes2)\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72h0x-yRv8Mr"
   },
   "outputs": [],
   "source": [
    "class XavierInitializer:\n",
    "    \"\"\"\n",
    "    Xavierの初期値のクラス\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルタサイズ\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み層\n",
    "        if filter_num and C and filter_size is not None:\n",
    "            W =  np.random.randn(filter_num, C, filter_size) / np.sqrt(filter/num) \n",
    "        \n",
    "        #全結合層\n",
    "        else:\n",
    "            W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1) \n",
    "    \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (n_nodes2, )\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FK3vIz2Jv8Ms"
   },
   "outputs": [],
   "source": [
    "class HeInitializer:\n",
    "    \"\"\"\n",
    "    Heの初期値のクラス\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "\n",
    "    def W(self, n_nodes1=None, n_nodes2=None, \n",
    "                  filter_num=None, C=None, filter_size=None):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "        filter_num : int\n",
    "            フィルター数\n",
    "        C : int\n",
    "            チャンネル数\n",
    "        filter_size : int\n",
    "            フィルタサイズ\n",
    "        Returns\n",
    "        ----------\n",
    "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
    "            重み\n",
    "        \"\"\"\n",
    "        #畳み込み層\n",
    "        if filter_num and C and filter_size is not None:\n",
    "            W = np.random.randn(filter_num, C, filter_size) * np.sqrt(2 / filter_num)\n",
    "       \n",
    "        #全結合層\n",
    "        else:\n",
    "            W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
    "    \n",
    "        return W\n",
    "    \n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "            後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B : 次の形のndarray, shape (n_nodes2, )\n",
    "            バイアス\n",
    "        \"\"\"\n",
    "        B = np.zeros(n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdVDoM3Wv8Mu"
   },
   "source": [
    "**最適化手法クラス**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKfqLBEzv8Mu"
   },
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        #バッチサイズで割る\n",
    "        layer.W -= self.alpha* layer.dW / layer.dB.shape[0] #(n_nodes1, n_nodes2)\n",
    "        layer.B -= self.alpha* layer.dB.mean(axis=0) #(n_nodes2)\n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cd9msTdqv8Mx"
   },
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    \"\"\"\n",
    "    AdaGradの最適化\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.H_W= None\n",
    "        self.H_B = None\n",
    "        \n",
    "\n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        layer : 更新後の層のインスタンス\n",
    "        \"\"\"\n",
    "        #self.Hの初期化\n",
    "        if self.H_W is None:\n",
    "            self.H_W = np.zeros(layer.W.shape)\n",
    "        if self.H_B is None:\n",
    "            self.H_B = np.zeros(layer.B.shape)\n",
    "        \n",
    "        #更新    \n",
    "        self.H_W += (layer.dW / layer.dB.shape[0]) ** 2 #重みの勾配の二乗和\n",
    "        self.H_B += (layer.dB.mean(axis=0)) ** 2 #バイアスの二乗和\n",
    "        layer.W -= self.alpha / np.sqrt(self.H_W + 1e-7) * layer.dW / layer.dB.shape[0] #重み\n",
    "        layer.B -= self.alpha / np.sqrt(self.H_B + 1e-7) * layer.dB.mean(axis=0) #バイアス \n",
    "        \n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "93BnIDpev8My"
   },
   "source": [
    "**活性化関数クラス**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9Rsc4Jjv8Mz"
   },
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    '''\n",
    "    シグモイド関数のクラス\n",
    "    Parameters\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "\n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.Z = 1 / (1 + np.exp(-A)) \n",
    "        \n",
    "        return self.Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        dA = dZ * (1 - self.Z) * self.Z\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2VWFH4-_v8M0"
   },
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    '''\n",
    "    ハイパポリックタンジェント関数のクラス\n",
    "    Parameters\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "\n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.Z =  np.tanh(A)\n",
    "        \n",
    "        return  self.Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        dA = dZ * (1 - self.Z**2)\n",
    "        \n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqtZv4Gkv8M2"
   },
   "outputs": [],
   "source": [
    "class Relu:\n",
    "    '''\n",
    "    ReLU関数のクラス\n",
    "    Parameters\n",
    "    \n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "\n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            活性化関数を計算したもの\n",
    "        '''\n",
    "        self.X = A.copy()\n",
    "        \n",
    "        #Aが0以下なら0にする\n",
    "        Z = np.maximum(0, A)\n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            Zに関する損失Lの勾配\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        #forwardで0以下の部分を0にする\n",
    "        dA = np.where(self.X > 0, dZ, 0)\n",
    "\n",
    "        return dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBPvfeScv8M4"
   },
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    '''\n",
    "    ソフトマックス関数のクラス\n",
    "    Parameters\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.Z = None\n",
    "    \n",
    "    def forward(self, A):\n",
    "        '''\n",
    "        フォワードプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        A : 次の形のndarray, shape (batch_size, n_output)\n",
    "            特徴量ベクトルと重みとバイアスを計算したもの\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_output)\n",
    "            ソフトマックス関数の計算結果\n",
    "        '''\n",
    "        #オーバーフロー対策\n",
    "        c = np.max(A)\n",
    "        exp_A = np.exp(A - c)\n",
    "        \n",
    "        #分母\n",
    "        sum_exp_A = np.sum(exp_A, axis=1).reshape(-1, 1)\n",
    "\n",
    "        self.Z = exp_A / sum_exp_A\n",
    "        \n",
    "        return self.Z\n",
    "\n",
    "    \n",
    "    def backward(self, y):\n",
    "        '''\n",
    "        バックプロバケーション\n",
    "        Parameters\n",
    "        --------------\n",
    "        y : 次の形のndarray, shape (batch_size, n_output)\n",
    "            正解ラベルのベクトル\n",
    "        Z : 次の形のndarray, shape (batch_size, n_output)\n",
    "            フォワードプロバケーションの出力\n",
    "        \n",
    "        Returns\n",
    "        ---------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes1)  \n",
    "           Aに関する損失Lの勾配 \n",
    "        '''\n",
    "        #交差エントロピー誤差の計算\n",
    "        loss_sum = np.sum(y * np.log(self.Z), axis=1)\n",
    "        loss = -np.mean(loss_sum)\n",
    "        \n",
    "        #勾配の計算\n",
    "        dA = self.Z - y\n",
    "        \n",
    "        return dA, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LXz85XVlv8M5"
   },
   "outputs": [],
   "source": [
    "class Flatten():\n",
    "    '''\n",
    "    平滑化を行うクラス\n",
    "    \n",
    "    Attribute\n",
    "    -----------\n",
    "    X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        入力\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.X_shape = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        フォワード\n",
    "\n",
    "        Parameters\n",
    "        -------------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        X_1d : 次の形のndarray, shape (N, C, H ,W)\n",
    "        '''\n",
    "        #1次元にする\n",
    "        X_1d = X.reshape(X.shape[0], -1)\n",
    "        \n",
    "        #shapeを記録\n",
    "        self.X_shape = X.shape\n",
    "        \n",
    "        return X_1d\n",
    "    \n",
    "\n",
    "    def backward(self, X):\n",
    "        '''\n",
    "        バックワード\n",
    "\n",
    "        Parameters\n",
    "        -------------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "            入力\n",
    "            \n",
    "        Returns\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (N, C, H ,W)\n",
    "        '''\n",
    "        #shapeを戻す\n",
    "        X = X.reshape(self.X_shape)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "kQyPM8l3v8M6",
    "outputId": "00552658-918c-4536-d734-653c3610f971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習用データの学習過程1epoc目 : 1.3166034621199658\n",
      "検証用データの学習過程1epoc目 : 0.9208038636123383\n",
      "学習用データの学習過程2epoc目 : 0.518384174844151\n",
      "検証用データの学習過程2epoc目 : 0.7982887000316323\n",
      "学習用データの学習過程3epoc目 : 0.3208184164054251\n",
      "検証用データの学習過程3epoc目 : 0.7687709511787605\n",
      "学習用データの学習過程4epoc目 : 0.22001759925997105\n",
      "検証用データの学習過程4epoc目 : 0.753503682108429\n",
      "学習用データの学習過程5epoc目 : 0.16179583566388137\n",
      "検証用データの学習過程5epoc目 : 0.7438897455290994\n",
      "学習用データの学習過程6epoc目 : 0.1199553110341322\n",
      "検証用データの学習過程6epoc目 : 0.7343490047695787\n",
      "学習用データの学習過程7epoc目 : 0.09346560252166754\n",
      "検証用データの学習過程7epoc目 : 0.7344318559068284\n",
      "学習用データの学習過程8epoc目 : 0.07415330236067923\n",
      "検証用データの学習過程8epoc目 : 0.7339073627393892\n",
      "学習用データの学習過程9epoc目 : 0.06083149932695168\n",
      "検証用データの学習過程9epoc目 : 0.7337423144825805\n",
      "学習用データの学習過程10epoc目 : 0.05015333939033533\n",
      "検証用データの学習過程10epoc目 : 0.7453468230478328\n"
     ]
    }
   ],
   "source": [
    "cnn = Scratch1dCNNClassifier()\n",
    "cnn.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNzMEVYJyN1f"
   },
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iBvcK3E1xu1S"
   },
   "outputs": [],
   "source": [
    "def cost_curve(loss, val_loss):\n",
    "    '''\n",
    "    学習曲線を出力する関数\n",
    "    '''\n",
    "    p1= plt.plot(loss, label='loss')\n",
    "    p2 = plt.plot(val_loss, label='val_loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('Cost curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "j3tp9sYvx8nX",
    "outputId": "014f8065-b812-4ecb-c685-538445cc2e9d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSBuFgoiItFEoiIhIG4WCiIi0+f+sBCeNgE6O2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_curve(cnn.loss_list, cnn.val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vv5syjY5yFrk"
   },
   "outputs": [],
   "source": [
    "def evalution(y_test, y_pred):\n",
    "    '''\n",
    "     分類問題の指標値を出力する関数\n",
    " \n",
    "     Paraeters\n",
    "     -------------\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "        正解値\n",
    "    y_pred : 次の形のndarray, shape (n_samples, )\n",
    "        予測したラベル\n",
    "    '''\n",
    "    #accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('accuracy :', accuracy)\n",
    "\n",
    "    #precision\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    print('precision :', precision)\n",
    "\n",
    "    #recall\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    print('recall :', recall)\n",
    "\n",
    "    #f1\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    print('f1 :', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "H6saZIOpyId2",
    "outputId": "e2b0e1a1-9a96-4bdd-f834-57886b2e066f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy : 0.775\n",
      "precision : 0.7866978609625669\n",
      "recall : 0.7419892813584764\n",
      "f1 : 0.7451650639494509\n"
     ]
    }
   ],
   "source": [
    "evalution(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjjA5ABi3_1F"
   },
   "source": [
    "時間がかかるため、MNISTのtrain, testデータそれぞれ1/100にして実施。  \n",
    "lossは下がったが、val_lossは下がらず、過学習傾向があった。  \n",
    "testデータで精度を確認したが、あまり高いと言えない結果となった。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VebAvCr6v8M8"
   },
   "source": [
    "## 【問題6】（アドバンス課題）パディングの実装\n",
    "\n",
    "畳み込み層にパディングを加えてください。1次元配列の場合、前後にn個特徴量を増やせるようにしてください。\n",
    "\n",
    "最も単純なパディングは全て0で埋めるゼロパディングであり、CNNでは一般的です。他に端の値を繰り返す方法などもあります。\n",
    "\n",
    "フレームワークによっては、元の入力のサイズを保つようにという指定をすることができます。この機能も持たせておくと便利です。\n",
    "\n",
    "なお、NumPyにはパディングの関数が存在します。\n",
    "\n",
    "[numpy.pad — NumPy v1.15 Manual](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.pad.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C72S_AtGv8M8"
   },
   "source": [
    "## 【問題7】（アドバンス課題）ミニバッチへの対応\n",
    "\n",
    "ここまでの課題はバッチサイズ1で良いとしてきました。しかし、実際は全結合層同様にミニバッチ学習が行われます。Conv1dクラスを複数のデータが同時に計算できるように変更してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eLxKjQFHv8M9"
   },
   "source": [
    "## 【問題8】（アドバンス課題）任意のストライド数\n",
    "\n",
    "ストライドは1限定の実装をしてきましたが、任意のストライド数に対応できるようにしてください。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "E4XAioqvv8MG"
   ],
   "name": "sprint12-dl-scratch-cnn1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
