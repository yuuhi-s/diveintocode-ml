{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint9 アンサンブル学習、グループワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## この課題の目的\n",
    "\n",
    "- アンサンブル学習について理解する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アンサンブル学習\n",
    "\n",
    "3種類のアンサンブル学習の効果を小さめのデータセットで確認していきます。\n",
    "\n",
    "- ブレンディング\n",
    "- バギング\n",
    "- スタッキング"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小さなデータセットの用意\n",
    "\n",
    "以前も利用した回帰のデータセットを用意します。\n",
    "\n",
    "[House Prices: Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "この中の<font color='red'>train.csv</font>をダウンロードし、目的変数として<font color='red'>SalePrice</font>、説明変数として、<font color='red'>GrLivArea</font>とYearBuiltを使います。\n",
    "\n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データの抜き出し\n",
    "df = pd.read_csv('train.csv')\n",
    "df = df[['GrLivArea', 'YearBuilt', 'SalePrice']]\n",
    "\n",
    "#説明変数をX, 目的変数をyのndarrayに格納\n",
    "X = df[['YearBuilt', 'GrLivArea']].values\n",
    "y = df['SalePrice'].values\n",
    "\n",
    "X = X.astype('float64')\n",
    "y = y.astype('float64')\n",
    "\n",
    "#データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#対数変換\n",
    "X_train_std = np.log(X_train)\n",
    "y_train_std = np.log(y_train)\n",
    "X_test_std = np.log(X_test)\n",
    "y_test_std = np.log(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "[sklearn.linear_model.LinearRegression — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "\n",
    "[sklearn.svm.SVR — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)\n",
    "\n",
    "[sklearn.tree.DecisionTreeRegressor — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題1】ブレンディング\n",
    "\n",
    "ブレンディングを実装し、単一モデルより精度があがる例を<font color='red'>最低3つ</font>示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを示します。\n",
    "\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。必ずしも単一モデルの精度が高い必要はありません。\n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    "\n",
    "補足\n",
    "\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。\n",
    "\n",
    "[sklearn.ensemble.VotingClassifier — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)\n",
    "\n",
    "考察\n",
    "\n",
    "どういった組み合わせが良いか、どのようにすると多様なモデルが作れるかを考えてみましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_score(X_train, X_test, y_train, y_test, model):\n",
    "    '''\n",
    "    モデルの学習、推定し、精度を求める関数\n",
    "    \n",
    "    Parameters\n",
    "    --------------\n",
    "    X_train: 次の形のndarray, shape (n_samples, n_features)\n",
    "        学習用データの特徴量\n",
    "    X_test: 次の形のndarray, shape (n_samples, n_features)\n",
    "        検証用データの特徴量\n",
    "    y_train: 次の形のndarray, shape (n_samples,)\n",
    "        学習用データの正解データ\n",
    "    y_test: 次の形のndarray, shape (n_samples, )\n",
    "        検証用データの正解データ\n",
    "    model ; クラス\n",
    "        学習に使用するモデル\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : 次の形のndarray, shape (n_samples, 1)\n",
    "        予測したデータ\n",
    "    mse : float\n",
    "        MSEスコア\n",
    "    r2 : float\n",
    "        R2スコア\n",
    "    '''\n",
    "    #学習モデルのインスタンス化\n",
    "    cls = model\n",
    "    \n",
    "    #学習\n",
    "    cls.fit(X_train, y_train)\n",
    "    \n",
    "    #推定\n",
    "    y_pred = cls.predict(X_test)\n",
    "    \n",
    "    #MSE\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    \n",
    "    #R2\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return y_pred, mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#線形回帰\n",
    "y_linear_pred, linear_mse, linear_r2 = pipe_score(X_train_std, X_test_std, \n",
    "                                                                              y_train_std, y_test_std, LinearRegression())\n",
    "\n",
    "#SVM\n",
    "y_svm_pred, svm_mse, svm_r2 = pipe_score(X_train_std, X_test_std, \n",
    "                                                                             np.ravel(y_train_std), np.ravel(y_test_std), SVR(gamma='auto'))\n",
    "\n",
    "#決定木\n",
    "y_tree_pred, tree_mse, tree_r2 = pipe_score(X_train_std, X_test_std, \n",
    "                                                                            y_train_std, y_test_std, DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>線形回帰</th>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.712701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.053603</td>\n",
       "      <td>0.650392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>決定木</th>\n",
       "      <td>0.066854</td>\n",
       "      <td>0.563969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MSE        R2\n",
       "線形回帰  0.044050  0.712701\n",
       "SVM   0.053603  0.650392\n",
       "決定木   0.066854  0.563969"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#単一モデルの精度\n",
    "score = pd.DataFrame([[linear_mse, linear_r2], \n",
    "                                         [svm_mse, svm_r2], \n",
    "                                         [tree_mse, tree_r2]],\n",
    "                                        columns = ['MSE', 'R2'], \n",
    "                                         index = ['線形回帰', 'SVM', '決定木'])\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・ブレンディング1\n",
    "\n",
    "単一モデルを参考に各モデルを重み付けし、足し合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.04329095860297254 \t R2 : 0.7176508501502658\n"
     ]
    }
   ],
   "source": [
    "#ブレンディング1\n",
    "y_brend1_pred = (y_linear_pred.reshape(-1, 1) * 0.5 + y_svm_pred.reshape(-1, 1) * 0.3+ y_tree_pred.reshape(-1, 1) * 0.2)\n",
    "\n",
    "#MSE\n",
    "brend1_mse = mean_squared_error(y_test_std, y_brend1_pred)\n",
    "\n",
    "#R2\n",
    "brend1_r2 = r2_score(y_test_std, y_brend1_pred)\n",
    "\n",
    "print('MSE :', brend1_mse, '\\t', 'R2 :', brend1_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・ブレンディング2\n",
    "\n",
    "決定木はグリッドサーチの結果からパラメータチューニングを行い、各モデルを重み付けし、足し合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: -0.04225317393283391\n",
      "Best parameters: {'max_depth': 6}\n",
      "Best cross-validation: -0.04903131849032219\n"
     ]
    }
   ],
   "source": [
    "#決定木でグリッドサーチ\n",
    "tree_param_grid = {'max_depth': list(range(4, 10))}\n",
    "\n",
    "gs = GridSearchCV(estimator=DecisionTreeRegressor(),\n",
    "                 param_grid = tree_param_grid,   \n",
    "                 scoring='neg_mean_squared_error', \n",
    "                  cv=5)\n",
    "\n",
    "gs.fit(X_train_std, y_train_std)\n",
    "\n",
    "#結果の出力\n",
    "print('Test set score: {}'.format(gs.score(X_test_std, y_test_std)))\n",
    "print('Best parameters: {}'.format(gs.best_params_))\n",
    "print('Best cross-validation: {}'.format(gs.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#グリッドサーチを行った結果で学習、予測\n",
    "gs_y_tree_pred, _, _ = pipe_score(X_train_std, X_test_std, y_train_std, y_test_std, \n",
    "                                                                  DecisionTreeRegressor(max_depth=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.04114489381818696 \t R2 : 0.7316477582128433\n"
     ]
    }
   ],
   "source": [
    "#ブレンディング2\n",
    "y_brend2_pred = (y_linear_pred.reshape(-1, 1) * 0.4 \n",
    "                                + y_svm_pred.reshape(-1, 1) * 0.2+ gs_y_tree_pred.reshape(-1, 1) * 0.4)\n",
    "\n",
    "#MSE\n",
    "brend2_mse = mean_squared_error(y_test_std, y_brend2_pred)\n",
    "\n",
    "#R2\n",
    "brend2_r2 = r2_score(y_test_std, y_brend2_pred)\n",
    "\n",
    "print('MSE :', brend2_mse, '\\t', 'R2 :', brend2_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・ブレンディング3\n",
    "\n",
    "平均をとる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.04435330246988872 \t R2 : 0.7107221080444888\n"
     ]
    }
   ],
   "source": [
    "#ブレンディング3\n",
    "y_brend3_pred = (y_linear_pred.reshape(-1, 1) \n",
    "                                 + y_svm_pred.reshape(-1, 1)  + y_tree_pred.reshape(-1, 1)) / 3\n",
    "\n",
    "#MSE\n",
    "brend3_mse = mean_squared_error(y_test_std, y_brend3_pred)\n",
    "\n",
    "#R2\n",
    "brend3_r2 = r2_score(y_test_std, y_brend3_pred)\n",
    "\n",
    "print('MSE :', brend3_mse, '\\t', 'R2 :', brend3_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ・ブレンディング4\n",
    "\n",
    "SVMのkernelをpoly, rbf, sigmoidとして、それらの平均をとる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM(karnel='poly')\n",
    "y_svm_poly_pred, _, _ = pipe_score(X_train_std, X_test_std, \n",
    "                                                                             np.ravel(y_train_std), np.ravel(y_test_std), SVR(kernel='poly', gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM(karnel='rbf')\n",
    "y_svm_rbf_pred, _, _ = pipe_score(X_train_std, X_test_std, \n",
    "                                                                             np.ravel(y_train_std), np.ravel(y_test_std), SVR(kernel='poly', gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM(karnel='sigmoid')\n",
    "y_svm_sigmoid_pred, _, _ = pipe_score(X_train_std, X_test_std, \n",
    "                                                                             np.ravel(y_train_std), np.ravel(y_test_std), SVR(kernel='poly', gamma='auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.04160854934107324 \t R2 : 0.7286237377953078\n"
     ]
    }
   ],
   "source": [
    "#ブレンディング4\n",
    "y_brend4_pred = (y_svm_poly_pred.reshape(-1, 1) \n",
    "                                 + y_svm_rbf_pred.reshape(-1, 1)  + y_svm_sigmoid_pred.reshape(-1, 1)) / 3\n",
    "\n",
    "#MSE\n",
    "brend4_mse = mean_squared_error(y_test_std, y_brend4_pred)\n",
    "\n",
    "#R2\n",
    "brend4_r2 = r2_score(y_test_std, y_brend4_pred)\n",
    "\n",
    "print('MSE :', brend4_mse, '\\t', 'R2 :', brend4_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ブレンディング1</th>\n",
       "      <td>0.043291</td>\n",
       "      <td>0.717651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ブレンディング2</th>\n",
       "      <td>0.041145</td>\n",
       "      <td>0.731648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ブレンディング3</th>\n",
       "      <td>0.044353</td>\n",
       "      <td>0.710722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ブレンディング4</th>\n",
       "      <td>0.041609</td>\n",
       "      <td>0.728624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               MSE        R2\n",
       "ブレンディング1  0.043291  0.717651\n",
       "ブレンディング2  0.041145  0.731648\n",
       "ブレンディング3  0.044353  0.710722\n",
       "ブレンディング4  0.041609  0.728624"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ブレンディングの精度\n",
    "brend_score = pd.DataFrame([[brend1_mse, brend1_r2], \n",
    "                                                     [brend2_mse, brend2_r2], \n",
    "                                                     [brend3_mse, brend3_r2],\n",
    "                                                     [brend4_mse, brend4_r2]],\n",
    "                                                    columns = ['MSE', 'R2'], \n",
    "                                                     index = ['ブレンディング1', 'ブレンディング2', 'ブレンディング3', 'ブレンディング4'])\n",
    "\n",
    "brend_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単一モデルでは線形回帰がMSE0.044と一番低く、R2が0.713と一番高かった。ブレンディング1~4では以下のことを行った。  \n",
    "\n",
    "- ブレンディング1 : 単一モデルを参考に各モデルを重み付けし、足し合わせる\n",
    "- ブレンディング2 : 決定木はグリッドサーチの結果からパラメータチューニングを行い、各モデルを重み付けし、足し合わせる\n",
    "- ブレンディング3 : 平均をとる\n",
    "- ブレンディング4 : SVMのkernelをpoly, rbf, sigmoidとする\n",
    "    \n",
    "結果として、平均をとったブレンディング3以外のブレンディングで、単一モデルより精度が向上した。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】バギング\n",
    "\n",
    "バギングを実装し、単一モデルより精度があがる例を<font color='red'>最低1つ</font>示してください。\n",
    "\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ブートストラップサンプル）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "[sklearn.model_selection.train_test_split — scikit-learn 0.20.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1番目 MSE : 0.044 \t R2 : 0.711\n",
      "2番目 MSE : 0.044 \t R2 : 0.712\n",
      "3番目 MSE : 0.044 \t R2 : 0.712\n",
      "4番目 MSE : 0.044 \t R2 : 0.712\n",
      "5番目 MSE : 0.044 \t R2 : 0.712\n",
      "6番目 MSE : 0.044 \t R2 : 0.712\n",
      "7番目 MSE : 0.044 \t R2 : 0.712\n",
      "8番目 MSE : 0.044 \t R2 : 0.712\n",
      "9番目 MSE : 0.044 \t R2 : 0.712\n",
      "10番目 MSE : 0.044 \t R2 : 0.712\n",
      "11番目 MSE : 0.044 \t R2 : 0.712\n",
      "12番目 MSE : 0.044 \t R2 : 0.713\n",
      "13番目 MSE : 0.044 \t R2 : 0.713\n",
      "14番目 MSE : 0.044 \t R2 : 0.713\n",
      "15番目 MSE : 0.044 \t R2 : 0.713\n",
      "16番目 MSE : 0.044 \t R2 : 0.713\n",
      "17番目 MSE : 0.044 \t R2 : 0.713\n",
      "18番目 MSE : 0.044 \t R2 : 0.713\n",
      "19番目 MSE : 0.044 \t R2 : 0.713\n",
      "20番目 MSE : 0.044 \t R2 : 0.713\n"
     ]
    }
   ],
   "source": [
    "#予測した結果を足す0配列\n",
    "bagging_linear = np.zeros(len(y_test_std)).reshape(-1, 1)\n",
    "\n",
    "for i in range(20):\n",
    "    bagging_X_train, _, bagging_y_train, _ = train_test_split(X_train_std, y_train_std, shuffle=True, test_size=0.2)\n",
    "    \n",
    "    #学習、予測\n",
    "    y_pred, _, _ = pipe_score(bagging_X_train, X_test_std, bagging_y_train, y_test_std, LinearRegression())\n",
    "    \n",
    "    #予測した結果を配列に足し上げる\n",
    "    bagging_linear += y_pred.reshape(-1, 1)\n",
    "    \n",
    "    #足し上げた結果をモデルの数で割る\n",
    "    linear_bagging_y_pred = bagging_linear / (i+1)\n",
    "\n",
    "    #MSE\n",
    "    linear_bagging_mse = mean_squared_error(y_test_std, linear_bagging_y_pred)\n",
    "\n",
    "    #R2\n",
    "    linear_bagging_r2 = r2_score(y_test_std, linear_bagging_y_pred)\n",
    "    \n",
    "    print('{}番目 MSE : {:.3f} \\t R2 : {:.3f}'.format(i+1, linear_bagging_mse, linear_bagging_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1番目 MSE : 0.055 \t R2 : 0.639\n",
      "2番目 MSE : 0.055 \t R2 : 0.641\n",
      "3番目 MSE : 0.055 \t R2 : 0.642\n",
      "4番目 MSE : 0.055 \t R2 : 0.641\n",
      "5番目 MSE : 0.055 \t R2 : 0.641\n",
      "6番目 MSE : 0.055 \t R2 : 0.641\n",
      "7番目 MSE : 0.055 \t R2 : 0.641\n",
      "8番目 MSE : 0.055 \t R2 : 0.641\n",
      "9番目 MSE : 0.055 \t R2 : 0.640\n",
      "10番目 MSE : 0.055 \t R2 : 0.640\n",
      "11番目 MSE : 0.055 \t R2 : 0.641\n",
      "12番目 MSE : 0.055 \t R2 : 0.641\n",
      "13番目 MSE : 0.055 \t R2 : 0.641\n",
      "14番目 MSE : 0.055 \t R2 : 0.641\n",
      "15番目 MSE : 0.055 \t R2 : 0.641\n",
      "16番目 MSE : 0.055 \t R2 : 0.640\n",
      "17番目 MSE : 0.055 \t R2 : 0.640\n",
      "18番目 MSE : 0.055 \t R2 : 0.640\n",
      "19番目 MSE : 0.055 \t R2 : 0.640\n",
      "20番目 MSE : 0.055 \t R2 : 0.640\n"
     ]
    }
   ],
   "source": [
    "#予測した結果を足す0配列\n",
    "bagging_svm = np.zeros(len(y_test_std)).reshape(-1, 1)\n",
    "\n",
    "for i in range(20):\n",
    "    bagging_X_train, _, bagging_y_train, _ = train_test_split(X_train_std, y_train_std, shuffle=True, test_size=0.2)\n",
    "    \n",
    "    #学習、予測\n",
    "    y_pred, _, _ = pipe_score(bagging_X_train, X_test_std, np.ravel(bagging_y_train), np.ravel(y_test_std), SVR(gamma='auto'))\n",
    "    \n",
    "    #予測した結果を配列に足し上げる\n",
    "    bagging_svm += y_pred.reshape(-1, 1)\n",
    "    \n",
    "    #足し上げた結果をモデルの数で割る\n",
    "    svm_bagging_y_pred = bagging_svm / (i+1)\n",
    "\n",
    "    #MSE\n",
    "    svm_bagging_mse = mean_squared_error(y_test_std, svm_bagging_y_pred)\n",
    "\n",
    "    #R2\n",
    "    svm_bagging_r2 = r2_score(y_test_std, svm_bagging_y_pred)\n",
    "    \n",
    "    print('{}番目 MSE : {:.3f} \\t R2 : {:.3f}'.format(i+1, svm_bagging_mse, svm_bagging_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1番目 MSE : 0.070 \t R2 : 0.546\n",
      "2番目 MSE : 0.058 \t R2 : 0.622\n",
      "3番目 MSE : 0.056 \t R2 : 0.637\n",
      "4番目 MSE : 0.053 \t R2 : 0.654\n",
      "5番目 MSE : 0.054 \t R2 : 0.651\n",
      "6番目 MSE : 0.052 \t R2 : 0.661\n",
      "7番目 MSE : 0.052 \t R2 : 0.661\n",
      "8番目 MSE : 0.052 \t R2 : 0.660\n",
      "9番目 MSE : 0.052 \t R2 : 0.661\n",
      "10番目 MSE : 0.051 \t R2 : 0.669\n",
      "11番目 MSE : 0.050 \t R2 : 0.671\n",
      "12番目 MSE : 0.050 \t R2 : 0.672\n",
      "13番目 MSE : 0.050 \t R2 : 0.675\n",
      "14番目 MSE : 0.049 \t R2 : 0.679\n",
      "15番目 MSE : 0.049 \t R2 : 0.678\n",
      "16番目 MSE : 0.049 \t R2 : 0.678\n",
      "17番目 MSE : 0.050 \t R2 : 0.677\n",
      "18番目 MSE : 0.049 \t R2 : 0.679\n",
      "19番目 MSE : 0.049 \t R2 : 0.681\n",
      "20番目 MSE : 0.049 \t R2 : 0.683\n"
     ]
    }
   ],
   "source": [
    "#予測した結果を足す0配列\n",
    "bagging_tree = np.zeros(len(y_test_std)).reshape(-1, 1)\n",
    "\n",
    "for i in range(20):\n",
    "    bagging_X_train, _, bagging_y_train, _ = train_test_split(X_train_std, y_train_std, shuffle=True, test_size=0.2)\n",
    "    \n",
    "    #学習、予測\n",
    "    y_pred, _, _ = pipe_score(bagging_X_train, X_test_std, bagging_y_train, y_test_std, DecisionTreeRegressor())\n",
    "    \n",
    "    #予測した結果を配列に足し上げる\n",
    "    bagging_tree += y_pred.reshape(-1, 1)\n",
    "    \n",
    "    #足し上げた結果をモデルの数で割る\n",
    "    tree_bagging_y_pred = bagging_tree / (i+1)\n",
    "\n",
    "    #MSE\n",
    "    tree_bagging_mse = mean_squared_error(y_test_std, tree_bagging_y_pred)\n",
    "\n",
    "    #R2\n",
    "    tree_bagging_r2 = r2_score(y_test_std, tree_bagging_y_pred)\n",
    "    \n",
    "    print('{}番目 MSE : {:.3f} \\t R2 : {:.3f}'.format(i+1, tree_bagging_mse, tree_bagging_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各モデルにおいて、ブーストラップサンプルを1~20種類まで抜き出し、MSEとR2を求めた。線形回帰とSVMでは、ブーストラップサンプルの個数に関わらず精度は変わらなかったが、決定木のみ、ブーストラップサンプルを増やすにつれて精度が向上した。決定木単一の場合はMSEが0.067、R2が0.564であったが、20回抜き出した時はMSEは0.049、R2は0.683であった。\n",
    "決定木の精度が向上した理由として、決定木は訓練データが異なると、ツリー構造が異なってくる可能性があるが、バギングを行うことで訓練データの偏りがなくなったことで、精度が向上したと思われる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題3】スタッキング\n",
    "\n",
    "スタッキングを実装し、単一モデルより精度があがる例を最低1つ示してください。\n",
    "\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずは$K_0=3,M_0=2$程度にします。\n",
    "\n",
    "学習時\n",
    "\n",
    "（ステージ$0$）\n",
    "\n",
    "- 学習データを$K_0$個に分割する。\n",
    "\n",
    "- 分割した内の$(K_0 - 1)$個をまとめて学習用データ、残り$1$個を推定用データとする組み合わせが$K_0$個作れる。\n",
    "\n",
    "- あるモデルのインスタンスを$K_0$個用意し、異なる学習用データを使い学習する。\n",
    "\n",
    "- それぞれの学習済みモデルに対して、使っていない残り$1$個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "\n",
    "- さらに、異なるモデルのインスタンスも$K_0$個用意し、同様のことを行う。モデルが$M_0$個あれば、 $M_0$個のブレンドデータが得られる。\n",
    "\n",
    "(ステージ$n$）\n",
    "\n",
    "- ステージ$n - 1$のブレンドデータを$M_{n - 1}$次元の特徴量を持つ学習用データと考え、 $K_n$個に分割する。以下同様である。\n",
    "\n",
    "（ステージ$N$）＊最後のステージ\n",
    "\n",
    "- ステージ$N - 1$の$M_{N - 1}$個のブレンドデータを$M_{N - 1}$次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "推定時\n",
    "\n",
    "（ステージ$0$）\n",
    "\n",
    "- テストデータを$K_0 \\times M_0$個の学習済みモデルに入力し、$K_0 \\times M_0$個の推定値を得る。これを$K_0$の軸で平均値を求め$M_0$次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ$n$）\n",
    "\n",
    "- ステージ$n - 1$で得たブレンドテストを$K_n \\times M_n$個の学習済みモデルに入力し、$K_n \\times M_n$個の推定値を得る。これを$K_n$の軸で平均値を求め$M_0$次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージ$N$）＊最後のステージ\n",
    "\n",
    "- ステージ$N - 1$で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **ステージ0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#線形回帰\n",
    "\n",
    "#空の配列を用意\n",
    "stac_linear_array = np.array([])\n",
    "#テストデータを格納する0配列\n",
    "stac_linear_test_array = np.zeros([len(y_test_std), 3])\n",
    "\n",
    "#学習データを3分割\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "#分割したデータをリストへ格納\n",
    "for i, (train, test) in enumerate(kf.split(X_train_std, y_train_std)):\n",
    "    \n",
    "    #インスタンス化\n",
    "    stac_linear = LinearRegression()\n",
    "    \n",
    "    #分割した学習用データで学習\n",
    "    stac_linear.fit(X_train_std[train], y_train_std[train])\n",
    "    \n",
    "    #使用していない推定データで推定\n",
    "    y_pred_linear = stac_linear.predict(X_train_std[test])\n",
    "    \n",
    "    #テストデータを推定\n",
    "    y_pred_test_linear = stac_linear.predict(X_test_std)\n",
    "    \n",
    "    #予測した結果をnumpy配列に入れる\n",
    "    stac_linear_array = np.append(stac_linear_array, y_pred_linear).reshape(-1, 1)\n",
    "    stac_linear_test_array[:, i] += y_pred_test_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#SVM\n",
    "\n",
    "#空の配列を用意\n",
    "stac_svm_array = np.array([])\n",
    "#テストデータを格納する0配列\n",
    "stac_svm_test_array = np.zeros([len(y_test_std), 3])\n",
    "\n",
    "#分割したデータをリストへ格納\n",
    "for i, (train, test) in enumerate(kf.split(X_train_std, y_train_std)):\n",
    "    \n",
    "    #インスタンス化\n",
    "    stac_svm = SVR(gamma='auto')\n",
    "    \n",
    "    #分割した学習用データで学習\n",
    "    stac_svm.fit(X_train_std[train], y_train_std[train])\n",
    "    \n",
    "    #使用していない推定データで推定\n",
    "    y_pred_svm = stac_svm.predict(X_train_std[test])\n",
    "    \n",
    "    #テストデータを推定\n",
    "    y_pred_test_svm = stac_linear.predict(X_test_std)\n",
    "    \n",
    "    #予測した結果をnumpy配列に入れる\n",
    "    stac_svm_array = np.append(stac_svm_array, y_pred_svm).reshape(-1, 1)\n",
    "    stac_svm_test_array[:, i] += y_pred_test_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#決定木\n",
    "\n",
    "#空の配列を用意\n",
    "stac_tree_array = np.array([])\n",
    "#テストデータを格納する0配列\n",
    "stac_tree_test_array = np.zeros([len(y_test_std), 3])\n",
    "\n",
    "#分割したデータをリストへ格納\n",
    "for i, (train, test) in enumerate(kf.split(X_train_std, y_train_std)):\n",
    "    \n",
    "    #インスタンス化\n",
    "    stac_tree = DecisionTreeRegressor()\n",
    "    \n",
    "    #分割した学習用データで学習\n",
    "    stac_tree.fit(X_train_std[train], y_train_std[train])\n",
    "    \n",
    "    #使用していない推定データで推定\n",
    "    y_pred_tree = stac_tree.predict(X_train_std[test])\n",
    "    \n",
    "    #テストデータを推定\n",
    "    y_pred_test_tree = stac_tree.predict(X_test_std)\n",
    "    \n",
    "    #予測した結果をnumpy配列に入れる\n",
    "    stac_tree_array = np.append(stac_tree_array, y_pred_tree).reshape(-1, 1)\n",
    "    stac_tree_test_array[:, i] += y_pred_test_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#各モデルのブレンドデータを横に結合\n",
    "data0 = np.hstack([stac_linear_array, stac_svm_array, stac_tree_array])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルごとに平均値をとり、各モデルのブレンドテストを横に結合\n",
    "data0_test = np.hstack([stac_linear_test_array.mean(axis=1).reshape(-1, 1), \n",
    "                                            stac_svm_test_array.mean(axis=1).reshape(-1, 1), \n",
    "                                            stac_tree_test_array.mean(axis=1).reshape(-1, 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ステージ1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 0.041653843466348754 \t R2 : 0.7283283237370972\n"
     ]
    }
   ],
   "source": [
    "#1種類のモデルで学習\n",
    "#インスタンス化\n",
    "stac1 = LinearRegression()\n",
    "\n",
    "#学習\n",
    "stac1.fit(data0, y_train_std)\n",
    "\n",
    "#テストデータで予測\n",
    "stac_pred = stac1.predict(data0_test)\n",
    "\n",
    "#MSE\n",
    "stac_mse = mean_squared_error(y_test_std, stac_pred)\n",
    "\n",
    "#R2\n",
    "stac_r2 = r2_score(y_test_std, stac_pred)\n",
    "\n",
    "print('MSE :', stac_mse, '\\t', 'R2 :', stac_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スタッキングはステージ0とステージ1を実装した。結果はMSEが0.042、R2が0.728であり、単一モデルで一番精度の良い線形回帰のMSE:0.044、R2:0.713より精度が少し高かった。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122,
   "position": {
    "height": "237px",
    "left": "690px",
    "right": "20px",
    "top": "114px",
    "width": "611px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
